{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model\n",
    "\n",
    "\n",
    "\n",
    "Contents\n",
    "\n",
    "1. Explore the data:\n",
    "\n",
    "We have found that the MICs are discrete multiples of 2.\n",
    "Thus we can interpret the problem in terms of classification.\n",
    "\n",
    "2. The classification model\n",
    "\n",
    "Include check points to automatically save only the best model.\n",
    "We use the best recorded model for evaluations.\n",
    "https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "\n",
    "\n",
    "Tasks\n",
    "\n",
    "1. Try more k-mears.\n",
    "\n",
    "We are working with 4-mers but we want to go to 10-mers.\n",
    "\n",
    "2. Try unbalanced class approach.\n",
    "\n",
    "With raw approach we find decent results.\n",
    "https://towardsdatascience.com/handling-class-imbalanced-data-using-a-loss-specifically-made-for-it-6e58fd65ffab\n",
    "\n",
    "3. Try to comput the accuracy considering +/- 1 2-fold \n",
    "\n",
    "Reproduce the Fig. 3 of the paper.\n",
    "https://jcm.asm.org/content/57/2/e01260-18/figures-only\n",
    "\n",
    "4. Try CNN-1D, specially when we use the 10-mers since the number of bins is going to increase a lot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# MIC values in a 1 2-fold dilution step (or 1 2-fold dilution factor)\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Keras classification model\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout    \n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAA</th>\n",
       "      <th>AAAC</th>\n",
       "      <th>AAAG</th>\n",
       "      <th>AAAT</th>\n",
       "      <th>AACA</th>\n",
       "      <th>AACC</th>\n",
       "      <th>AACG</th>\n",
       "      <th>AACT</th>\n",
       "      <th>AAGA</th>\n",
       "      <th>AAGC</th>\n",
       "      <th>...</th>\n",
       "      <th>nalidixic acid</th>\n",
       "      <th>ampicillin</th>\n",
       "      <th>sulfisoxazole</th>\n",
       "      <th>cefoxitin</th>\n",
       "      <th>tetracycline</th>\n",
       "      <th>ceftiofur</th>\n",
       "      <th>amoxicillin/clavulanic acid</th>\n",
       "      <th>streptomycin</th>\n",
       "      <th>azithromycin</th>\n",
       "      <th>kanamycin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010195</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>0.010075</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010247</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>0.010122</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.010154</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.010122</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>0.010153</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.008559</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1937 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAAA      AAAC      AAAG      AAAT      AACA      AACC      AACG  \\\n",
       "0     0.010195  0.009592  0.009397  0.010176  0.007437  0.007577  0.010206   \n",
       "1     0.010449  0.009637  0.009843  0.010463  0.007509  0.007464  0.010087   \n",
       "2     0.010097  0.009737  0.009135  0.010075  0.007710  0.007822  0.010148   \n",
       "3     0.010247  0.009551  0.009677  0.010202  0.007336  0.007510  0.010134   \n",
       "4     0.010307  0.009660  0.009587  0.010329  0.007443  0.007574  0.010206   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1932  0.009980  0.009666  0.009202  0.009970  0.007589  0.007733  0.010247   \n",
       "1933  0.010330  0.009561  0.009833  0.010424  0.007569  0.007630  0.009912   \n",
       "1934  0.010122  0.009620  0.009437  0.010167  0.007503  0.007677  0.010154   \n",
       "1935  0.010025  0.009611  0.009521  0.010214  0.007612  0.007600  0.010122   \n",
       "1936  0.010226  0.009454  0.009795  0.010327  0.007293  0.007432  0.010153   \n",
       "\n",
       "          AACT      AAGA      AAGC  ...  nalidixic acid  ampicillin  \\\n",
       "0     0.005423  0.006263  0.008236  ...             4.0         1.0   \n",
       "1     0.005524  0.006698  0.008495  ...             4.0         1.0   \n",
       "2     0.005425  0.006208  0.008100  ...             4.0         1.0   \n",
       "3     0.005421  0.006495  0.008521  ...             4.0         1.0   \n",
       "4     0.005528  0.006474  0.008381  ...            32.0         1.0   \n",
       "...        ...       ...       ...  ...             ...         ...   \n",
       "1932  0.005414  0.006218  0.008093  ...             4.0         1.0   \n",
       "1933  0.005661  0.006756  0.008575  ...             4.0        32.0   \n",
       "1934  0.005604  0.006500  0.008380  ...             4.0        32.0   \n",
       "1935  0.005471  0.006532  0.008427  ...             4.0        32.0   \n",
       "1936  0.005451  0.006566  0.008559  ...             4.0         1.0   \n",
       "\n",
       "      sulfisoxazole  cefoxitin  tetracycline  ceftiofur  \\\n",
       "0              16.0        4.0          32.0        0.5   \n",
       "1             256.0        4.0          32.0        1.0   \n",
       "2              32.0        4.0          32.0        0.5   \n",
       "3              32.0        4.0          32.0        1.0   \n",
       "4              64.0        2.0           4.0        0.5   \n",
       "...             ...        ...           ...        ...   \n",
       "1932           32.0        2.0          32.0        1.0   \n",
       "1933          256.0       16.0          32.0        8.0   \n",
       "1934          256.0       32.0          32.0        8.0   \n",
       "1935          256.0       32.0          32.0        8.0   \n",
       "1936           32.0        4.0           4.0        1.0   \n",
       "\n",
       "      amoxicillin/clavulanic acid  streptomycin  azithromycin  kanamycin  \n",
       "0                             1.0           8.0           8.0        NaN  \n",
       "1                             1.0          64.0           8.0        NaN  \n",
       "2                             1.0           4.0           8.0        NaN  \n",
       "3                             1.0           8.0           8.0        NaN  \n",
       "4                             1.0           4.0           4.0        NaN  \n",
       "...                           ...           ...           ...        ...  \n",
       "1932                          1.0           4.0           8.0        NaN  \n",
       "1933                         32.0          64.0           4.0        NaN  \n",
       "1934                         32.0          64.0           4.0       64.0  \n",
       "1935                         32.0           4.0           4.0        NaN  \n",
       "1936                          1.0          16.0           4.0        NaN  \n",
       "\n",
       "[1937 rows x 151 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4-mers Spectrum- MIC-Matrix\n",
    "\n",
    "matrix = pd.read_csv('tetramers_mics_matrix.csv', index_col=0)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Amount of genomes')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEICAYAAACuxNj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgdVZ3/8fcnCfsWMBEhiQQwoKAgGBZ3BIZNII4DDCAYWYw4gDgyIoiPQZTfMDojwiA4ASJEWWUzKg5GliDjkNCshk3asCQhkCZhU4Yl8P39cU6T4nK7qzrddwn9eT3Pfbrq1Kmqb9etW9+qOrUoIjAzM+vNkFYHYGZm7c/JwszMSjlZmJlZKScLMzMr5WRhZmalnCzMzKyUk0WbkXShpO+1aN6S9FNJz0ia3YoYVjSSPi7poV6Gj5UUkob1Yx6PStp1eccfTGq/j96WXdl3V2Fe90naaXnHX9E4WZTIK9siSWsUyo6UdHMLw2qUjwF/B4yOiO1bHcyKICL+EBGbd/f3d8Peyp2FFVFOxO/p7q/9PnrTl7r1vpeI2DIibu5jvN07D3fVlI+Q9IqkRwtlb1qXJG0g6QJJCyW9IOlBSd8pbpsaycmimqHAca0Ooq8kDe3jKBsBj0bE3xoRj5m9YXVJ7y/0Hww80lNlSesB/wusBnw4ItYi7dgNBzZtZKBviAh/evkAjwInAkuA4bnsSODm3D0WCGBYYZybgSNz9xeA/wHOAJ4F5gIfyeXzgEXAxMK4FwI/AWYALwAzgY0Kw9+bhy0BHgIOqBn3XOA64G/ArnX+nw2B6Xn8TuCLufwI4CXgNeCvwHfqjDsU+A/gadKKfUzxfwfWAS4AFgILgO8BQwvL4Vbg34Fn8vh7lsWVh50C/AL4eV4mfwI2A07Ky28esFuhfm9xvCcv0+fy/3F5D9/7RcDxuXtU/j+Pzv2b5jiHADsB83P5z4DXgf/Ly/CEwvoxEXg8z/PkHuY5CXgVeCWP/6vCOvgvwL057suBVQvj7Q3cTVq//ghs1cP0RVoPFwHP5+X4/jzs08BduXwecEphvO7/4bA87BngKGC7HNOzwNk18zoceCDXvZ7COlwnrl8AT+b/7RZgy5p1+sfAb/J3PwvYNA+7Jcf1t7y8/rH4fRSW3UnA/TmWn3Yvuzp130f67T4L3AfsW+F72bXw2/gm8Jcc5x3AmDr/a/ey/Bbwg0J5B3AyaWeNOtP/Xv6+hrRsW9iqGa8on+4vDLga+F4u62uyWJp/aEPzl/54/gGsAuyWV641Cz+OF4BP5OFnArfmYWuQfqyHAcOAbUgbny0K4z4HfJS0IVu1zv9zC3AOsCrwQaAL2LkQ6629LIuj8o9uNLAu8HvenCyuAf4rx/lOYDbwpcK0XwW+mJfDl4EnAFWI6xRSIts9/9/TSMnmZGClPM1HCnH2FselebwheV4f6+F/PZxlG4WDSRuBywvDfpm7d+KtG6ddC/1j8zI6j7RXuDXwMvC+HuZ7IXk9q5nmbFJCXY+0ET4qD9uGtPHfIS/Xibn+KnWmvTtpIzaclDjeB2xQ+D8+kJfLVsBTwGdq/oef5GW2W/4+rs3Ld1SO4ZO5/gRSwn9f/r6+Bfyxl/XqcGAt0vr+I+DumuWxGNg+T+ti4LLC8ADeU+iv933MAcbkZfc/LPsdv1GXtB51kjb4KwM7k36Hm5d8L90b86+TNuab52W7NfCOOv9r97IcS/otDwW2AB4kbWce7WH6t1FnB66p28JWznxF+LAsWbyftCEeSd+TxcOFYR/I9dcvlC0GPlhYKYs/hjVJe/tjSHtOf6iJ77+AyYVxp/Xyv4zJ01qrUPavwIWFWHtLFjeSN7q5f9fu/x1Yn7QRXK0w/CDgpsK0OwvDVs/jvqtCXKcAMwrD9iHt4XUfLayVpzW8QhzTgCmkdpnevvdNSXuiQ0gbyS+xbMNyEfC13L0T1ZLF6ELZbODAHuZ7IfU3SocU+r8P/CR3nwt8t6b+Q+QNd035zsCfgR0p2UMlbbTPqPkfRtWss/9Y6L8K+Gru/i1wRGHYEOBFejm6KNQdnue1TmF5nF8YvhfwYKG/SrI4qmb8v9TWBT5OOroZUqh7KfkIq5fvpXtj/hAwocL/170sh5F2tnYHTiftwPSWLB4u/h+t+LjNoqKImAP8mnRKqq+eKnT/X55ebdmahf55hfn+lXTKY0NSm8IOkp7t/gCfI21w3zJuHRsCSyLihULZY6Q9wyo2rJl+sXsj0t7ZwkJs/0Xa8+z2ZOH/ejF3rlkxrtrl9XREvFbo755WWRwnkPb8ZuerWQ6v949GxF9Ipzc+SNqQ/Bp4QtLmwCdJp7L64slC94u8+fvuz/gbAcfXrBNjSMv0TSLiRuBs0lHtIklTJK0NIGkHSTdJ6pL0HOkockTNJGq/g57W4Y2AMwvxLCEt87esZ5KGSjpd0l8kPU/aQFIz7/4uu+J6+hh1lk0umxcRr9fUrfrbGEM6+uyLaaSdqINIpzB7sxjYoI/TH1BOFn0zmXTKo7gCdTcGr14oK268l8eY7g5Ja5IOn58grfQzI2J44bNmRHy5MG70Mt0ngPUkrVUoezfpvH4VC0mnoN4SZ47tZWBEIba1I2LLCtPtb1xFvcYREU9GxBcjYkPS0cI5xatpaswE9gNWjogFuX8i6RTc3T2M09vyr6Kv488DTqtZJ1aPiEvrTjzirIj4EOnUx2ak0ycAl5DajMZExDqkoykt37/APNIRaDGm1SLij3XqHkw6bbUrqa1pbC5f3nnXU1xP301a32o9AYyRNKSmbvc6WPa9zKPvDc1XkdqK5kbE4yV1fw/8fU18TeVk0QcR0UlqXPxKoayLtEIdkveSDqf/VyfsJeljklYGvgvcFhHzSHu3m0k6VNJK+bOdpPdVjH8eqQH0XyWtKmkrUsP2zyvGdQVwnKRRkoYD3yhMeyHwO+A/JK0taYikTSV9sglxFafVaxyS9pfUnfCeIW0EXu9hcjNJjfi35P6bc/+thaOaWk8Bm/Q17n6Mfx5wVD4ykKQ1JH26JvECkNeVHSStRNrJeYll//tapKO7lyRtT9qIL6+fACdJ2jLPdx1J+/dQdy1Scl9M2uH6f32cV5XldbSk0fmKopNJv+Fas0hHLSfk39VOpNOdl1Wcz/nAdyWNy9/DVpLe0VtQka463Jl0WrvMD4G1gYskbQSQf4c/zL+XhnOy6LtTSQ2nRV8k7aEtBrYkbfj64xLSUcwS4EPAIQD5NM1uwIGkPaEngX8jNQxWdRBp7+0JUkPw5Ij4fcVxzyNtiO8lXTlzHanxvnvD+XlS42D3lSdXUv3QuT9x1eotju2AWZL+StqTPi4i5vYwnZmkjVl3sriVtEG7pYf6kNpavpVPwfzLcsR+AbBFHv/assoR0UFa/84m/a+dpFMb9axN+g6fIZ1iWQz8IA/7J+BUSS8A3ybtGCyXiLiGtF5elk8tzQH27KH6tBzLAtL3dVsfZ3cKaQP6rKQDeqhzCWm9nUs6VfSW+1gi4hVSctiTdNHIOcDnI+LBXKXse/khaZn9jnRF2QWkCxp6FREd+ZRnWb0lpKsoXyWtvy8AN5DaUTvLxh8I3VeimPWZpD1JDa0btToWM2ssH1lYZZJWk7SXpGGSRpGOfq5pdVxm1ng+srDKJK1OOjXzXtLVL78hncZ5vqWBmVnDOVmYmVkpn4YyM7NSy/3Y5HY2YsSIGDt2bKvDMDNbodxxxx1PR8TIesPelsli7NixdHR0tDoMM7MViqTHehrm01BmZlbKycLMzEo5WZiZWSknCzMzK+VkYWZmpZwszMyslJOFmZmVcrIwM7NSThZmZlbqbXkHd60PfX1aS+Z7xw8+35L5mpkNNB9ZmJlZKScLMzMr5WRhZmalnCzMzKyUk4WZmZVqWLKQNFXSIklzasqPlfSgpPskfb9QfpKkTkkPSdq9UL5HLuuUdGKj4jUzs5418tLZC4GzgTeuW5X0KWACsHVEvCzpnbl8C+BAYEtgQ+D3kjbLo/0Y+DtgPnC7pOkRcX8D4zYzsxoNSxYRcYuksTXFXwZOj4iXc51FuXwCcFkuf0RSJ7B9HtYZEXMBJF2W6zpZmJk1UbPbLDYDPi5plqSZkrbL5aOAeYV683NZT+VvIWmSpA5JHV1dXQ0I3cxs8Gp2shgGrAfsCHwduEKSBmLCETElIsZHxPiRI+u+b9zMzJZTsx/3MR+4OiICmC3pdWAEsAAYU6g3OpfRS7mZmTVJs48srgU+BZAbsFcGngamAwdKWkXSxsA4YDZwOzBO0saSViY1gk9vcsxmZoNew44sJF0K7ASMkDQfmAxMBabmy2lfASbmo4z7JF1BarheChwdEa/l6RwDXA8MBaZGxH2NitnMzOpr5NVQB/Uw6JAe6p8GnFan/DrgugEMzczM+sh3cJuZWSknCzMzK+VkYWZmpZwszMyslJOFmZmVcrIwM7NSThZmZlbKycLMzEo5WZiZWSknCzMzK+VkYWZmpZwszMyslJOFmZmVcrIwM7NSThZmZlbKycLMzEo1LFlImippUX4rXu2w4yWFpBG5X5LOktQp6V5J2xbqTpT0cP5MbFS8ZmbWs0YeWVwI7FFbKGkMsBvweKF4T9J7t8cBk4Bzc931SK9j3QHYHpgsad0GxmxmZnU0LFlExC3AkjqDzgBOAKJQNgGYFsltwHBJGwC7AzMiYklEPAPMoE4CMjOzxmpqm4WkCcCCiLinZtAoYF6hf34u66m83rQnSeqQ1NHV1TWAUZuZWdOShaTVgW8C327E9CNiSkSMj4jxI0eObMQszMwGrWYeWWwKbAzcI+lRYDRwp6R3AQuAMYW6o3NZT+VmZtZETUsWEfGniHhnRIyNiLGkU0rbRsSTwHTg8/mqqB2B5yJiIXA9sJukdXPD9m65zMzMmqiRl85eCvwvsLmk+ZKO6KX6dcBcoBM4D/gngIhYAnwXuD1/Ts1lZmbWRMMaNeGIOKhk+NhCdwBH91BvKjB1QIMzM7M+8R3cZmZWysnCzMxKOVmYmVkpJwszMyvlZGFmZqWcLMzMrJSThZmZlXKyMDOzUk4WZmZWqjRZSFpD0pDcvZmkfSWt1PjQzMysXVQ5srgFWFXSKOB3wKGkt+CZmdkgUSVZKCJeBD4LnBMR+wNbNjYsMzNrJ5WShaQPA58DfpPLhjYuJDMzazdVksVXgZOAayLiPkmbADc1NiwzM2snpY8oj4iZwMz8WlQiYi7wlUYHZmZm7aPK1VAflnQ/8GDu31rSOQ2PzMzM2kaV01A/AnYHFgNExD3AJ8pGkjRV0iJJcwplP5D0oKR7JV0jaXhh2EmSOiU9JGn3QvkeuaxT0ol9+efMzGxgVLopLyLm1RS9VmG0C4E9aspmAO+PiK2AP5PaQpC0BXAg6SqrPYBzJA2VNBT4MbAnsAVwUK5rZmZNVCVZzJP0ESAkrSTpX4AHykaKiFuAJTVlv4uIpbn3NmB07p4AXBYRL0fEI6R3cW+fP50RMTciXgEuy3XNzKyJqiSLo0jvxx4FLAA+SA/vy+6jw4Hf5u5RQPHoZX4u66n8LSRNktQhqaOrq2sAwjMzs25VroZ6mnSPxYCRdDKwFLh4oKYZEVOAKQDjx4+PgZqumZlVSBaSNgaOBcYW60fEvsszQ0lfAPYGdomI7o36AmBModroXEYv5WZm1iSlyQK4FrgA+BXwen9mJmkP4ATgk/kRIt2mA5dI+iGwITAOmA0IGJcT1gJSI/jB/YnBzMz6rkqyeCkizurrhCVdCuwEjJA0H5hMuvppFWCGJIDbIuKofGf4FcD9pNNTR0fEa3k6xwDXkx4xMjUi7utrLGZm1j9VksWZkiaTnjj7cndhRNzZ20gRcVCd4gt6qX8acFqd8uuA6yrEaWZmDVIlWXyA9FjynVl2Gipyv5mZDQJVksX+wCb5PgczMxuEqtxnMQcYXlrLzMzetqocWQwHHpR0O29us1iuS2fNzGzFUyVZTG54FGZm1tYqvc9C0vrAdrlodkQsamxYZmbWTqq8z+IA0g1y+wMHALMk7dfowMzMrH1UOQ11MrBd99GEpJHA74ErGxmYmZm1jypXQw2pOe20uOJ4Zmb2NlHlyOK/JV0PXJr7/xHfUW1mNqhUaeD+uqR/AD6ai6ZExDWNDcvMzNpJlSMLIuIq4KoGx2JmZm2qytVQn5X0sKTnJD0v6QVJzzcjODMzaw9Vjiy+D+wTEaXv3TYzs7enKlc1PeVEYWY2uFVJFh2SLpd0UD4l9VlJny0bSdJUSYskzSmUrSdpRj6tNUPSurlcks6S1CnpXknbFsaZmOs/LGnicv2XZmbWL1WSxdrAi8BuwD75s3eF8S4E9qgpOxG4ISLGATfkfoA9Sa9SHQdMAs6FlFxIz6baAdgemNydYMzMrHmqXDp72PJMOCJukTS2pngC6VWrABcBNwPfyOXTIiKA2yQNl7RBrjsjIpYASJpBSkCXYmZmTVPlaqjNJN3QfTpJ0laSvrWc81s/Ihbm7ieB9XP3KGBeod78XNZTeb04J0nqkNTR1dW1nOGZmVk9VU5DnQecBLwKEBH3Agf2d8b5KCL6O53C9KZExPiIGD9y5MiBmqyZmVEtWaweEbNrypYu5/yeyqeXyH+7nzm1ABhTqDc6l/VUbmZmTVQlWTwtaVPyUUB+PPnC3kfp0XSg+4qmicAvC+Wfz1dF7Qg8l09XXQ/sJmnd3LC9Wy4zM7MmqnJT3tHAFOC9khYAjwCHlI0k6VJSA/UISfNJVzWdDlwh6QjgMdL7MSA9mHAvoJN05dVhABGxRNJ3gdtzvVO7G7vNzKx5qlwNNRfYVdIapMeVv1BlwhFxUA+DdqlTN0hJqd50pgJTq8zTzMwaozRZSPpaTT/Ac8AdEXF3g+IyM7M2UqXNYjxwFMsuZf0S6V6H8ySd0MDYzMysTVRpsxgNbBsRfwWQNBn4DfAJ4A7SgwbNzOxtrMqRxTuBlwv9r5Jurvu/mnIzM3ubqnJkcTEwS1L3Za77AJfkBu/7GxaZmZm1jSpXQ31X0m9Z9lrVoyKiI3d/rmGRmZlZ26j6WtUOoKO0opmZvS1VabMwM7NBrsdkIWmVZgZiZmbtq7cji/8FkPSzJsViZmZtqrc2i5UlHQx8pN5rVCPi6saFZWZm7aS3ZHEU6Wqn4aTLZYsCcLIwMxskekwWEXErcKukjoi4oIkxmZlZm6ly6ezPJH2F9HgPgJnATyLi1caFZWZm7aRKsjgHWCn/BTgUOBc4slFBmZlZe6mSLLaLiK0L/TdKuqdRAZmZWfupclPea/m1qgBI2gR4rT8zlfTPku6TNEfSpZJWlbSxpFmSOiVdLmnlXHeV3N+Zh4/tz7zNzKzvqiSLrwM3SbpZ0kzgRuD45Z2hpFHAV4DxEfF+YChwIPBvwBkR8R7gGeCIPMoRwDO5/Ixcz8zMmqg0WUTEDcA40gb+WGDziLipn/MdBqwmaRiwOrAQ2Bm4Mg+/CPhM7p6Q+8nDd1F+XZ+ZmTVHpWdDRcTLEXFv/vTrHRYRsQD4d+BxUpJ4jvQSpWcjYmmuNp/0Vj7y33l53KW5/jtqpytpkqQOSR1dXV39CdHMzGo0/UGCktYlHS1sDGwIrEF6TWu/RMSUiBgfEeNHjhzZ38mZmVlBK546uyvwSER05Xs1ria9K2N4Pi0F6VWuC3L3AmAMQB6+DrC4uSGbmQ1upclC0g1VyvrgcWBHSavntoddSG/cuwnYL9eZCHS/mW967icPvzEioh/zNzOzPurxPgtJq5Ian0fkU0fdjcprs6w9oc8iYpakK4E7gaXAXcAU4DfAZZK+l8u6HzFyAeku8k5gCenKKTMza6Lebsr7EvBVUrvCHSxLFs8DZ/dnphExGZhcUzwX2L5O3ZeA/fszPzMz65/eHiR4JnCmpGMj4j+bGJOZmbWZ0sd9RMR/SvoIMLZYPyKmNTAuMzNrI6XJIr8pb1PgbpY95iMAJwszs0GiyoMExwNb+AokM7PBq8p9FnOAdzU6EDMza19VjixGAPdLmg288aiPiNi3YVGZmVlbqZIsTml0EGZm1t6qXA01sxmBmJlZ+6pyNdQLpKufAFYmvWL1bxGxdiMDMzOz9lHlyGKt7u78LKcJwI6NDMrMzNpLn546G8m1wO4NisfMzNpQldNQny30DiHdd/FSwyIyM7O2U+VqqH0K3UuBR0mnoszMbJCo0mZxWDMCMTOz9lXl5UejJV0jaVH+XCVpdDOCMzOz9lClgfunpLfVbZg/v8plZmY2SFRJFiMj4qcRsTR/LgRG9memkoZLulLSg5IekPRhSetJmiHp4fx33VxXks6S1CnpXknb9mfeZmbWd1WSxWJJh0gamj+HAIv7Od8zgf+OiPcCWwMPACcCN0TEOOCG3A+wJzAufyYB5/Zz3mZm1kdVksXhwAHAk8BCYD9guRu9Ja0DfIL8ju2IeCUiniVdYXVRrnYR8JncPQGYlu/xuA0YLmmD5Z2/mZn1XZWroR4DBvIJsxsDXcBPJW1Ner/3ccD6EbEw13kSWD93jwLmFcafn8sWFsqQNIl05MG73/3uAQzXzMyq3JS3MXAsb32t6vImkGHAtsCxETFL0pksO+XUPe2Q1KeXLUXEFGAKwPjx4/2iJjOzAVTlprxrSaeMfgW8PgDznA/Mj4hZuf9KUrJ4StIGEbEwn2ZalIcvAMYUxh+dy8zMrEmqJIuXIuKsgZphRDwpaZ6kzSPiIWAX4P78mQicnv/+Mo8yHThG0mXADsBzhdNVZmbWBFWSxZmSJgO/481vyruzH/M9FrhY0srAXFKD+RDgCklHAI+RGtUBrgP2AjqBF+lH47qZmS2fKsniA8ChwM4sOw0VuX+5RMTdpAcS1tqlTt0Ajl7eeZmZWf9VSRb7A5tExCuNDsbMzNpTlfss5gDDGx2ImZm1rypHFsOBByXdzpvbLAby3gszM2tjVZLF5IZHYWZmba3KHdwzi/2SPgYcBMysP4aZmb3dVDmyQNI2wMGkxu5HgKsaGZSZmbWXHpOFpM1IRxAHAU8DlwOKiE81KTYzM2sTvR1ZPAj8Adg7IjoBJP1zU6IyM7O20tuls58lPdn1JknnSdoFUHPCMjOzdtJjsoiIayPiQOC9wE3AV4F3SjpX0m7NCtDMzFqv9Ka8iPhbRFwSEfuQnvh6F/CNhkdmZmZto8od3G+IiGciYkpEvOUZTmZm9vbVp2RhZmaDk5OFmZmVcrIwM7NSLUsWkoZKukvSr3P/xpJmSeqUdHl+MRKSVsn9nXn42FbFbGY2WLXyyOI44IFC/78BZ0TEe4BngCNy+RHAM7n8jFzPzMyaqCXJQtJo4NPA+blfpDfvXZmrXAR8JndPyP3k4bvk+mZm1iStOrL4EXACy17T+g7g2YhYmvvnA6Ny9yhgHkAe/lyu/yaSJknqkNTR1dXVyNjNzAadpicLSXsDiyLijoGcbr7/Y3xEjB85cuRATtrMbNCr9IjyAfZRYF9JewGrAmsDZwLDJQ3LRw+jgQW5/gJgDDBf0jBgHWBx88M2Mxu8mn5kEREnRcToiBgLHAjcGBGfIz1/ar9cbSLwy9w9PfeTh98YEdHEkM3MBr12us/iG8DXJHWS2iQuyOUXAO/I5V8DTmxRfGZmg1YrTkO9ISJuBm7O3XOB7evUeYn0hj4zM2uRdjqyMDOzNuVkYWZmpZwszMyslJOFmZmVcrIwM7NSThZmZlbKycLMzEo5WZiZWSknCzMzK+VkYWZmpZwszMyslJOFmZmVcrIwM7NSThZmZlbKycLMzEo5WZiZWammJwtJYyTdJOl+SfdJOi6XrydphqSH8991c7kknSWpU9K9krZtdsxmZoNdK44slgLHR8QWwI7A0ZK2IL0u9YaIGAfcwLLXp+4JjMufScC5zQ/ZzGxwa3qyiIiFEXFn7n4BeAAYBUwALsrVLgI+k7snANMiuQ0YLmmDJodtZjaotbTNQtJYYBtgFrB+RCzMg54E1s/do4B5hdHm57LaaU2S1CGpo6urq2Exm5kNRi1LFpLWBK4CvhoRzxeHRUQA0ZfpRcSUiBgfEeNHjhw5gJGamVlLkoWklUiJ4uKIuDoXP9V9ein/XZTLFwBjCqOPzmVmZtYkrbgaSsAFwAMR8cPCoOnAxNw9Efhlofzz+aqoHYHnCqerzMysCYa1YJ4fBQ4F/iTp7lz2TeB04ApJRwCPAQfkYdcBewGdwIvAYc0N18zMmp4sIuJWQD0M3qVO/QCObmhQZmbWK9/BbWZmpZwszMyslJOFmZmVcrIwM7NSThZmZlbKycLMzEo5WZiZWalW3JRnZoPEA6fd2JL5vu/knVsy37czH1mYmVkpJwszMyvlZGFmZqXcZmH2NnHaIfu1ZL4n//zKlszXmsvJwswGnVNOOWVQzHMg+TSUmZmVcrIwM7NSThZmZlZqhWmzkLQHcCYwFDg/Ik5vcUhmZgPmil9s35L5HrD/7Er1VohkIWko8GPg74D5wO2SpkfE/a2NzAars4//VUvme8x/7NOS+ZqtEMkC2B7ojIi5AJIuAyYAK2yyePzUD7Rkvu/+9p9aMl8zW7EpveK6vUnaD9gjIo7M/YcCO0TEMYU6k4BJuXdz4KEBmv0I4OkBmtZAcUzVtWNcjqkax1TdQMW1UUSMrDdgRTmyKBURU4ApAz1dSR0RMX6gp9sfjqm6dozLMVXjmKprRlwrytVQC4Axhf7RuczMzJpgRUkWtwPjJG0saWXgQGB6i2MyMxs0VojTUBGxVNIxwPWkS2enRsR9TZr9gJ/aGgCOqbp2jMsxVeOYqmt4XCtEA7eZmbXWinIayszMWsjJwszMSg3qZCFpD0kPSeqUdGKd4V+TdL+keyXdIGmjwrDXJN2dPw1pbK8Q3xckdRXiOLIRcdTMc6qkRZLm9DBcks7KMd8radsGxzNG0k35e7pP0nGtjqkw36GS7pL06zrDVpF0eY5plqSxTYrpn/NymiPpUkmrNjuuntYhScdKejDH9/0exu31N9GPmFaVNFvSPXn+38nlF+f5zclxr9TD+BMlPZw/EwcwruGSrszL5QFJHy4MO15SSBrRlJgiYlB+SA3lfwE2AVYG7gG2qKnzKWD13P1l4PLCsL+2QXxfAM5u8qTX6gQAAASZSURBVHL7BLAtMKeH4XsBvwUE7AjManA8GwDb5u61gD/XWU5Njakw368BlwC/rjPsn4Cf5O4Di+tWA+MZBTwCrJb7rwC+0Oy46q1D+bf2e2CV3P/OOuOV/ib6EZOANXP3SsCsvK7slYcJuBT4cp1x1wPm5r/r5u51Byiui4Ajc/fKwPDcPYZ0wc9jwIhmxDSYjyzeeIRIRLwCdD9C5A0RcVNEvJh7byPd39E28bVCRNwCLOmlygRgWiS3AcMlbdDAeBZGxJ25+wXgAdJGsWUxAUgaDXwaOL+HKhNIGwKAK4FdJKmRMWXDgNUkDQNWB55odlw9rENfBk6PiJdznUV1Rm3YbyKvG3/NvSvlT0TEdXlYALOpvw3YHZgREUsi4hlgBrBHf2OStA4psV6QY3wlIp7Ng88ATgB6ukJpwGMazMliFDCv0D+ft25kio4g7Z12W1VSh6TbJH2mhfH9Qz61cqWkMXWGN1tfl+uAyadMtiHtFbY6ph+Rfsyv9zD8jZgiYinwHPCORgYUEQuAfwceBxYCz0XE71odV7YZ8PF86mumpO3q1Gno95hPG94NLCJtaGcVhq0EHAr8dxPj2hjoAn6aT2eeL2kNSROABRFxTy/jDnhMgzlZVCbpEGA88INC8UaRbq8/GPiRpE1bENqvgLERsRVpz+GikvpvW5LWBK4CvhoRz7c4lr2BRRFxRyvjqCVpXdKe+MbAhsAaed1uB8NIp0x2BL4OXNGkI603RMRrEfFB0tHD9pLeXxh8DnBLRPyhiSENI52uOzcitgH+BpwCfBP4dhPjAAZ3sqj0CBFJuwInA/t2HyLDG3tpRHoS7s2kPdqmxhcRiwsxnQ98aIBjWB5NfzRL3uu7Crg4Iq5ug5g+Cuwr6VHSqZKdJf28p5jyKaF1gMUNjAlgV+CRiOiKiFeBq4GPtEFckPZ8r85nfGaTjshqG26b8j3mUz03kU/bSJoMjCS1QdXTqLjmA/MLRzhXkpLHxsA9ef0aDdwp6V0Nj2kgGmFWxA8pa8/NC767sWzLmjrbkBrUxtWUr8uyhrgRwMMMUENbH+PboND998BtTVp2Y+m5gfvTvLkxeXaDYxEwDfhRL3WaGlPNvHeifgP30by5IfmKJsSyA3Afqa1CpCPRY1sRV+06BBwFnJq7NyOdQlHNOKW/iX7EM5JljcerAX8A9gaOBP5Iviigh3HXI104sG7+PAKsN0Bx/QHYPHefAvygZvij9NzAPaAxNXTlbPcP6UqHP+eEcHIuO5V0FAHp6oyngLvzZ3ou/wjwp7yy/gk4okXx/Wv+8d9D2hN6bxOW2aWk892vkvZ8jsg/9KPycJFeVPWXvGzGNziej5Ea+e4tfE97tTKmmvh2IieLmu9uVeAXQCep4XSTJsXzHeBBYA7wM2CVZsfVwzq0MvDzHNedwM657obAdb39JgYopq2Au/J6NAf4di5fmufVvW51l48nvbGze/zD8zLrBA4bwLg+CHTkuK6l5oomCsmi0TH5cR9mZlZqMLdZmJlZRU4WZmZWysnCzMxKOVmYmVkpJwszMyvlZGFmZqWcLMzMrNT/B+6uxgR7EYoGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar chart showing the number of genomes with the same antibiotic MIC values\n",
    "\n",
    "# List of unique MIC values without NaN values\n",
    "mic_values = matrix['ceftriaxone'].loc[matrix['ceftriaxone']>0].sort_values().unique()\n",
    "\n",
    "# Number of genomes with the same antibiotic MIC\n",
    "amount = [len(matrix.loc[matrix['ceftriaxone']==mic]) for mic in mic_values]\n",
    "\n",
    "# Set the width and height of the figure\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Number of genomes with the same antibiotic MIC\")\n",
    "\n",
    "# Bar chart showing average arrival delay for Spirit Airlines flights by month\n",
    "sns.barplot(x=mic_values, y=amount)\n",
    "\n",
    "# Add label for vertical axis\n",
    "plt.ylabel(\"Amount of genomes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.25   0.50   1.00   2.00   4.00   8.00   16.00  32.00  64.00\n",
      "0   1678      5      1      1     14     67     93     57     21\n",
      "   0.120  0.125  0.250  0.500  1.000  2.000  4.000\n",
      "0   1091    660    140      9      2      1     34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.015</th>\n",
       "      <th>0.030</th>\n",
       "      <th>0.060</th>\n",
       "      <th>0.120</th>\n",
       "      <th>0.125</th>\n",
       "      <th>0.250</th>\n",
       "      <th>0.500</th>\n",
       "      <th>1.000</th>\n",
       "      <th>2.000</th>\n",
       "      <th>4.000</th>\n",
       "      <th>8.000</th>\n",
       "      <th>16.000</th>\n",
       "      <th>32.000</th>\n",
       "      <th>64.000</th>\n",
       "      <th>128.000</th>\n",
       "      <th>256.000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1596.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>430.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>769.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>563.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.015    0.030    0.060    0.120    0.125    0.250    0.500    1.000    \\\n",
       "0       NaN      NaN      NaN      NaN      NaN   1678.0      5.0      1.0   \n",
       "1       NaN      NaN      NaN   1091.0    660.0    140.0      9.0      2.0   \n",
       "2    1596.0    299.0     10.0      NaN      5.0      6.0     17.0      4.0   \n",
       "3       NaN      NaN      NaN      NaN      NaN    430.0   1078.0    198.0   \n",
       "4       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "5       NaN      NaN      NaN      NaN      NaN      NaN      NaN      4.0   \n",
       "6       NaN      NaN      NaN      NaN      NaN      NaN      NaN   1246.0   \n",
       "7       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "8       NaN      NaN      NaN      NaN      NaN      NaN      NaN     41.0   \n",
       "9       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "10      NaN      NaN      NaN      NaN      NaN      1.0    430.0   1191.0   \n",
       "11      NaN      NaN      NaN      NaN      NaN      NaN      NaN   1354.0   \n",
       "12      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "13      NaN      NaN      NaN      NaN      NaN      1.0      NaN      9.0   \n",
       "14      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "    2.000    4.000    8.000    16.000   32.000   64.000   128.000  256.000  \n",
       "0       1.0     14.0     67.0     93.0     57.0     21.0      NaN      NaN  \n",
       "1       1.0     34.0      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3      11.0      4.0     20.0    196.0      NaN      NaN      NaN      NaN  \n",
       "4      16.0    672.0   1113.0     43.0     93.0      NaN      NaN      NaN  \n",
       "5     545.0   1328.0     26.0     15.0     19.0      NaN      NaN      NaN  \n",
       "6     182.0      8.0      NaN      2.0    499.0      NaN      NaN      NaN  \n",
       "7       NaN      NaN      NaN    275.0    713.0    283.0     17.0    649.0  \n",
       "8     836.0    700.0    108.0     43.0    209.0      NaN      NaN      NaN  \n",
       "9       NaN    769.0      6.0      6.0   1156.0      NaN      NaN      NaN  \n",
       "10     63.0      7.0    245.0      NaN      NaN      NaN      NaN      NaN  \n",
       "11     90.0     21.0    163.0     64.0    245.0      NaN      NaN      NaN  \n",
       "12     34.0    146.0    419.0    161.0     93.0    689.0      NaN      NaN  \n",
       "13    462.0   1280.0    171.0     14.0      NaN      NaN      NaN      NaN  \n",
       "14      NaN      NaN    563.0      7.0      3.0     66.0      NaN      NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of genomes with the same MIC, by antibiotic.\n",
    "\n",
    "antibiotics = matrix.columns[-15:]\n",
    "amounts = []\n",
    "for antibiotic in antibiotics:\n",
    "    mic_values = matrix[antibiotic].loc[matrix[antibiotic]>0].sort_values().unique()\n",
    "    amount = []\n",
    "    for mic in mic_values:\n",
    "        amount.append(len(matrix.loc[matrix[antibiotic]==mic]))\n",
    "    amounts.append(pd.DataFrame(np.reshape(amount, (1,-1)), columns=mic_values))\n",
    "amounts_dframe = amounts[0].append(amounts[1:15], sort=False, ignore_index=True)\n",
    "\n",
    "print(amounts[0])\n",
    "print(amounts[1])\n",
    "amounts_dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 33.0, 'Antibiotic MIC (micrograms per milliliter)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap showing the number of genomes with the same MIC, by antibiotic.\n",
    "\n",
    "# Set the width and height of the figure\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Number of genomes with the same MIC, by antibiotic\")\n",
    "\n",
    "# Heatmap showing the amount of genomes with the same MIC for each MIC, by antibiotic\n",
    "sns.heatmap(data=amounts_dframe, annot=True,fmt='.4g',cmap=\"YlGnBu\")\n",
    "\n",
    "# Add label for horizontal axis\n",
    "plt.xlabel(\"Antibiotic MIC (micrograms per milliliter)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atibiotic\n",
    "antibiotic = 'ceftriaxone'\n",
    "# list of unique mic values (leaving nan values)\n",
    "mic_values_uniq = matrix[antibiotic].loc[matrix[antibiotic]>0].sort_values().unique()\n",
    "# list of MIC values\n",
    "mic_values = matrix[antibiotic].loc[matrix[antibiotic]>0].values\n",
    "# by definition we need to reshape the list of mics\n",
    "mic_reshape = np.reshape(mic_values,(-1,1))\n",
    "# define encoder function\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# transform data from numerical cat to onehot code\n",
    "mic_onehot = encoder.fit_transform(mic_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'active_features_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-726817bcb163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmic_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'active_features_'"
     ]
    }
   ],
   "source": [
    "# A two-fold dilution reduces the concentration of a solution\n",
    "# by a factor of two that is reduces the original concentration by one half. \n",
    "# A series of two-fold dilutions is described as two-fold serial dilutions.\n",
    "\n",
    "# The accuracy within +/-1 2-fold dilution step of the laboratory-derived MIC.\n",
    "\n",
    "# The utility of AMR diagnostic devices is often described in terms of error rate. Major\n",
    "# errors (MEs) are defined as susceptible genomes that have been incorrectly assigned\n",
    "# resistant MICs by the model. Very major errors (VMEs) are defined as resistant genomes\n",
    "# that have been incorrectly assigned susceptible MICs by the model. FDA standards for\n",
    "# automated systems recommend a major error rate of < 3% (54). All antibiotics used in\n",
    "# the model had ME rates within this range (Table 2). The FDA standards for VME rates\n",
    "# indicate that the lower 95% confidence limit should be < 1.5% and that the upper limit\n",
    "# should be <7.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features input (X) and the target output (y) variables\n",
    "X = matrix.loc[matrix[antibiotic]>0].values[:,0:136]\n",
    "y = mic_onehot\n",
    "# Split into the training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We standardize the input samples\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network for classification\n",
    "\n",
    "# If we use more and more layers we get overfit, so we have to balance the network. \n",
    "# Anyway, during training we always save the best model only,\n",
    "# so if there is overfit we just save the best one\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(136, ), activation='relu', name='input'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(mic_onehot.shape[1], activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit with a validation method in order to test overfit, also we checkpoint the best model for later test\n",
    "\n",
    "# Overvit can be found when the train loss is small but validation loss is big\n",
    "\n",
    "filepath=\"cnn_class_mic.h5\"\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=50, verbose=1, min_delta=1e-7)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, verbose=1, patience=20, min_lr=0.000000001)\n",
    "callbacks=[reduce_lr, checkpoint, earlystopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9822 - accuracy: 0.4219\n",
      "Epoch 00001: val_loss improved from inf to 1.42730, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7601 - accuracy: 0.5656 - val_loss: 1.4273 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3426 - accuracy: 0.7734\n",
      "Epoch 00002: val_loss improved from 1.42730 to 0.80049, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1493 - accuracy: 0.8098 - val_loss: 0.8005 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7259 - accuracy: 0.8828\n",
      "Epoch 00003: val_loss improved from 0.80049 to 0.66501, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8762 - accuracy: 0.8680 - val_loss: 0.6650 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7505 - accuracy: 0.8828\n",
      "Epoch 00004: val_loss improved from 0.66501 to 0.61707, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7607 - accuracy: 0.8697 - val_loss: 0.6171 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6555 - accuracy: 0.8594\n",
      "Epoch 00005: val_loss improved from 0.61707 to 0.60945, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6686 - accuracy: 0.8697 - val_loss: 0.6094 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5863 - accuracy: 0.8672\n",
      "Epoch 00006: val_loss improved from 0.60945 to 0.58270, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6452 - accuracy: 0.8697 - val_loss: 0.5827 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7179 - accuracy: 0.8672\n",
      "Epoch 00007: val_loss improved from 0.58270 to 0.56564, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6114 - accuracy: 0.8697 - val_loss: 0.5656 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7012 - accuracy: 0.8438\n",
      "Epoch 00008: val_loss improved from 0.56564 to 0.55725, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5587 - accuracy: 0.8697 - val_loss: 0.5572 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5959 - accuracy: 0.8594\n",
      "Epoch 00009: val_loss improved from 0.55725 to 0.55293, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5750 - accuracy: 0.8697 - val_loss: 0.5529 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5574 - accuracy: 0.8594\n",
      "Epoch 00010: val_loss did not improve from 0.55293\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.8697 - val_loss: 0.5567 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3722 - accuracy: 0.9219\n",
      "Epoch 00011: val_loss improved from 0.55293 to 0.54675, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5334 - accuracy: 0.8697 - val_loss: 0.5467 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4462 - accuracy: 0.8906\n",
      "Epoch 00012: val_loss improved from 0.54675 to 0.54117, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5196 - accuracy: 0.8697 - val_loss: 0.5412 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4457 - accuracy: 0.8828\n",
      "Epoch 00013: val_loss did not improve from 0.54117\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5141 - accuracy: 0.8697 - val_loss: 0.5439 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4782 - accuracy: 0.8750\n",
      "Epoch 00014: val_loss improved from 0.54117 to 0.53892, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8697 - val_loss: 0.5389 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3614 - accuracy: 0.8984\n",
      "Epoch 00015: val_loss improved from 0.53892 to 0.53669, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4957 - accuracy: 0.8697 - val_loss: 0.5367 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4242 - accuracy: 0.9062\n",
      "Epoch 00016: val_loss improved from 0.53669 to 0.53386, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4861 - accuracy: 0.8697 - val_loss: 0.5339 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4890 - accuracy: 0.8828\n",
      "Epoch 00017: val_loss improved from 0.53386 to 0.53105, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4733 - accuracy: 0.8697 - val_loss: 0.5310 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4685 - accuracy: 0.8516\n",
      "Epoch 00018: val_loss improved from 0.53105 to 0.52736, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4609 - accuracy: 0.8697 - val_loss: 0.5274 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3341 - accuracy: 0.9219\n",
      "Epoch 00019: val_loss did not improve from 0.52736\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.8697 - val_loss: 0.5335 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4720 - accuracy: 0.8672\n",
      "Epoch 00020: val_loss improved from 0.52736 to 0.52624, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4471 - accuracy: 0.8697 - val_loss: 0.5262 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5333 - accuracy: 0.8438\n",
      "Epoch 00021: val_loss did not improve from 0.52624\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.8697 - val_loss: 0.5290 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5662 - accuracy: 0.8359\n",
      "Epoch 00022: val_loss did not improve from 0.52624\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8697 - val_loss: 0.5282 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2592 - accuracy: 0.9219\n",
      "Epoch 00023: val_loss improved from 0.52624 to 0.52149, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.8697 - val_loss: 0.5215 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4030 - accuracy: 0.8516\n",
      "Epoch 00024: val_loss improved from 0.52149 to 0.52008, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.8697 - val_loss: 0.5201 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7344 - accuracy: 0.7812\n",
      "Epoch 00025: val_loss did not improve from 0.52008\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8697 - val_loss: 0.5268 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5530 - accuracy: 0.8359\n",
      "Epoch 00026: val_loss improved from 0.52008 to 0.51570, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8697 - val_loss: 0.5157 - val_accuracy: 0.8662 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8828\n",
      "Epoch 00027: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8697 - val_loss: 0.5178 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3852 - accuracy: 0.8594\n",
      "Epoch 00028: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8697 - val_loss: 0.5264 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4066 - accuracy: 0.8438\n",
      "Epoch 00029: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8697 - val_loss: 0.5353 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4084 - accuracy: 0.8516\n",
      "Epoch 00030: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8697 - val_loss: 0.5251 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3083 - accuracy: 0.8984\n",
      "Epoch 00031: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8697 - val_loss: 0.5314 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4573 - accuracy: 0.8438\n",
      "Epoch 00032: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8697 - val_loss: 0.5334 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4382 - accuracy: 0.8438\n",
      "Epoch 00033: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8697 - val_loss: 0.5410 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3430 - accuracy: 0.8906\n",
      "Epoch 00034: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8697 - val_loss: 0.5426 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3490 - accuracy: 0.8828\n",
      "Epoch 00035: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8697 - val_loss: 0.5498 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2807 - accuracy: 0.8984\n",
      "Epoch 00036: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8697 - val_loss: 0.5610 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2337 - accuracy: 0.9219\n",
      "Epoch 00037: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8697 - val_loss: 0.5662 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4750 - accuracy: 0.8438\n",
      "Epoch 00038: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8697 - val_loss: 0.5675 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9219\n",
      "Epoch 00039: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8697 - val_loss: 0.5800 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2869 - accuracy: 0.8906\n",
      "Epoch 00040: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8697 - val_loss: 0.5785 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3693 - accuracy: 0.8438\n",
      "Epoch 00041: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.8697 - val_loss: 0.5986 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4043 - accuracy: 0.8203\n",
      "Epoch 00042: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8697 - val_loss: 0.6255 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3064 - accuracy: 0.8828\n",
      "Epoch 00043: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3385 - accuracy: 0.8697 - val_loss: 0.6228 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2837 - accuracy: 0.8750\n",
      "Epoch 00044: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8697 - val_loss: 0.6278 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2639 - accuracy: 0.8828\n",
      "Epoch 00045: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8697 - val_loss: 0.6529 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2727 - accuracy: 0.8906\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8697 - val_loss: 0.6517 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2825 - accuracy: 0.8906\n",
      "Epoch 00047: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.8705 - val_loss: 0.6553 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3177 - accuracy: 0.8516\n",
      "Epoch 00048: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8713 - val_loss: 0.6711 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3042 - accuracy: 0.8594\n",
      "Epoch 00049: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3038 - accuracy: 0.8713 - val_loss: 0.6729 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2701 - accuracy: 0.8750\n",
      "Epoch 00050: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2939 - accuracy: 0.8713 - val_loss: 0.6863 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1718 - accuracy: 0.9219\n",
      "Epoch 00051: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.8713 - val_loss: 0.7077 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2450 - accuracy: 0.8828\n",
      "Epoch 00052: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2947 - accuracy: 0.8713 - val_loss: 0.6963 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2601 - accuracy: 0.8828\n",
      "Epoch 00053: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2948 - accuracy: 0.8713 - val_loss: 0.7194 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2935 - accuracy: 0.8594\n",
      "Epoch 00054: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2887 - accuracy: 0.8738 - val_loss: 0.7320 - val_accuracy: 0.8662 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3710 - accuracy: 0.8516\n",
      "Epoch 00055: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.8746 - val_loss: 0.7320 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3733 - accuracy: 0.8359\n",
      "Epoch 00056: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2872 - accuracy: 0.8754 - val_loss: 0.7258 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3926 - accuracy: 0.8438\n",
      "Epoch 00057: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2907 - accuracy: 0.8762 - val_loss: 0.7467 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2402 - accuracy: 0.8984\n",
      "Epoch 00058: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8770 - val_loss: 0.7461 - val_accuracy: 0.8681 - lr: 5.0000e-04\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3926 - accuracy: 0.8359\n",
      "Epoch 00059: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8754 - val_loss: 0.7743 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2642 - accuracy: 0.8828\n",
      "Epoch 00060: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2846 - accuracy: 0.8754 - val_loss: 0.7953 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4423 - accuracy: 0.8047\n",
      "Epoch 00061: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.8795 - val_loss: 0.7901 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2969 - accuracy: 0.8516\n",
      "Epoch 00062: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.8787 - val_loss: 0.8028 - val_accuracy: 0.8642 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2449 - accuracy: 0.8984\n",
      "Epoch 00063: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2788 - accuracy: 0.8820 - val_loss: 0.7961 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2786 - accuracy: 0.8828\n",
      "Epoch 00064: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2745 - accuracy: 0.8795 - val_loss: 0.8276 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2180 - accuracy: 0.9062\n",
      "Epoch 00065: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2759 - accuracy: 0.8811 - val_loss: 0.8232 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2936 - accuracy: 0.8750\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.8795 - val_loss: 0.8354 - val_accuracy: 0.8642 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2786 - accuracy: 0.8906\n",
      "Epoch 00067: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.8795 - val_loss: 0.8465 - val_accuracy: 0.8662 - lr: 2.5000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2331 - accuracy: 0.8984\n",
      "Epoch 00068: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2713 - accuracy: 0.8836 - val_loss: 0.8601 - val_accuracy: 0.8662 - lr: 2.5000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3042 - accuracy: 0.8828\n",
      "Epoch 00069: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2710 - accuracy: 0.8828 - val_loss: 0.8638 - val_accuracy: 0.8662 - lr: 2.5000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1990 - accuracy: 0.9062\n",
      "Epoch 00070: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.8820 - val_loss: 0.8846 - val_accuracy: 0.8681 - lr: 2.5000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2371 - accuracy: 0.9219\n",
      "Epoch 00071: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.8852 - val_loss: 0.8830 - val_accuracy: 0.8681 - lr: 2.5000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2887 - accuracy: 0.8828\n",
      "Epoch 00072: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.8836 - val_loss: 0.8762 - val_accuracy: 0.8662 - lr: 2.5000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3122 - accuracy: 0.8672\n",
      "Epoch 00073: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.8844 - val_loss: 0.8823 - val_accuracy: 0.8681 - lr: 2.5000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2068 - accuracy: 0.9062\n",
      "Epoch 00074: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2614 - accuracy: 0.8844 - val_loss: 0.8877 - val_accuracy: 0.8681 - lr: 2.5000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3129 - accuracy: 0.8594\n",
      "Epoch 00075: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2619 - accuracy: 0.8852 - val_loss: 0.8865 - val_accuracy: 0.8681 - lr: 2.5000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2959 - accuracy: 0.8516\n",
      "Epoch 00076: val_loss did not improve from 0.51570\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.8885 - val_loss: 0.8948 - val_accuracy: 0.8662 - lr: 2.5000e-04\n",
      "Epoch 00076: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=4000, batch_size=128, validation_split=0.3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, we can visualize the history of the model fit \n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and test the predictions.\n",
    "model_from_file = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.96 0.   0.   0.   0.   0.01 0.01 0.02 0.  ]\n",
      " [1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.95 0.   0.   0.   0.   0.01 0.02 0.02 0.  ]\n",
      " [0.77 0.   0.01 0.   0.01 0.05 0.09 0.06 0.01]\n",
      " [0.31 0.05 0.06 0.03 0.06 0.12 0.16 0.13 0.07]\n",
      " [0.97 0.   0.   0.   0.   0.   0.01 0.01 0.  ]\n",
      " [0.99 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.98 0.   0.   0.   0.   0.   0.01 0.01 0.  ]\n",
      " [0.97 0.   0.   0.   0.   0.01 0.01 0.01 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])\n",
    "pred = model_from_file.predict(X_train[:10])\n",
    "print(np.round_(pred, decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8707864880561829, 0, 0, 0, 0, 0, 0.1666666716337204, 0.75, 1.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat X_test and y_test\n",
    "pd.DataFrame(X_test)\n",
    "pd.DataFrame(y_test)\n",
    "test_data = pd.concat([pd.DataFrame(X_test),pd.DataFrame(mic_reshape)], axis=1, join='inner')\n",
    "test_data_enc = pd.concat([pd.DataFrame(X_test),pd.DataFrame(y_test)], axis=1, join='inner')\n",
    "    \n",
    "accuracy = []\n",
    "for mic in mic_values_uniq:\n",
    "    X_test_class = test_data.loc[test_data.iloc[:,136]==mic].iloc[:,0:136].to_numpy()\n",
    "    if len(X_test_class)!=0:\n",
    "        y_test_class = test_data_enc.loc[test_data.iloc[:,136]==mic].iloc[:,136:145].to_numpy()\n",
    "        scores = model_from_file.evaluate(X_test_class, y_test_class, verbose=0)\n",
    "        accuracy.append(scores[1])\n",
    "    else:\n",
    "        accuracy.append(0)\n",
    "        \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar chart showing the number of genomes with the same antibiotic MIC values\n",
    "\n",
    "# Set the width and height of the figure\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Avarage accuracy of the MIC Prediction Model\")\n",
    "\n",
    "# Bar chart showing average arrival delay for Spirit Airlines flights by month\n",
    "sns.barplot(x=mic_values, y=accuracy)\n",
    "\n",
    "# Add label for vertical axis\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "[0.02 0.04 0.   0.   0.94 0.19 0.55 0.27 0.   0.   0.   0.   0.   0.\n",
      " 1.   0.17 0.56 0.27 0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "# ROC plot\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = model.predict(X_test).flatten()\n",
    "\n",
    "print(y_test_flat[:20])\n",
    "print(np.round_(y_pred_flat[:20], decimals = 2))\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test.flat, y_pred_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8702572005526624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('cnn class ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.81\n",
      "accuracy: 67.30%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model_from_file.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f\" % (model_from_file.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model_from_file.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.04\n",
      "accuracy: 57.22%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model_from_file.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f\" % (model_from_file.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model_from_file.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9802 - accuracy: 0.3359\n",
      "Epoch 00001: val_loss improved from inf to 1.40990, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 1.7445 - accuracy: 0.5697 - val_loss: 1.4099 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2172 - accuracy: 0.8594\n",
      "Epoch 00002: val_loss improved from 1.40990 to 0.83855, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1071 - accuracy: 0.8451 - val_loss: 0.8385 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1970 - accuracy: 0.8438\n",
      "Epoch 00003: val_loss improved from 0.83855 to 0.68873, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9036 - accuracy: 0.8689 - val_loss: 0.6887 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8981 - accuracy: 0.8672\n",
      "Epoch 00004: val_loss improved from 0.68873 to 0.60796, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7615 - accuracy: 0.8697 - val_loss: 0.6080 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8547 - accuracy: 0.8594\n",
      "Epoch 00005: val_loss improved from 0.60796 to 0.59989, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7168 - accuracy: 0.8697 - val_loss: 0.5999 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8613 - accuracy: 0.7969\n",
      "Epoch 00006: val_loss improved from 0.59989 to 0.57704, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.8697 - val_loss: 0.5770 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6452 - accuracy: 0.8438\n",
      "Epoch 00007: val_loss improved from 0.57704 to 0.55899, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.8697 - val_loss: 0.5590 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5615 - accuracy: 0.8984\n",
      "Epoch 00008: val_loss improved from 0.55899 to 0.55527, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5926 - accuracy: 0.8697 - val_loss: 0.5553 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4775 - accuracy: 0.8906\n",
      "Epoch 00009: val_loss improved from 0.55527 to 0.55433, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5768 - accuracy: 0.8697 - val_loss: 0.5543 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5842 - accuracy: 0.8281\n",
      "Epoch 00010: val_loss did not improve from 0.55433\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.8697 - val_loss: 0.5568 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5793 - accuracy: 0.8828\n",
      "Epoch 00011: val_loss improved from 0.55433 to 0.54355, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5426 - accuracy: 0.8697 - val_loss: 0.5435 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5499 - accuracy: 0.8594\n",
      "Epoch 00012: val_loss improved from 0.54355 to 0.53697, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5346 - accuracy: 0.8697 - val_loss: 0.5370 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5327 - accuracy: 0.8594\n",
      "Epoch 00013: val_loss improved from 0.53697 to 0.53517, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5129 - accuracy: 0.8697 - val_loss: 0.5352 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5491 - accuracy: 0.8594\n",
      "Epoch 00014: val_loss improved from 0.53517 to 0.53214, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5341 - accuracy: 0.8697 - val_loss: 0.5321 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5088 - accuracy: 0.8750\n",
      "Epoch 00015: val_loss did not improve from 0.53214\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.8697 - val_loss: 0.5395 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5139 - accuracy: 0.8594\n",
      "Epoch 00016: val_loss improved from 0.53214 to 0.52142, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4896 - accuracy: 0.8697 - val_loss: 0.5214 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5075 - accuracy: 0.8594\n",
      "Epoch 00017: val_loss did not improve from 0.52142\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.8697 - val_loss: 0.5262 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4432 - accuracy: 0.8750\n",
      "Epoch 00018: val_loss did not improve from 0.52142\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8697 - val_loss: 0.5335 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3535 - accuracy: 0.8906\n",
      "Epoch 00019: val_loss did not improve from 0.52142\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.8697 - val_loss: 0.5259 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4320 - accuracy: 0.8594\n",
      "Epoch 00020: val_loss improved from 0.52142 to 0.51924, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4562 - accuracy: 0.8697 - val_loss: 0.5192 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3832 - accuracy: 0.8750\n",
      "Epoch 00021: val_loss did not improve from 0.51924\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.8697 - val_loss: 0.5204 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4636 - accuracy: 0.8516\n",
      "Epoch 00022: val_loss did not improve from 0.51924\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.8697 - val_loss: 0.5250 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4130 - accuracy: 0.8750\n",
      "Epoch 00023: val_loss improved from 0.51924 to 0.51398, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.8697 - val_loss: 0.5140 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3578 - accuracy: 0.8984\n",
      "Epoch 00024: val_loss improved from 0.51398 to 0.51382, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8697 - val_loss: 0.5138 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4445 - accuracy: 0.8672\n",
      "Epoch 00025: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8697 - val_loss: 0.5330 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3321 - accuracy: 0.8984\n",
      "Epoch 00026: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8697 - val_loss: 0.5236 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4653 - accuracy: 0.8594\n",
      "Epoch 00027: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8697 - val_loss: 0.5224 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3541 - accuracy: 0.8906\n",
      "Epoch 00028: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8697 - val_loss: 0.5263 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4204 - accuracy: 0.8438\n",
      "Epoch 00029: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8697 - val_loss: 0.5258 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2744 - accuracy: 0.9062\n",
      "Epoch 00030: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8697 - val_loss: 0.5265 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3504 - accuracy: 0.8906\n",
      "Epoch 00031: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8697 - val_loss: 0.5261 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4691 - accuracy: 0.8125\n",
      "Epoch 00032: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8697 - val_loss: 0.5257 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3860 - accuracy: 0.8750\n",
      "Epoch 00033: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8697 - val_loss: 0.5324 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4183 - accuracy: 0.8672\n",
      "Epoch 00034: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8697 - val_loss: 0.5261 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2972 - accuracy: 0.8984\n",
      "Epoch 00035: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8697 - val_loss: 0.5339 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3577 - accuracy: 0.8750\n",
      "Epoch 00036: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.8697 - val_loss: 0.5440 - val_accuracy: 0.8681 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3276 - accuracy: 0.8906\n",
      "Epoch 00037: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8697 - val_loss: 0.5521 - val_accuracy: 0.8681 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3739 - accuracy: 0.8516\n",
      "Epoch 00038: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8697 - val_loss: 0.5593 - val_accuracy: 0.8681 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3796 - accuracy: 0.8672\n",
      "Epoch 00039: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8697 - val_loss: 0.5722 - val_accuracy: 0.8681 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3719 - accuracy: 0.8672\n",
      "Epoch 00040: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3517 - accuracy: 0.8697 - val_loss: 0.5794 - val_accuracy: 0.8681 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3663 - accuracy: 0.8438\n",
      "Epoch 00041: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3494 - accuracy: 0.8697 - val_loss: 0.5793 - val_accuracy: 0.8719 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2556 - accuracy: 0.9062\n",
      "Epoch 00042: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8705 - val_loss: 0.5854 - val_accuracy: 0.8719 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8828\n",
      "Epoch 00043: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8713 - val_loss: 0.5978 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2949 - accuracy: 0.8750\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8705 - val_loss: 0.5902 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3994 - accuracy: 0.8281\n",
      "Epoch 00045: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8713 - val_loss: 0.6028 - val_accuracy: 0.8815 - lr: 5.0000e-04\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4115 - accuracy: 0.8359\n",
      "Epoch 00046: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8713 - val_loss: 0.6147 - val_accuracy: 0.8815 - lr: 5.0000e-04\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3126 - accuracy: 0.8672\n",
      "Epoch 00047: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3292 - accuracy: 0.8705 - val_loss: 0.6169 - val_accuracy: 0.8815 - lr: 5.0000e-04\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3740 - accuracy: 0.8281\n",
      "Epoch 00048: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3169 - accuracy: 0.8721 - val_loss: 0.6248 - val_accuracy: 0.8815 - lr: 5.0000e-04\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2283 - accuracy: 0.9141\n",
      "Epoch 00049: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8730 - val_loss: 0.6370 - val_accuracy: 0.8815 - lr: 5.0000e-04\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3439 - accuracy: 0.8672\n",
      "Epoch 00050: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3185 - accuracy: 0.8738 - val_loss: 0.6319 - val_accuracy: 0.8795 - lr: 5.0000e-04\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3850 - accuracy: 0.8359\n",
      "Epoch 00051: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8754 - val_loss: 0.6386 - val_accuracy: 0.8795 - lr: 5.0000e-04\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3224 - accuracy: 0.8672\n",
      "Epoch 00052: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.8738 - val_loss: 0.6612 - val_accuracy: 0.8795 - lr: 5.0000e-04\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2636 - accuracy: 0.8906\n",
      "Epoch 00053: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3047 - accuracy: 0.8746 - val_loss: 0.6631 - val_accuracy: 0.8776 - lr: 5.0000e-04\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8438\n",
      "Epoch 00054: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8762 - val_loss: 0.6593 - val_accuracy: 0.8795 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2539 - accuracy: 0.8906\n",
      "Epoch 00055: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3055 - accuracy: 0.8738 - val_loss: 0.6691 - val_accuracy: 0.8795 - lr: 5.0000e-04\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2977 - accuracy: 0.8828\n",
      "Epoch 00056: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3025 - accuracy: 0.8779 - val_loss: 0.6841 - val_accuracy: 0.8795 - lr: 5.0000e-04\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2320 - accuracy: 0.9062\n",
      "Epoch 00057: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.8811 - val_loss: 0.6951 - val_accuracy: 0.8776 - lr: 5.0000e-04\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2882 - accuracy: 0.8750\n",
      "Epoch 00058: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.8770 - val_loss: 0.6952 - val_accuracy: 0.8776 - lr: 5.0000e-04\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3254 - accuracy: 0.8594\n",
      "Epoch 00059: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8787 - val_loss: 0.7033 - val_accuracy: 0.8776 - lr: 5.0000e-04\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3123 - accuracy: 0.8750\n",
      "Epoch 00060: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2942 - accuracy: 0.8770 - val_loss: 0.7118 - val_accuracy: 0.8776 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3351 - accuracy: 0.8594\n",
      "Epoch 00061: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2880 - accuracy: 0.8828 - val_loss: 0.7342 - val_accuracy: 0.8776 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2960 - accuracy: 0.8750\n",
      "Epoch 00062: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.8803 - val_loss: 0.7514 - val_accuracy: 0.8795 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3355 - accuracy: 0.8359\n",
      "Epoch 00063: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2801 - accuracy: 0.8828 - val_loss: 0.7488 - val_accuracy: 0.8815 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3191 - accuracy: 0.8516\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8828 - val_loss: 0.7666 - val_accuracy: 0.8795 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3097 - accuracy: 0.8672\n",
      "Epoch 00065: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.8828 - val_loss: 0.7618 - val_accuracy: 0.8776 - lr: 2.5000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3813 - accuracy: 0.8516\n",
      "Epoch 00066: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8811 - val_loss: 0.7644 - val_accuracy: 0.8757 - lr: 2.5000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3017 - accuracy: 0.8516\n",
      "Epoch 00067: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2792 - accuracy: 0.8852 - val_loss: 0.7766 - val_accuracy: 0.8776 - lr: 2.5000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1641 - accuracy: 0.9375\n",
      "Epoch 00068: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2800 - accuracy: 0.8852 - val_loss: 0.7865 - val_accuracy: 0.8795 - lr: 2.5000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2770 - accuracy: 0.8906\n",
      "Epoch 00069: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.8844 - val_loss: 0.7938 - val_accuracy: 0.8776 - lr: 2.5000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3231 - accuracy: 0.8594\n",
      "Epoch 00070: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2723 - accuracy: 0.8885 - val_loss: 0.7903 - val_accuracy: 0.8776 - lr: 2.5000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2171 - accuracy: 0.9062\n",
      "Epoch 00071: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2718 - accuracy: 0.8811 - val_loss: 0.7939 - val_accuracy: 0.8776 - lr: 2.5000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2083 - accuracy: 0.9219\n",
      "Epoch 00072: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.8869 - val_loss: 0.7954 - val_accuracy: 0.8757 - lr: 2.5000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2243 - accuracy: 0.8984\n",
      "Epoch 00073: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2693 - accuracy: 0.8836 - val_loss: 0.8048 - val_accuracy: 0.8757 - lr: 2.5000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2355 - accuracy: 0.8984\n",
      "Epoch 00074: val_loss did not improve from 0.51382\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2713 - accuracy: 0.8852 - val_loss: 0.8167 - val_accuracy: 0.8757 - lr: 2.5000e-04\n",
      "Epoch 00074: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.0586 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from inf to 1.89134, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.9781 - accuracy: 0.0566 - val_loss: 1.8913 - val_accuracy: 0.3174 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9297 - accuracy: 0.1484\n",
      "Epoch 00002: val_loss improved from 1.89134 to 1.76601, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.8585 - accuracy: 0.2008 - val_loss: 1.7660 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7656 - accuracy: 0.2969\n",
      "Epoch 00003: val_loss improved from 1.76601 to 1.51071, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.6978 - accuracy: 0.4090 - val_loss: 1.5107 - val_accuracy: 0.6099 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5835 - accuracy: 0.5391\n",
      "Epoch 00004: val_loss improved from 1.51071 to 1.25659, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.4910 - accuracy: 0.5262 - val_loss: 1.2566 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4446 - accuracy: 0.5469\n",
      "Epoch 00005: val_loss improved from 1.25659 to 1.11797, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3160 - accuracy: 0.5344 - val_loss: 1.1180 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2460 - accuracy: 0.5156\n",
      "Epoch 00006: val_loss improved from 1.11797 to 1.05451, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2397 - accuracy: 0.5287 - val_loss: 1.0545 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1958 - accuracy: 0.5000\n",
      "Epoch 00007: val_loss improved from 1.05451 to 1.00332, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1312 - accuracy: 0.5336 - val_loss: 1.0033 - val_accuracy: 0.6138 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0818 - accuracy: 0.5156\n",
      "Epoch 00008: val_loss improved from 1.00332 to 0.97795, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1042 - accuracy: 0.5238 - val_loss: 0.9779 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1179 - accuracy: 0.5156\n",
      "Epoch 00009: val_loss improved from 0.97795 to 0.94867, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0648 - accuracy: 0.5410 - val_loss: 0.9487 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1110 - accuracy: 0.5156\n",
      "Epoch 00010: val_loss improved from 0.94867 to 0.93097, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0415 - accuracy: 0.5410 - val_loss: 0.9310 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8919 - accuracy: 0.6406\n",
      "Epoch 00011: val_loss improved from 0.93097 to 0.92734, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0121 - accuracy: 0.5303 - val_loss: 0.9273 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0273 - accuracy: 0.5625\n",
      "Epoch 00012: val_loss improved from 0.92734 to 0.91061, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.0014 - accuracy: 0.5377 - val_loss: 0.9106 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0994 - accuracy: 0.5469\n",
      "Epoch 00013: val_loss improved from 0.91061 to 0.89337, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9765 - accuracy: 0.5320 - val_loss: 0.8934 - val_accuracy: 0.6214 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9442 - accuracy: 0.5234\n",
      "Epoch 00014: val_loss improved from 0.89337 to 0.88221, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9528 - accuracy: 0.5336 - val_loss: 0.8822 - val_accuracy: 0.6272 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9102 - accuracy: 0.5547\n",
      "Epoch 00015: val_loss improved from 0.88221 to 0.87920, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9543 - accuracy: 0.5549 - val_loss: 0.8792 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9359 - accuracy: 0.5547\n",
      "Epoch 00016: val_loss improved from 0.87920 to 0.87029, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9334 - accuracy: 0.5418 - val_loss: 0.8703 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8815 - accuracy: 0.5938\n",
      "Epoch 00017: val_loss did not improve from 0.87029\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9344 - accuracy: 0.5648 - val_loss: 0.8743 - val_accuracy: 0.6654 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8803 - accuracy: 0.5781\n",
      "Epoch 00018: val_loss improved from 0.87029 to 0.84764, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9032 - accuracy: 0.5680 - val_loss: 0.8476 - val_accuracy: 0.6386 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8897 - accuracy: 0.5859\n",
      "Epoch 00019: val_loss did not improve from 0.84764\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8924 - accuracy: 0.5623 - val_loss: 0.8520 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8982 - accuracy: 0.5781\n",
      "Epoch 00020: val_loss improved from 0.84764 to 0.84140, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8887 - accuracy: 0.5754 - val_loss: 0.8414 - val_accuracy: 0.6788 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8137 - accuracy: 0.6406\n",
      "Epoch 00021: val_loss did not improve from 0.84140\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8878 - accuracy: 0.5861 - val_loss: 0.8466 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9507 - accuracy: 0.6016\n",
      "Epoch 00022: val_loss improved from 0.84140 to 0.84098, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8796 - accuracy: 0.6066 - val_loss: 0.8410 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9493 - accuracy: 0.5781\n",
      "Epoch 00023: val_loss improved from 0.84098 to 0.82937, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8600 - accuracy: 0.6025 - val_loss: 0.8294 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9498 - accuracy: 0.5625\n",
      "Epoch 00024: val_loss did not improve from 0.82937\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8449 - accuracy: 0.6041 - val_loss: 0.8371 - val_accuracy: 0.6922 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8583 - accuracy: 0.6406\n",
      "Epoch 00025: val_loss improved from 0.82937 to 0.82590, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8360 - accuracy: 0.6082 - val_loss: 0.8259 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8523 - accuracy: 0.5859\n",
      "Epoch 00026: val_loss did not improve from 0.82590\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7991 - accuracy: 0.6418 - val_loss: 0.8279 - val_accuracy: 0.6788 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7526 - accuracy: 0.6484\n",
      "Epoch 00027: val_loss did not improve from 0.82590\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8074 - accuracy: 0.6443 - val_loss: 0.8269 - val_accuracy: 0.6673 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7994 - accuracy: 0.6953\n",
      "Epoch 00028: val_loss improved from 0.82590 to 0.81313, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8230 - accuracy: 0.6484 - val_loss: 0.8131 - val_accuracy: 0.6826 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8222 - accuracy: 0.6953\n",
      "Epoch 00029: val_loss did not improve from 0.81313\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7853 - accuracy: 0.6623 - val_loss: 0.8161 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8147 - accuracy: 0.6797\n",
      "Epoch 00030: val_loss improved from 0.81313 to 0.81014, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7696 - accuracy: 0.6656 - val_loss: 0.8101 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8973 - accuracy: 0.6484\n",
      "Epoch 00031: val_loss improved from 0.81014 to 0.81014, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7739 - accuracy: 0.6639 - val_loss: 0.8101 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6903 - accuracy: 0.6719\n",
      "Epoch 00032: val_loss improved from 0.81014 to 0.79979, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7509 - accuracy: 0.6631 - val_loss: 0.7998 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8722 - accuracy: 0.6250\n",
      "Epoch 00033: val_loss did not improve from 0.79979\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7563 - accuracy: 0.6746 - val_loss: 0.8073 - val_accuracy: 0.6845 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6251 - accuracy: 0.7578\n",
      "Epoch 00034: val_loss improved from 0.79979 to 0.79669, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7295 - accuracy: 0.6910 - val_loss: 0.7967 - val_accuracy: 0.6902 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6763 - accuracy: 0.7500\n",
      "Epoch 00035: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7390 - accuracy: 0.6984 - val_loss: 0.8023 - val_accuracy: 0.6692 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7262 - accuracy: 0.6797\n",
      "Epoch 00036: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7040 - accuracy: 0.6869 - val_loss: 0.7978 - val_accuracy: 0.6922 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7154 - accuracy: 0.6875\n",
      "Epoch 00037: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7300 - accuracy: 0.6861 - val_loss: 0.8008 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6149 - accuracy: 0.7500\n",
      "Epoch 00038: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7043 - accuracy: 0.6992 - val_loss: 0.8035 - val_accuracy: 0.6902 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6621 - accuracy: 0.7266\n",
      "Epoch 00039: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6747 - accuracy: 0.7074 - val_loss: 0.8032 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6734 - accuracy: 0.7422\n",
      "Epoch 00040: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6855 - accuracy: 0.7115 - val_loss: 0.8164 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6965 - accuracy: 0.7656\n",
      "Epoch 00041: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6826 - accuracy: 0.7164 - val_loss: 0.8035 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7460 - accuracy: 0.6562\n",
      "Epoch 00042: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.7287 - val_loss: 0.8019 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5592 - accuracy: 0.7578\n",
      "Epoch 00043: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.7352 - val_loss: 0.8074 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5996 - accuracy: 0.7734\n",
      "Epoch 00044: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.7328 - val_loss: 0.7996 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6158 - accuracy: 0.7422\n",
      "Epoch 00045: val_loss did not improve from 0.79669\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6448 - accuracy: 0.7311 - val_loss: 0.8096 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6442 - accuracy: 0.6953\n",
      "Epoch 00046: val_loss improved from 0.79669 to 0.79595, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6331 - accuracy: 0.7303 - val_loss: 0.7960 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5461 - accuracy: 0.7812\n",
      "Epoch 00047: val_loss did not improve from 0.79595\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6440 - accuracy: 0.7328 - val_loss: 0.8304 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7632 - accuracy: 0.6875\n",
      "Epoch 00048: val_loss improved from 0.79595 to 0.78633, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6321 - accuracy: 0.7492 - val_loss: 0.7863 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4363 - accuracy: 0.8359\n",
      "Epoch 00049: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6190 - accuracy: 0.7525 - val_loss: 0.8251 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6269 - accuracy: 0.6953\n",
      "Epoch 00050: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.7500 - val_loss: 0.8229 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6821 - accuracy: 0.7031\n",
      "Epoch 00051: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6110 - accuracy: 0.7557 - val_loss: 0.8325 - val_accuracy: 0.6788 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5741 - accuracy: 0.7891\n",
      "Epoch 00052: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6011 - accuracy: 0.7689 - val_loss: 0.8033 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6919 - accuracy: 0.7031\n",
      "Epoch 00053: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5930 - accuracy: 0.7607 - val_loss: 0.7999 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6749 - accuracy: 0.7344\n",
      "Epoch 00054: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5645 - accuracy: 0.7721 - val_loss: 0.8262 - val_accuracy: 0.6922 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6063 - accuracy: 0.7266\n",
      "Epoch 00055: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5896 - accuracy: 0.7680 - val_loss: 0.7994 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4615 - accuracy: 0.8203\n",
      "Epoch 00056: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5557 - accuracy: 0.7762 - val_loss: 0.8498 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4345 - accuracy: 0.8438\n",
      "Epoch 00057: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7795 - val_loss: 0.8291 - val_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4406 - accuracy: 0.8281\n",
      "Epoch 00058: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7902 - val_loss: 0.8524 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5231 - accuracy: 0.7891\n",
      "Epoch 00059: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7959 - val_loss: 0.8701 - val_accuracy: 0.6960 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5096 - accuracy: 0.7891\n",
      "Epoch 00060: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7869 - val_loss: 0.8688 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4742 - accuracy: 0.8281\n",
      "Epoch 00061: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.8025 - val_loss: 0.8512 - val_accuracy: 0.6922 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4930 - accuracy: 0.7891\n",
      "Epoch 00062: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7943 - val_loss: 0.8430 - val_accuracy: 0.6902 - lr: 0.0010\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5781 - accuracy: 0.7969\n",
      "Epoch 00063: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7943 - val_loss: 0.9016 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6472 - accuracy: 0.7109\n",
      "Epoch 00064: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7787 - val_loss: 0.8331 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4772 - accuracy: 0.8047\n",
      "Epoch 00065: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.8033 - val_loss: 0.8751 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4664 - accuracy: 0.8516\n",
      "Epoch 00066: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.8082 - val_loss: 0.8706 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5205 - accuracy: 0.7812\n",
      "Epoch 00067: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.8066 - val_loss: 0.8851 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4743 - accuracy: 0.8203\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.8082 - val_loss: 0.8938 - val_accuracy: 0.6902 - lr: 0.0010\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3894 - accuracy: 0.8516\n",
      "Epoch 00069: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.8287 - val_loss: 0.8950 - val_accuracy: 0.6979 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5183 - accuracy: 0.7812\n",
      "Epoch 00070: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.8172 - val_loss: 0.9107 - val_accuracy: 0.7036 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3894 - accuracy: 0.8438\n",
      "Epoch 00071: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.8180 - val_loss: 0.9023 - val_accuracy: 0.6998 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4391 - accuracy: 0.8203\n",
      "Epoch 00072: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8254 - val_loss: 0.9090 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4546 - accuracy: 0.7969\n",
      "Epoch 00073: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8254 - val_loss: 0.9019 - val_accuracy: 0.7075 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3851 - accuracy: 0.8516\n",
      "Epoch 00074: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.8205 - val_loss: 0.9011 - val_accuracy: 0.7075 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4338 - accuracy: 0.8828\n",
      "Epoch 00075: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8467 - val_loss: 0.9182 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3746 - accuracy: 0.8750\n",
      "Epoch 00076: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.8295 - val_loss: 0.9329 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3766 - accuracy: 0.8516\n",
      "Epoch 00077: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.8508 - val_loss: 0.9443 - val_accuracy: 0.7113 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4045 - accuracy: 0.8594\n",
      "Epoch 00078: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.8311 - val_loss: 0.9164 - val_accuracy: 0.7094 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4176 - accuracy: 0.8438\n",
      "Epoch 00079: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8451 - val_loss: 0.9371 - val_accuracy: 0.7094 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3916 - accuracy: 0.8594\n",
      "Epoch 00080: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8402 - val_loss: 0.9092 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4636 - accuracy: 0.8359\n",
      "Epoch 00081: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8426 - val_loss: 0.9591 - val_accuracy: 0.7075 - lr: 5.0000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3291 - accuracy: 0.8594\n",
      "Epoch 00082: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8541 - val_loss: 0.9442 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4576 - accuracy: 0.8047\n",
      "Epoch 00083: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8320 - val_loss: 0.9386 - val_accuracy: 0.7036 - lr: 5.0000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3751 - accuracy: 0.8750\n",
      "Epoch 00084: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8541 - val_loss: 0.9767 - val_accuracy: 0.7189 - lr: 5.0000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3550 - accuracy: 0.8516\n",
      "Epoch 00085: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8467 - val_loss: 0.9730 - val_accuracy: 0.7113 - lr: 5.0000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4359 - accuracy: 0.8438\n",
      "Epoch 00086: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8541 - val_loss: 0.9727 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3712 - accuracy: 0.8984\n",
      "Epoch 00087: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8459 - val_loss: 0.9810 - val_accuracy: 0.7036 - lr: 5.0000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4282 - accuracy: 0.8672\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4068 - accuracy: 0.8533 - val_loss: 1.0174 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 89/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3176 - accuracy: 0.9062\n",
      "Epoch 00089: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3874 - accuracy: 0.8549 - val_loss: 1.0279 - val_accuracy: 0.7113 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3108 - accuracy: 0.8906\n",
      "Epoch 00090: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8566 - val_loss: 1.0226 - val_accuracy: 0.7055 - lr: 2.5000e-04\n",
      "Epoch 91/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3064 - accuracy: 0.9062\n",
      "Epoch 00091: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3648 - accuracy: 0.8672 - val_loss: 1.0105 - val_accuracy: 0.7132 - lr: 2.5000e-04\n",
      "Epoch 92/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8672\n",
      "Epoch 00092: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8582 - val_loss: 1.0093 - val_accuracy: 0.7170 - lr: 2.5000e-04\n",
      "Epoch 93/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3761 - accuracy: 0.8438\n",
      "Epoch 00093: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8648 - val_loss: 1.0226 - val_accuracy: 0.7036 - lr: 2.5000e-04\n",
      "Epoch 94/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4295 - accuracy: 0.8359\n",
      "Epoch 00094: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8639 - val_loss: 1.0028 - val_accuracy: 0.7170 - lr: 2.5000e-04\n",
      "Epoch 95/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3587 - accuracy: 0.8750\n",
      "Epoch 00095: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8664 - val_loss: 1.0501 - val_accuracy: 0.7055 - lr: 2.5000e-04\n",
      "Epoch 96/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2913 - accuracy: 0.9141\n",
      "Epoch 00096: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8779 - val_loss: 1.0288 - val_accuracy: 0.7132 - lr: 2.5000e-04\n",
      "Epoch 97/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4735 - accuracy: 0.8203\n",
      "Epoch 00097: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8738 - val_loss: 1.0443 - val_accuracy: 0.7132 - lr: 2.5000e-04\n",
      "Epoch 98/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4196 - accuracy: 0.8438\n",
      "Epoch 00098: val_loss did not improve from 0.78633\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8656 - val_loss: 1.0301 - val_accuracy: 0.7132 - lr: 2.5000e-04\n",
      "Epoch 00098: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9807 - accuracy: 0.2031\n",
      "Epoch 00001: val_loss improved from inf to 1.41287, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 1.7688 - accuracy: 0.3943 - val_loss: 1.4129 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3773 - accuracy: 0.7656\n",
      "Epoch 00002: val_loss improved from 1.41287 to 0.96616, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.2959 - accuracy: 0.7762 - val_loss: 0.9662 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1406 - accuracy: 0.8125\n",
      "Epoch 00003: val_loss improved from 0.96616 to 0.79560, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0157 - accuracy: 0.8197 - val_loss: 0.7956 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0057 - accuracy: 0.8281\n",
      "Epoch 00004: val_loss improved from 0.79560 to 0.73526, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9089 - accuracy: 0.8213 - val_loss: 0.7353 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7573 - accuracy: 0.8203\n",
      "Epoch 00005: val_loss improved from 0.73526 to 0.70420, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7872 - accuracy: 0.8205 - val_loss: 0.7042 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7398 - accuracy: 0.7969\n",
      "Epoch 00006: val_loss improved from 0.70420 to 0.65488, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7205 - accuracy: 0.8213 - val_loss: 0.6549 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5072 - accuracy: 0.8906\n",
      "Epoch 00007: val_loss improved from 0.65488 to 0.61925, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7035 - accuracy: 0.8197 - val_loss: 0.6192 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7381 - accuracy: 0.8047\n",
      "Epoch 00008: val_loss improved from 0.61925 to 0.60378, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6655 - accuracy: 0.8230 - val_loss: 0.6038 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6869 - accuracy: 0.8047\n",
      "Epoch 00009: val_loss improved from 0.60378 to 0.58734, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6237 - accuracy: 0.8180 - val_loss: 0.5873 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6661 - accuracy: 0.8203\n",
      "Epoch 00010: val_loss improved from 0.58734 to 0.58603, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6114 - accuracy: 0.8213 - val_loss: 0.5860 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6400 - accuracy: 0.7969\n",
      "Epoch 00011: val_loss improved from 0.58603 to 0.58252, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5912 - accuracy: 0.8197 - val_loss: 0.5825 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6974 - accuracy: 0.7969\n",
      "Epoch 00012: val_loss did not improve from 0.58252\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5730 - accuracy: 0.8180 - val_loss: 0.5826 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4774 - accuracy: 0.8438\n",
      "Epoch 00013: val_loss did not improve from 0.58252\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.8205 - val_loss: 0.5891 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6503 - accuracy: 0.7812\n",
      "Epoch 00014: val_loss did not improve from 0.58252\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5708 - accuracy: 0.8205 - val_loss: 0.5905 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6387 - accuracy: 0.7578\n",
      "Epoch 00015: val_loss did not improve from 0.58252\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.8197 - val_loss: 0.5865 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5501 - accuracy: 0.8281\n",
      "Epoch 00016: val_loss improved from 0.58252 to 0.57849, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5213 - accuracy: 0.8197 - val_loss: 0.5785 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5635 - accuracy: 0.8203\n",
      "Epoch 00017: val_loss did not improve from 0.57849\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.8197 - val_loss: 0.5849 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5707 - accuracy: 0.8125\n",
      "Epoch 00018: val_loss did not improve from 0.57849\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5234 - accuracy: 0.8213 - val_loss: 0.5788 - val_accuracy: 0.8413 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5177 - accuracy: 0.8047\n",
      "Epoch 00019: val_loss did not improve from 0.57849\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.8213 - val_loss: 0.5826 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5048 - accuracy: 0.8125\n",
      "Epoch 00020: val_loss did not improve from 0.57849\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5106 - accuracy: 0.8221 - val_loss: 0.5819 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4538 - accuracy: 0.8516\n",
      "Epoch 00021: val_loss did not improve from 0.57849\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.8221 - val_loss: 0.5795 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5961 - accuracy: 0.8047\n",
      "Epoch 00022: val_loss improved from 0.57849 to 0.57158, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5029 - accuracy: 0.8189 - val_loss: 0.5716 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5033 - accuracy: 0.8281\n",
      "Epoch 00023: val_loss did not improve from 0.57158\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.8221 - val_loss: 0.5830 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4267 - accuracy: 0.8281\n",
      "Epoch 00024: val_loss did not improve from 0.57158\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.8197 - val_loss: 0.5816 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5269 - accuracy: 0.7891\n",
      "Epoch 00025: val_loss did not improve from 0.57158\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.8221 - val_loss: 0.5774 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4961 - accuracy: 0.8281\n",
      "Epoch 00026: val_loss did not improve from 0.57158\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.8213 - val_loss: 0.5745 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5696 - accuracy: 0.7578\n",
      "Epoch 00027: val_loss did not improve from 0.57158\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.8213 - val_loss: 0.5761 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5100 - accuracy: 0.7891\n",
      "Epoch 00028: val_loss improved from 0.57158 to 0.56543, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4600 - accuracy: 0.8221 - val_loss: 0.5654 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5514 - accuracy: 0.7969\n",
      "Epoch 00029: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.8221 - val_loss: 0.5699 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5088 - accuracy: 0.8047\n",
      "Epoch 00030: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.8197 - val_loss: 0.5791 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4204 - accuracy: 0.8047\n",
      "Epoch 00031: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.8230 - val_loss: 0.5749 - val_accuracy: 0.8413 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5186 - accuracy: 0.7734\n",
      "Epoch 00032: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8230 - val_loss: 0.5745 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5077 - accuracy: 0.7812\n",
      "Epoch 00033: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8205 - val_loss: 0.5670 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2741 - accuracy: 0.9141\n",
      "Epoch 00034: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.8221 - val_loss: 0.5734 - val_accuracy: 0.8451 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5663 - accuracy: 0.8125\n",
      "Epoch 00035: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8221 - val_loss: 0.5723 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3926 - accuracy: 0.8750\n",
      "Epoch 00036: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8246 - val_loss: 0.5740 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4313 - accuracy: 0.8359\n",
      "Epoch 00037: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8254 - val_loss: 0.5738 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4277 - accuracy: 0.7812\n",
      "Epoch 00038: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8221 - val_loss: 0.5791 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4018 - accuracy: 0.8516\n",
      "Epoch 00039: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8311 - val_loss: 0.5765 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3684 - accuracy: 0.8672\n",
      "Epoch 00040: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8311 - val_loss: 0.5738 - val_accuracy: 0.8470 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4809 - accuracy: 0.7891\n",
      "Epoch 00041: val_loss did not improve from 0.56543\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8311 - val_loss: 0.5837 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3981 - accuracy: 0.8203\n",
      "Epoch 00042: val_loss improved from 0.56543 to 0.56515, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8328 - val_loss: 0.5651 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3630 - accuracy: 0.8359\n",
      "Epoch 00043: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8303 - val_loss: 0.5883 - val_accuracy: 0.8394 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3908 - accuracy: 0.8359\n",
      "Epoch 00044: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8279 - val_loss: 0.5784 - val_accuracy: 0.8451 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4581 - accuracy: 0.8047\n",
      "Epoch 00045: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8336 - val_loss: 0.5875 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3498 - accuracy: 0.8438\n",
      "Epoch 00046: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8393 - val_loss: 0.5857 - val_accuracy: 0.8470 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4737 - accuracy: 0.7812\n",
      "Epoch 00047: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8467 - val_loss: 0.5776 - val_accuracy: 0.8585 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5689 - accuracy: 0.7422\n",
      "Epoch 00048: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8352 - val_loss: 0.5827 - val_accuracy: 0.8547 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3601 - accuracy: 0.8594\n",
      "Epoch 00049: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8459 - val_loss: 0.6108 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3024 - accuracy: 0.8828\n",
      "Epoch 00050: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8459 - val_loss: 0.6209 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3744 - accuracy: 0.7891\n",
      "Epoch 00051: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8451 - val_loss: 0.5922 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2796 - accuracy: 0.8906\n",
      "Epoch 00052: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8566 - val_loss: 0.6157 - val_accuracy: 0.8547 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3608 - accuracy: 0.8594\n",
      "Epoch 00053: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3235 - accuracy: 0.8656 - val_loss: 0.6273 - val_accuracy: 0.8547 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2828 - accuracy: 0.9062\n",
      "Epoch 00054: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3246 - accuracy: 0.8664 - val_loss: 0.6289 - val_accuracy: 0.8375 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8672\n",
      "Epoch 00055: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8549 - val_loss: 0.6115 - val_accuracy: 0.8356 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3614 - accuracy: 0.8594\n",
      "Epoch 00056: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8500 - val_loss: 0.6862 - val_accuracy: 0.8375 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8828\n",
      "Epoch 00057: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3243 - accuracy: 0.8623 - val_loss: 0.6281 - val_accuracy: 0.8394 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2411 - accuracy: 0.8750\n",
      "Epoch 00058: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3072 - accuracy: 0.8713 - val_loss: 0.6424 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3267 - accuracy: 0.8516\n",
      "Epoch 00059: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3040 - accuracy: 0.8713 - val_loss: 0.6749 - val_accuracy: 0.8394 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3044 - accuracy: 0.8906\n",
      "Epoch 00060: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3041 - accuracy: 0.8811 - val_loss: 0.7003 - val_accuracy: 0.8394 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3733 - accuracy: 0.8047\n",
      "Epoch 00061: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3042 - accuracy: 0.8738 - val_loss: 0.6777 - val_accuracy: 0.8356 - lr: 0.0010\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2531 - accuracy: 0.8828\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3049 - accuracy: 0.8820 - val_loss: 0.6927 - val_accuracy: 0.8356 - lr: 0.0010\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2811 - accuracy: 0.8984\n",
      "Epoch 00063: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2807 - accuracy: 0.8885 - val_loss: 0.7007 - val_accuracy: 0.8375 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2655 - accuracy: 0.9062\n",
      "Epoch 00064: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.8893 - val_loss: 0.7166 - val_accuracy: 0.8413 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3405 - accuracy: 0.8750\n",
      "Epoch 00065: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2708 - accuracy: 0.8852 - val_loss: 0.7149 - val_accuracy: 0.8279 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3062 - accuracy: 0.8906\n",
      "Epoch 00066: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2570 - accuracy: 0.8926 - val_loss: 0.7153 - val_accuracy: 0.8317 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2482 - accuracy: 0.9062\n",
      "Epoch 00067: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2581 - accuracy: 0.8934 - val_loss: 0.7402 - val_accuracy: 0.8279 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2769 - accuracy: 0.8906\n",
      "Epoch 00068: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2626 - accuracy: 0.8869 - val_loss: 0.7247 - val_accuracy: 0.8337 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1786 - accuracy: 0.9375\n",
      "Epoch 00069: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2501 - accuracy: 0.8992 - val_loss: 0.7486 - val_accuracy: 0.8279 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2401 - accuracy: 0.8984\n",
      "Epoch 00070: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.9066 - val_loss: 0.7433 - val_accuracy: 0.8279 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2596 - accuracy: 0.9062\n",
      "Epoch 00071: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2325 - accuracy: 0.9098 - val_loss: 0.7449 - val_accuracy: 0.8279 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2365 - accuracy: 0.9141\n",
      "Epoch 00072: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.9016 - val_loss: 0.7532 - val_accuracy: 0.8222 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2700 - accuracy: 0.8906\n",
      "Epoch 00073: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2416 - accuracy: 0.9057 - val_loss: 0.7430 - val_accuracy: 0.8317 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2107 - accuracy: 0.9141\n",
      "Epoch 00074: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2271 - accuracy: 0.9164 - val_loss: 0.7733 - val_accuracy: 0.8279 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2381 - accuracy: 0.8984\n",
      "Epoch 00075: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2250 - accuracy: 0.9148 - val_loss: 0.7975 - val_accuracy: 0.8203 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2180 - accuracy: 0.9062\n",
      "Epoch 00076: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2307 - accuracy: 0.9164 - val_loss: 0.7935 - val_accuracy: 0.8260 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2154 - accuracy: 0.8984\n",
      "Epoch 00077: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2064 - accuracy: 0.9221 - val_loss: 0.8188 - val_accuracy: 0.8260 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2110 - accuracy: 0.8984\n",
      "Epoch 00078: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2057 - accuracy: 0.9230 - val_loss: 0.8518 - val_accuracy: 0.8031 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2479 - accuracy: 0.9141\n",
      "Epoch 00079: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2137 - accuracy: 0.9164 - val_loss: 0.8631 - val_accuracy: 0.8126 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2525 - accuracy: 0.9062\n",
      "Epoch 00080: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9246 - val_loss: 0.8841 - val_accuracy: 0.8069 - lr: 5.0000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1734 - accuracy: 0.9375\n",
      "Epoch 00081: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2099 - accuracy: 0.9180 - val_loss: 0.9188 - val_accuracy: 0.8164 - lr: 5.0000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1695 - accuracy: 0.9531\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.9262 - val_loss: 0.9112 - val_accuracy: 0.8011 - lr: 5.0000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1334 - accuracy: 0.9453\n",
      "Epoch 00083: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9328 - val_loss: 0.9103 - val_accuracy: 0.8069 - lr: 2.5000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2266 - accuracy: 0.9141\n",
      "Epoch 00084: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9385 - val_loss: 0.9114 - val_accuracy: 0.8126 - lr: 2.5000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2021 - accuracy: 0.9219\n",
      "Epoch 00085: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1990 - accuracy: 0.9270 - val_loss: 0.9324 - val_accuracy: 0.8222 - lr: 2.5000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1145 - accuracy: 0.9609\n",
      "Epoch 00086: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9393 - val_loss: 0.9446 - val_accuracy: 0.8145 - lr: 2.5000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2381 - accuracy: 0.9141\n",
      "Epoch 00087: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9336 - val_loss: 0.9538 - val_accuracy: 0.8184 - lr: 2.5000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2207 - accuracy: 0.9062\n",
      "Epoch 00088: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.9377 - val_loss: 0.9636 - val_accuracy: 0.8126 - lr: 2.5000e-04\n",
      "Epoch 89/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1532 - accuracy: 0.9297\n",
      "Epoch 00089: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9230 - val_loss: 0.9652 - val_accuracy: 0.8088 - lr: 2.5000e-04\n",
      "Epoch 90/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1827 - accuracy: 0.9297\n",
      "Epoch 00090: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9361 - val_loss: 0.9716 - val_accuracy: 0.8164 - lr: 2.5000e-04\n",
      "Epoch 91/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1950 - accuracy: 0.9375\n",
      "Epoch 00091: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9434 - val_loss: 0.9767 - val_accuracy: 0.8184 - lr: 2.5000e-04\n",
      "Epoch 92/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2175 - accuracy: 0.9062\n",
      "Epoch 00092: val_loss did not improve from 0.56515\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1789 - accuracy: 0.9328 - val_loss: 1.0062 - val_accuracy: 0.8145 - lr: 2.5000e-04\n",
      "Epoch 00092: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.0460 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from inf to 1.89551, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.9690 - accuracy: 0.1180 - val_loss: 1.8955 - val_accuracy: 0.4111 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.8938 - accuracy: 0.2422\n",
      "Epoch 00002: val_loss improved from 1.89551 to 1.82133, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.8534 - accuracy: 0.3697 - val_loss: 1.8213 - val_accuracy: 0.5105 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7615 - accuracy: 0.5469\n",
      "Epoch 00003: val_loss improved from 1.82133 to 1.74381, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.7635 - accuracy: 0.5074 - val_loss: 1.7438 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6161 - accuracy: 0.5703\n",
      "Epoch 00004: val_loss improved from 1.74381 to 1.68108, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6886 - accuracy: 0.5467 - val_loss: 1.6811 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.8324 - accuracy: 0.5078\n",
      "Epoch 00005: val_loss improved from 1.68108 to 1.62351, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6183 - accuracy: 0.5582 - val_loss: 1.6235 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5693 - accuracy: 0.5625\n",
      "Epoch 00006: val_loss improved from 1.62351 to 1.56769, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.5607 - accuracy: 0.5598 - val_loss: 1.5677 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5273 - accuracy: 0.5156\n",
      "Epoch 00007: val_loss improved from 1.56769 to 1.51740, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4974 - accuracy: 0.5590 - val_loss: 1.5174 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4495 - accuracy: 0.5625\n",
      "Epoch 00008: val_loss improved from 1.51740 to 1.47013, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4473 - accuracy: 0.5557 - val_loss: 1.4701 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3420 - accuracy: 0.6016\n",
      "Epoch 00009: val_loss improved from 1.47013 to 1.42648, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3934 - accuracy: 0.5590 - val_loss: 1.4265 - val_accuracy: 0.5335 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2504 - accuracy: 0.6172\n",
      "Epoch 00010: val_loss improved from 1.42648 to 1.38364, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3436 - accuracy: 0.5508 - val_loss: 1.3836 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2283 - accuracy: 0.6094\n",
      "Epoch 00011: val_loss improved from 1.38364 to 1.33677, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2832 - accuracy: 0.5574 - val_loss: 1.3368 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3333 - accuracy: 0.5156\n",
      "Epoch 00012: val_loss improved from 1.33677 to 1.29785, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2374 - accuracy: 0.5451 - val_loss: 1.2978 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3109 - accuracy: 0.5547\n",
      "Epoch 00013: val_loss improved from 1.29785 to 1.26581, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2214 - accuracy: 0.5566 - val_loss: 1.2658 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2417 - accuracy: 0.5625\n",
      "Epoch 00014: val_loss improved from 1.26581 to 1.24637, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1965 - accuracy: 0.5541 - val_loss: 1.2464 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1627 - accuracy: 0.5703\n",
      "Epoch 00015: val_loss improved from 1.24637 to 1.23121, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1681 - accuracy: 0.5574 - val_loss: 1.2312 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1302 - accuracy: 0.6016\n",
      "Epoch 00016: val_loss improved from 1.23121 to 1.22383, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1595 - accuracy: 0.5541 - val_loss: 1.2238 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0466 - accuracy: 0.6250\n",
      "Epoch 00017: val_loss improved from 1.22383 to 1.21421, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1441 - accuracy: 0.5623 - val_loss: 1.2142 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1569 - accuracy: 0.5469\n",
      "Epoch 00018: val_loss improved from 1.21421 to 1.20870, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1354 - accuracy: 0.5582 - val_loss: 1.2087 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2135 - accuracy: 0.4922\n",
      "Epoch 00019: val_loss improved from 1.20870 to 1.20472, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1350 - accuracy: 0.5615 - val_loss: 1.2047 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2339 - accuracy: 0.5234\n",
      "Epoch 00020: val_loss improved from 1.20472 to 1.20282, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1171 - accuracy: 0.5607 - val_loss: 1.2028 - val_accuracy: 0.5335 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0312 - accuracy: 0.6172\n",
      "Epoch 00021: val_loss improved from 1.20282 to 1.19663, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1128 - accuracy: 0.5615 - val_loss: 1.1966 - val_accuracy: 0.5315 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1362 - accuracy: 0.5625\n",
      "Epoch 00022: val_loss improved from 1.19663 to 1.18977, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1010 - accuracy: 0.5607 - val_loss: 1.1898 - val_accuracy: 0.5315 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0343 - accuracy: 0.5547\n",
      "Epoch 00023: val_loss improved from 1.18977 to 1.18743, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0923 - accuracy: 0.5598 - val_loss: 1.1874 - val_accuracy: 0.5411 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0236 - accuracy: 0.5781\n",
      "Epoch 00024: val_loss improved from 1.18743 to 1.17729, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0958 - accuracy: 0.5631 - val_loss: 1.1773 - val_accuracy: 0.5507 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0700 - accuracy: 0.5547\n",
      "Epoch 00025: val_loss did not improve from 1.17729\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0613 - accuracy: 0.5689 - val_loss: 1.1857 - val_accuracy: 0.5545 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1533 - accuracy: 0.5391\n",
      "Epoch 00026: val_loss improved from 1.17729 to 1.16639, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0729 - accuracy: 0.5639 - val_loss: 1.1664 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9432 - accuracy: 0.6484\n",
      "Epoch 00027: val_loss improved from 1.16639 to 1.16557, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0572 - accuracy: 0.5697 - val_loss: 1.1656 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0826 - accuracy: 0.5547\n",
      "Epoch 00028: val_loss did not improve from 1.16557\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0527 - accuracy: 0.5787 - val_loss: 1.1671 - val_accuracy: 0.5717 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0461 - accuracy: 0.6172\n",
      "Epoch 00029: val_loss improved from 1.16557 to 1.15942, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0386 - accuracy: 0.5852 - val_loss: 1.1594 - val_accuracy: 0.5717 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0703 - accuracy: 0.5938\n",
      "Epoch 00030: val_loss improved from 1.15942 to 1.15796, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0337 - accuracy: 0.5861 - val_loss: 1.1580 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9741 - accuracy: 0.5859\n",
      "Epoch 00031: val_loss improved from 1.15796 to 1.15559, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0272 - accuracy: 0.5902 - val_loss: 1.1556 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0862 - accuracy: 0.6250\n",
      "Epoch 00032: val_loss improved from 1.15559 to 1.14253, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0025 - accuracy: 0.5984 - val_loss: 1.1425 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9340 - accuracy: 0.6875\n",
      "Epoch 00033: val_loss improved from 1.14253 to 1.14213, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0036 - accuracy: 0.6098 - val_loss: 1.1421 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0419 - accuracy: 0.5469\n",
      "Epoch 00034: val_loss improved from 1.14213 to 1.13130, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0019 - accuracy: 0.5984 - val_loss: 1.1313 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9372 - accuracy: 0.6328\n",
      "Epoch 00035: val_loss did not improve from 1.13130\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9850 - accuracy: 0.6131 - val_loss: 1.1318 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0093 - accuracy: 0.5859\n",
      "Epoch 00036: val_loss improved from 1.13130 to 1.12169, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.9744 - accuracy: 0.6066 - val_loss: 1.1217 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0652 - accuracy: 0.6172\n",
      "Epoch 00037: val_loss did not improve from 1.12169\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9717 - accuracy: 0.6107 - val_loss: 1.1408 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9835 - accuracy: 0.6484\n",
      "Epoch 00038: val_loss did not improve from 1.12169\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9525 - accuracy: 0.6164 - val_loss: 1.1278 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0262 - accuracy: 0.5703\n",
      "Epoch 00039: val_loss did not improve from 1.12169\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9566 - accuracy: 0.6156 - val_loss: 1.1283 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8986 - accuracy: 0.6562\n",
      "Epoch 00040: val_loss did not improve from 1.12169\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9472 - accuracy: 0.6148 - val_loss: 1.1234 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8435 - accuracy: 0.6484\n",
      "Epoch 00041: val_loss did not improve from 1.12169\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9360 - accuracy: 0.6221 - val_loss: 1.1337 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8615 - accuracy: 0.6172\n",
      "Epoch 00042: val_loss improved from 1.12169 to 1.11769, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9179 - accuracy: 0.6205 - val_loss: 1.1177 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8647 - accuracy: 0.6562\n",
      "Epoch 00043: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9188 - accuracy: 0.6156 - val_loss: 1.1341 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9667 - accuracy: 0.5703\n",
      "Epoch 00044: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8970 - accuracy: 0.6254 - val_loss: 1.1548 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0057 - accuracy: 0.5859\n",
      "Epoch 00045: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8999 - accuracy: 0.6320 - val_loss: 1.1517 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8345 - accuracy: 0.6719\n",
      "Epoch 00046: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8775 - accuracy: 0.6385 - val_loss: 1.1532 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8489 - accuracy: 0.6328\n",
      "Epoch 00047: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8739 - accuracy: 0.6418 - val_loss: 1.1545 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8947 - accuracy: 0.6719\n",
      "Epoch 00048: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8853 - accuracy: 0.6205 - val_loss: 1.1447 - val_accuracy: 0.5755 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9666 - accuracy: 0.5703\n",
      "Epoch 00049: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8776 - accuracy: 0.6287 - val_loss: 1.1623 - val_accuracy: 0.5698 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8853 - accuracy: 0.6172\n",
      "Epoch 00050: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8806 - accuracy: 0.6352 - val_loss: 1.1364 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8024 - accuracy: 0.6641\n",
      "Epoch 00051: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8566 - accuracy: 0.6443 - val_loss: 1.1625 - val_accuracy: 0.5698 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8938 - accuracy: 0.6562\n",
      "Epoch 00052: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8591 - accuracy: 0.6402 - val_loss: 1.1588 - val_accuracy: 0.5889 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8455 - accuracy: 0.6797\n",
      "Epoch 00053: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8490 - accuracy: 0.6500 - val_loss: 1.1737 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8757 - accuracy: 0.6172\n",
      "Epoch 00054: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8414 - accuracy: 0.6434 - val_loss: 1.1521 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8767 - accuracy: 0.6562\n",
      "Epoch 00055: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8437 - accuracy: 0.6443 - val_loss: 1.1639 - val_accuracy: 0.5966 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8420 - accuracy: 0.6406\n",
      "Epoch 00056: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8331 - accuracy: 0.6475 - val_loss: 1.1775 - val_accuracy: 0.5966 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9269 - accuracy: 0.6328\n",
      "Epoch 00057: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8115 - accuracy: 0.6516 - val_loss: 1.1394 - val_accuracy: 0.5908 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7627 - accuracy: 0.6875\n",
      "Epoch 00058: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8215 - accuracy: 0.6615 - val_loss: 1.1648 - val_accuracy: 0.6004 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6834 - accuracy: 0.6953\n",
      "Epoch 00059: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7954 - accuracy: 0.6639 - val_loss: 1.2097 - val_accuracy: 0.5927 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7378 - accuracy: 0.6875\n",
      "Epoch 00060: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8008 - accuracy: 0.6664 - val_loss: 1.1853 - val_accuracy: 0.6004 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8515 - accuracy: 0.6094\n",
      "Epoch 00061: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8008 - accuracy: 0.6475 - val_loss: 1.1677 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7572 - accuracy: 0.7031\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7892 - accuracy: 0.6746 - val_loss: 1.2563 - val_accuracy: 0.6023 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7748 - accuracy: 0.6875\n",
      "Epoch 00063: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7827 - accuracy: 0.6713 - val_loss: 1.1860 - val_accuracy: 0.6004 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7899 - accuracy: 0.6484\n",
      "Epoch 00064: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7808 - accuracy: 0.6697 - val_loss: 1.1732 - val_accuracy: 0.6042 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8411 - accuracy: 0.6328\n",
      "Epoch 00065: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7585 - accuracy: 0.6615 - val_loss: 1.2094 - val_accuracy: 0.5966 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8904 - accuracy: 0.6016\n",
      "Epoch 00066: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7645 - accuracy: 0.6639 - val_loss: 1.2048 - val_accuracy: 0.5946 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6955 - accuracy: 0.6406\n",
      "Epoch 00067: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7516 - accuracy: 0.6770 - val_loss: 1.2342 - val_accuracy: 0.5946 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7454 - accuracy: 0.6719\n",
      "Epoch 00068: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7523 - accuracy: 0.6803 - val_loss: 1.2068 - val_accuracy: 0.5946 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7758 - accuracy: 0.6797\n",
      "Epoch 00069: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7472 - accuracy: 0.6811 - val_loss: 1.2318 - val_accuracy: 0.5985 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8393 - accuracy: 0.6328\n",
      "Epoch 00070: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7587 - accuracy: 0.6639 - val_loss: 1.2117 - val_accuracy: 0.5985 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8007 - accuracy: 0.6250\n",
      "Epoch 00071: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7342 - accuracy: 0.6746 - val_loss: 1.2425 - val_accuracy: 0.5966 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7704 - accuracy: 0.6797\n",
      "Epoch 00072: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7331 - accuracy: 0.6779 - val_loss: 1.2540 - val_accuracy: 0.6004 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8085 - accuracy: 0.6406\n",
      "Epoch 00073: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7348 - accuracy: 0.6795 - val_loss: 1.2297 - val_accuracy: 0.6099 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8087 - accuracy: 0.6406\n",
      "Epoch 00074: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7273 - accuracy: 0.6697 - val_loss: 1.2493 - val_accuracy: 0.5927 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7875 - accuracy: 0.6328\n",
      "Epoch 00075: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7141 - accuracy: 0.6811 - val_loss: 1.2496 - val_accuracy: 0.5946 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7039 - accuracy: 0.6953\n",
      "Epoch 00076: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7216 - accuracy: 0.6844 - val_loss: 1.2730 - val_accuracy: 0.5946 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7590 - accuracy: 0.6875\n",
      "Epoch 00077: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7179 - accuracy: 0.6762 - val_loss: 1.2665 - val_accuracy: 0.6004 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7472 - accuracy: 0.6484\n",
      "Epoch 00078: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7289 - accuracy: 0.6811 - val_loss: 1.2951 - val_accuracy: 0.6004 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8450 - accuracy: 0.6016\n",
      "Epoch 00079: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7387 - accuracy: 0.6639 - val_loss: 1.2543 - val_accuracy: 0.6042 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7132 - accuracy: 0.6172\n",
      "Epoch 00080: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7092 - accuracy: 0.6803 - val_loss: 1.3381 - val_accuracy: 0.5966 - lr: 5.0000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7538 - accuracy: 0.6719\n",
      "Epoch 00081: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7148 - accuracy: 0.6795 - val_loss: 1.2869 - val_accuracy: 0.5985 - lr: 5.0000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7698 - accuracy: 0.6797\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7127 - accuracy: 0.6787 - val_loss: 1.2820 - val_accuracy: 0.6023 - lr: 5.0000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8120 - accuracy: 0.6484\n",
      "Epoch 00083: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7035 - accuracy: 0.6951 - val_loss: 1.2943 - val_accuracy: 0.6023 - lr: 2.5000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6603 - accuracy: 0.6797\n",
      "Epoch 00084: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7211 - accuracy: 0.6803 - val_loss: 1.3126 - val_accuracy: 0.6080 - lr: 2.5000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6330 - accuracy: 0.7188\n",
      "Epoch 00085: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.6861 - val_loss: 1.3091 - val_accuracy: 0.6080 - lr: 2.5000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6005 - accuracy: 0.7500\n",
      "Epoch 00086: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.7033 - val_loss: 1.3141 - val_accuracy: 0.6023 - lr: 2.5000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7160 - accuracy: 0.6406\n",
      "Epoch 00087: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.6910 - val_loss: 1.3251 - val_accuracy: 0.6004 - lr: 2.5000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7573 - accuracy: 0.6562\n",
      "Epoch 00088: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6754 - accuracy: 0.6861 - val_loss: 1.3195 - val_accuracy: 0.5985 - lr: 2.5000e-04\n",
      "Epoch 89/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7272 - accuracy: 0.6484\n",
      "Epoch 00089: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.6803 - val_loss: 1.3181 - val_accuracy: 0.5946 - lr: 2.5000e-04\n",
      "Epoch 90/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5459 - accuracy: 0.7578\n",
      "Epoch 00090: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.6934 - val_loss: 1.3010 - val_accuracy: 0.6042 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6810 - accuracy: 0.7266\n",
      "Epoch 00091: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.6984 - val_loss: 1.3216 - val_accuracy: 0.6061 - lr: 2.5000e-04\n",
      "Epoch 92/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6761 - accuracy: 0.7031\n",
      "Epoch 00092: val_loss did not improve from 1.11769\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6713 - accuracy: 0.6926 - val_loss: 1.3386 - val_accuracy: 0.6023 - lr: 2.5000e-04\n",
      "Epoch 00092: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.8727 - accuracy: 0.1953\n",
      "Epoch 00001: val_loss improved from inf to 1.53100, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.6710 - accuracy: 0.2361 - val_loss: 1.5310 - val_accuracy: 0.3537 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5027 - accuracy: 0.3672\n",
      "Epoch 00002: val_loss improved from 1.53100 to 1.35308, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4194 - accuracy: 0.3582 - val_loss: 1.3531 - val_accuracy: 0.3786 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2854 - accuracy: 0.3672\n",
      "Epoch 00003: val_loss improved from 1.35308 to 1.11469, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2244 - accuracy: 0.3877 - val_loss: 1.1147 - val_accuracy: 0.5832 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1798 - accuracy: 0.4609\n",
      "Epoch 00004: val_loss improved from 1.11469 to 1.00022, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1060 - accuracy: 0.4992 - val_loss: 1.0002 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9934 - accuracy: 0.5625\n",
      "Epoch 00005: val_loss improved from 1.00022 to 0.98497, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0953 - accuracy: 0.5262 - val_loss: 0.9850 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0196 - accuracy: 0.5312\n",
      "Epoch 00006: val_loss improved from 0.98497 to 0.98404, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0355 - accuracy: 0.5328 - val_loss: 0.9840 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9899 - accuracy: 0.4844\n",
      "Epoch 00007: val_loss improved from 0.98404 to 0.96924, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0303 - accuracy: 0.5336 - val_loss: 0.9692 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1042 - accuracy: 0.5703\n",
      "Epoch 00008: val_loss improved from 0.96924 to 0.94927, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9968 - accuracy: 0.5623 - val_loss: 0.9493 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1410 - accuracy: 0.5781\n",
      "Epoch 00009: val_loss improved from 0.94927 to 0.93804, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9990 - accuracy: 0.5689 - val_loss: 0.9380 - val_accuracy: 0.5966 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0116 - accuracy: 0.6328\n",
      "Epoch 00010: val_loss improved from 0.93804 to 0.92244, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9638 - accuracy: 0.5885 - val_loss: 0.9224 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9754 - accuracy: 0.5312\n",
      "Epoch 00011: val_loss improved from 0.92244 to 0.92231, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9691 - accuracy: 0.5902 - val_loss: 0.9223 - val_accuracy: 0.6520 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9695 - accuracy: 0.5781\n",
      "Epoch 00012: val_loss improved from 0.92231 to 0.90592, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9465 - accuracy: 0.5844 - val_loss: 0.9059 - val_accuracy: 0.6558 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9348 - accuracy: 0.6328\n",
      "Epoch 00013: val_loss improved from 0.90592 to 0.88977, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9495 - accuracy: 0.5811 - val_loss: 0.8898 - val_accuracy: 0.6558 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8741 - accuracy: 0.6641\n",
      "Epoch 00014: val_loss improved from 0.88977 to 0.88815, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9466 - accuracy: 0.5943 - val_loss: 0.8881 - val_accuracy: 0.6558 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7946 - accuracy: 0.6562\n",
      "Epoch 00015: val_loss improved from 0.88815 to 0.86663, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9169 - accuracy: 0.6033 - val_loss: 0.8666 - val_accuracy: 0.6597 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7567 - accuracy: 0.6875\n",
      "Epoch 00016: val_loss improved from 0.86663 to 0.84848, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9108 - accuracy: 0.6213 - val_loss: 0.8485 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8477 - accuracy: 0.6094\n",
      "Epoch 00017: val_loss improved from 0.84848 to 0.84577, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8857 - accuracy: 0.6197 - val_loss: 0.8458 - val_accuracy: 0.6616 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8251 - accuracy: 0.6953\n",
      "Epoch 00018: val_loss improved from 0.84577 to 0.82828, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8715 - accuracy: 0.6418 - val_loss: 0.8283 - val_accuracy: 0.6597 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9307 - accuracy: 0.6328\n",
      "Epoch 00019: val_loss improved from 0.82828 to 0.81648, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8691 - accuracy: 0.6393 - val_loss: 0.8165 - val_accuracy: 0.6769 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8401 - accuracy: 0.6719\n",
      "Epoch 00020: val_loss improved from 0.81648 to 0.80350, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8630 - accuracy: 0.6475 - val_loss: 0.8035 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7897 - accuracy: 0.6641\n",
      "Epoch 00021: val_loss improved from 0.80350 to 0.79339, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8401 - accuracy: 0.6533 - val_loss: 0.7934 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7500 - accuracy: 0.6484\n",
      "Epoch 00022: val_loss improved from 0.79339 to 0.78564, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8337 - accuracy: 0.6541 - val_loss: 0.7856 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6973 - accuracy: 0.7188\n",
      "Epoch 00023: val_loss improved from 0.78564 to 0.78163, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7883 - accuracy: 0.6705 - val_loss: 0.7816 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7353 - accuracy: 0.7422\n",
      "Epoch 00024: val_loss improved from 0.78163 to 0.78111, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7927 - accuracy: 0.6770 - val_loss: 0.7811 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7460 - accuracy: 0.7188\n",
      "Epoch 00025: val_loss improved from 0.78111 to 0.76674, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7882 - accuracy: 0.6820 - val_loss: 0.7667 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7761 - accuracy: 0.6875\n",
      "Epoch 00026: val_loss improved from 0.76674 to 0.75592, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7683 - accuracy: 0.6934 - val_loss: 0.7559 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8522 - accuracy: 0.6797\n",
      "Epoch 00027: val_loss improved from 0.75592 to 0.75200, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7846 - accuracy: 0.6885 - val_loss: 0.7520 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7157 - accuracy: 0.7031\n",
      "Epoch 00028: val_loss improved from 0.75200 to 0.74863, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7516 - accuracy: 0.6975 - val_loss: 0.7486 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8021 - accuracy: 0.6953\n",
      "Epoch 00029: val_loss did not improve from 0.74863\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7545 - accuracy: 0.6959 - val_loss: 0.7633 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7172 - accuracy: 0.7031\n",
      "Epoch 00030: val_loss improved from 0.74863 to 0.74695, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7580 - accuracy: 0.6877 - val_loss: 0.7469 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8392 - accuracy: 0.6719\n",
      "Epoch 00031: val_loss improved from 0.74695 to 0.72984, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7330 - accuracy: 0.7107 - val_loss: 0.7298 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9079 - accuracy: 0.6328\n",
      "Epoch 00032: val_loss improved from 0.72984 to 0.72573, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7137 - accuracy: 0.7156 - val_loss: 0.7257 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7196 - accuracy: 0.7422\n",
      "Epoch 00033: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7121 - accuracy: 0.7197 - val_loss: 0.7434 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5978 - accuracy: 0.7578\n",
      "Epoch 00034: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6991 - accuracy: 0.7189 - val_loss: 0.7502 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5583 - accuracy: 0.7812\n",
      "Epoch 00035: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6737 - accuracy: 0.7279 - val_loss: 0.7393 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6504 - accuracy: 0.7109\n",
      "Epoch 00036: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.7361 - val_loss: 0.7340 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6006 - accuracy: 0.7656\n",
      "Epoch 00037: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6635 - accuracy: 0.7279 - val_loss: 0.7292 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6328 - accuracy: 0.7578\n",
      "Epoch 00038: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6591 - accuracy: 0.7393 - val_loss: 0.7274 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5981 - accuracy: 0.7734\n",
      "Epoch 00039: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6649 - accuracy: 0.7303 - val_loss: 0.7379 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5955 - accuracy: 0.7422\n",
      "Epoch 00040: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6435 - accuracy: 0.7492 - val_loss: 0.7294 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7587 - accuracy: 0.6953\n",
      "Epoch 00041: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6432 - accuracy: 0.7426 - val_loss: 0.7361 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6569 - accuracy: 0.7656\n",
      "Epoch 00042: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.7385 - val_loss: 0.7544 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6702 - accuracy: 0.7188\n",
      "Epoch 00043: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6306 - accuracy: 0.7393 - val_loss: 0.7422 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7449 - accuracy: 0.7031\n",
      "Epoch 00044: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6067 - accuracy: 0.7557 - val_loss: 0.7509 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5161 - accuracy: 0.7656\n",
      "Epoch 00045: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6105 - accuracy: 0.7508 - val_loss: 0.7475 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6519 - accuracy: 0.7031\n",
      "Epoch 00046: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6008 - accuracy: 0.7459 - val_loss: 0.7427 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5594 - accuracy: 0.7734\n",
      "Epoch 00047: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.7680 - val_loss: 0.7539 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6054 - accuracy: 0.7578\n",
      "Epoch 00048: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7607 - val_loss: 0.7795 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6076 - accuracy: 0.7656\n",
      "Epoch 00049: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.7484 - val_loss: 0.7473 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6698 - accuracy: 0.7422\n",
      "Epoch 00050: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.7623 - val_loss: 0.7466 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 51/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5359 - accuracy: 0.8047\n",
      "Epoch 00051: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.7656 - val_loss: 0.7688 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6520 - accuracy: 0.7344\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.7623 - val_loss: 0.7752 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5267 - accuracy: 0.7812\n",
      "Epoch 00053: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5607 - accuracy: 0.7705 - val_loss: 0.7609 - val_accuracy: 0.6998 - lr: 5.0000e-04\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4992 - accuracy: 0.7812\n",
      "Epoch 00054: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7697 - val_loss: 0.7651 - val_accuracy: 0.6979 - lr: 5.0000e-04\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6136 - accuracy: 0.7344\n",
      "Epoch 00055: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7779 - val_loss: 0.7640 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5768 - accuracy: 0.7812\n",
      "Epoch 00056: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7877 - val_loss: 0.7726 - val_accuracy: 0.7036 - lr: 5.0000e-04\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5225 - accuracy: 0.7969\n",
      "Epoch 00057: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.7738 - val_loss: 0.7701 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5172 - accuracy: 0.7969\n",
      "Epoch 00058: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7844 - val_loss: 0.7829 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4702 - accuracy: 0.8125\n",
      "Epoch 00059: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7852 - val_loss: 0.7874 - val_accuracy: 0.7017 - lr: 5.0000e-04\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3952 - accuracy: 0.8359\n",
      "Epoch 00060: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5155 - accuracy: 0.7918 - val_loss: 0.7848 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5603 - accuracy: 0.7734\n",
      "Epoch 00061: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.7861 - val_loss: 0.7931 - val_accuracy: 0.7189 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5232 - accuracy: 0.7969\n",
      "Epoch 00062: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7975 - val_loss: 0.7940 - val_accuracy: 0.7189 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4755 - accuracy: 0.7656\n",
      "Epoch 00063: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.7869 - val_loss: 0.8000 - val_accuracy: 0.7266 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3819 - accuracy: 0.8516\n",
      "Epoch 00064: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.8156 - val_loss: 0.8062 - val_accuracy: 0.7228 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4777 - accuracy: 0.7891\n",
      "Epoch 00065: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.8074 - val_loss: 0.8129 - val_accuracy: 0.7228 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5114 - accuracy: 0.8047\n",
      "Epoch 00066: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.8066 - val_loss: 0.8036 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5851 - accuracy: 0.7812\n",
      "Epoch 00067: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.8090 - val_loss: 0.8129 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4463 - accuracy: 0.8281\n",
      "Epoch 00068: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.8205 - val_loss: 0.8259 - val_accuracy: 0.7228 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4546 - accuracy: 0.8359\n",
      "Epoch 00069: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.8295 - val_loss: 0.8283 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4668 - accuracy: 0.8203\n",
      "Epoch 00070: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8180 - val_loss: 0.8348 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3669 - accuracy: 0.8672\n",
      "Epoch 00071: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8352 - val_loss: 0.8328 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4783 - accuracy: 0.8438\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.8246 - val_loss: 0.8473 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5172 - accuracy: 0.7891\n",
      "Epoch 00073: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8459 - val_loss: 0.8480 - val_accuracy: 0.7132 - lr: 2.5000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4341 - accuracy: 0.8594\n",
      "Epoch 00074: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8377 - val_loss: 0.8428 - val_accuracy: 0.7094 - lr: 2.5000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4448 - accuracy: 0.8125\n",
      "Epoch 00075: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.8451 - val_loss: 0.8438 - val_accuracy: 0.7189 - lr: 2.5000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4814 - accuracy: 0.8125\n",
      "Epoch 00076: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.8311 - val_loss: 0.8437 - val_accuracy: 0.7170 - lr: 2.5000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5556 - accuracy: 0.7500\n",
      "Epoch 00077: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.8443 - val_loss: 0.8604 - val_accuracy: 0.7170 - lr: 2.5000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4730 - accuracy: 0.8047\n",
      "Epoch 00078: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.8328 - val_loss: 0.8608 - val_accuracy: 0.7228 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4237 - accuracy: 0.8438\n",
      "Epoch 00079: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.8508 - val_loss: 0.8632 - val_accuracy: 0.7247 - lr: 2.5000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4965 - accuracy: 0.8125\n",
      "Epoch 00080: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.8598 - val_loss: 0.8624 - val_accuracy: 0.7228 - lr: 2.5000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4408 - accuracy: 0.8438\n",
      "Epoch 00081: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8426 - val_loss: 0.8664 - val_accuracy: 0.7266 - lr: 2.5000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4586 - accuracy: 0.8516\n",
      "Epoch 00082: val_loss did not improve from 0.72573\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.8467 - val_loss: 0.8676 - val_accuracy: 0.7170 - lr: 2.5000e-04\n",
      "Epoch 00082: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7615 - accuracy: 0.1875\n",
      "Epoch 00001: val_loss improved from inf to 1.48022, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 1.6629 - accuracy: 0.2287 - val_loss: 1.4802 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4916 - accuracy: 0.4062\n",
      "Epoch 00002: val_loss improved from 1.48022 to 1.13614, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3438 - accuracy: 0.4902 - val_loss: 1.1361 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1043 - accuracy: 0.6172\n",
      "Epoch 00003: val_loss improved from 1.13614 to 0.90190, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0876 - accuracy: 0.6123 - val_loss: 0.9019 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8954 - accuracy: 0.7266\n",
      "Epoch 00004: val_loss improved from 0.90190 to 0.82607, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0018 - accuracy: 0.6279 - val_loss: 0.8261 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9551 - accuracy: 0.5938\n",
      "Epoch 00005: val_loss improved from 0.82607 to 0.80925, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9515 - accuracy: 0.6230 - val_loss: 0.8093 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9733 - accuracy: 0.5703\n",
      "Epoch 00006: val_loss improved from 0.80925 to 0.79776, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9264 - accuracy: 0.6230 - val_loss: 0.7978 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8033 - accuracy: 0.6641\n",
      "Epoch 00007: val_loss improved from 0.79776 to 0.78708, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8722 - accuracy: 0.6598 - val_loss: 0.7871 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9222 - accuracy: 0.6875\n",
      "Epoch 00008: val_loss improved from 0.78708 to 0.77214, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8655 - accuracy: 0.6631 - val_loss: 0.7721 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8515 - accuracy: 0.6328\n",
      "Epoch 00009: val_loss improved from 0.77214 to 0.76928, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8327 - accuracy: 0.6762 - val_loss: 0.7693 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9007 - accuracy: 0.5938\n",
      "Epoch 00010: val_loss improved from 0.76928 to 0.75990, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8389 - accuracy: 0.6762 - val_loss: 0.7599 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9333 - accuracy: 0.6484\n",
      "Epoch 00011: val_loss improved from 0.75990 to 0.75941, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8313 - accuracy: 0.6730 - val_loss: 0.7594 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7336 - accuracy: 0.6797\n",
      "Epoch 00012: val_loss improved from 0.75941 to 0.75175, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8099 - accuracy: 0.6803 - val_loss: 0.7517 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8855 - accuracy: 0.7266\n",
      "Epoch 00013: val_loss did not improve from 0.75175\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8012 - accuracy: 0.6721 - val_loss: 0.7572 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7648 - accuracy: 0.7266\n",
      "Epoch 00014: val_loss did not improve from 0.75175\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7972 - accuracy: 0.6762 - val_loss: 0.7518 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7198 - accuracy: 0.7031\n",
      "Epoch 00015: val_loss did not improve from 0.75175\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7871 - accuracy: 0.6803 - val_loss: 0.7563 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8081 - accuracy: 0.6797\n",
      "Epoch 00016: val_loss improved from 0.75175 to 0.74671, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7887 - accuracy: 0.6820 - val_loss: 0.7467 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7167 - accuracy: 0.6953\n",
      "Epoch 00017: val_loss improved from 0.74671 to 0.73970, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7790 - accuracy: 0.6795 - val_loss: 0.7397 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8009 - accuracy: 0.6953\n",
      "Epoch 00018: val_loss did not improve from 0.73970\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7857 - accuracy: 0.6795 - val_loss: 0.7426 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8140 - accuracy: 0.6641\n",
      "Epoch 00019: val_loss did not improve from 0.73970\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7866 - accuracy: 0.6836 - val_loss: 0.7439 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7230 - accuracy: 0.6641\n",
      "Epoch 00020: val_loss improved from 0.73970 to 0.72528, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7743 - accuracy: 0.6754 - val_loss: 0.7253 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7421 - accuracy: 0.6953\n",
      "Epoch 00021: val_loss did not improve from 0.72528\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7482 - accuracy: 0.6861 - val_loss: 0.7278 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7745 - accuracy: 0.6250\n",
      "Epoch 00022: val_loss improved from 0.72528 to 0.72241, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7437 - accuracy: 0.6902 - val_loss: 0.7224 - val_accuracy: 0.7304 - lr: 0.0010\n",
      "Epoch 23/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7680 - accuracy: 0.6719\n",
      "Epoch 00023: val_loss did not improve from 0.72241\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7512 - accuracy: 0.6902 - val_loss: 0.7242 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6592 - accuracy: 0.7344\n",
      "Epoch 00024: val_loss did not improve from 0.72241\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7491 - accuracy: 0.6934 - val_loss: 0.7299 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7326 - accuracy: 0.7188\n",
      "Epoch 00025: val_loss improved from 0.72241 to 0.71732, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7267 - accuracy: 0.6902 - val_loss: 0.7173 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7227 - accuracy: 0.7109\n",
      "Epoch 00026: val_loss improved from 0.71732 to 0.70685, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7238 - accuracy: 0.7008 - val_loss: 0.7068 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7920 - accuracy: 0.6484\n",
      "Epoch 00027: val_loss improved from 0.70685 to 0.70533, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7327 - accuracy: 0.6975 - val_loss: 0.7053 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7859 - accuracy: 0.6953\n",
      "Epoch 00028: val_loss did not improve from 0.70533\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7221 - accuracy: 0.7066 - val_loss: 0.7060 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6232 - accuracy: 0.7812\n",
      "Epoch 00029: val_loss improved from 0.70533 to 0.70234, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7214 - accuracy: 0.7025 - val_loss: 0.7023 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7755 - accuracy: 0.6797\n",
      "Epoch 00030: val_loss improved from 0.70234 to 0.69722, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7106 - accuracy: 0.7098 - val_loss: 0.6972 - val_accuracy: 0.7495 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6829 - accuracy: 0.7266\n",
      "Epoch 00031: val_loss improved from 0.69722 to 0.69412, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7069 - accuracy: 0.7131 - val_loss: 0.6941 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6668 - accuracy: 0.7500\n",
      "Epoch 00032: val_loss did not improve from 0.69412\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.7270 - val_loss: 0.6987 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6609 - accuracy: 0.7344\n",
      "Epoch 00033: val_loss improved from 0.69412 to 0.69128, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6731 - accuracy: 0.7230 - val_loss: 0.6913 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6475 - accuracy: 0.7500\n",
      "Epoch 00034: val_loss improved from 0.69128 to 0.68014, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6752 - accuracy: 0.7213 - val_loss: 0.6801 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7072 - accuracy: 0.7656\n",
      "Epoch 00035: val_loss improved from 0.68014 to 0.67955, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6973 - accuracy: 0.7197 - val_loss: 0.6795 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6478 - accuracy: 0.7500\n",
      "Epoch 00036: val_loss did not improve from 0.67955\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6701 - accuracy: 0.7311 - val_loss: 0.6804 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6048 - accuracy: 0.7188\n",
      "Epoch 00037: val_loss improved from 0.67955 to 0.67287, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6835 - accuracy: 0.7180 - val_loss: 0.6729 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7821 - accuracy: 0.6797\n",
      "Epoch 00038: val_loss improved from 0.67287 to 0.66675, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6576 - accuracy: 0.7311 - val_loss: 0.6668 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6239 - accuracy: 0.7344\n",
      "Epoch 00039: val_loss did not improve from 0.66675\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.7246 - val_loss: 0.6701 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6983 - accuracy: 0.6641\n",
      "Epoch 00040: val_loss did not improve from 0.66675\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.7279 - val_loss: 0.6695 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6887 - accuracy: 0.7500\n",
      "Epoch 00041: val_loss did not improve from 0.66675\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6570 - accuracy: 0.7328 - val_loss: 0.6671 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4989 - accuracy: 0.8438\n",
      "Epoch 00042: val_loss improved from 0.66675 to 0.65574, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6421 - accuracy: 0.7344 - val_loss: 0.6557 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6795 - accuracy: 0.7266\n",
      "Epoch 00043: val_loss did not improve from 0.65574\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.7254 - val_loss: 0.6559 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5393 - accuracy: 0.7891\n",
      "Epoch 00044: val_loss improved from 0.65574 to 0.65119, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6397 - accuracy: 0.7459 - val_loss: 0.6512 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5345 - accuracy: 0.7891\n",
      "Epoch 00045: val_loss did not improve from 0.65119\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.7443 - val_loss: 0.6559 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6454 - accuracy: 0.7422\n",
      "Epoch 00046: val_loss improved from 0.65119 to 0.64825, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6125 - accuracy: 0.7475 - val_loss: 0.6482 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4406 - accuracy: 0.8594\n",
      "Epoch 00047: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.7508 - val_loss: 0.6575 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6216 - accuracy: 0.7422\n",
      "Epoch 00048: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.7598 - val_loss: 0.6514 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6176 - accuracy: 0.7500\n",
      "Epoch 00049: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7525 - val_loss: 0.6540 - val_accuracy: 0.7342 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6046 - accuracy: 0.8047\n",
      "Epoch 00050: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.7533 - val_loss: 0.6606 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6600 - accuracy: 0.7578\n",
      "Epoch 00051: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6048 - accuracy: 0.7525 - val_loss: 0.6614 - val_accuracy: 0.7342 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6479 - accuracy: 0.7422\n",
      "Epoch 00052: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.7574 - val_loss: 0.6530 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5334 - accuracy: 0.7969\n",
      "Epoch 00053: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5743 - accuracy: 0.7770 - val_loss: 0.6705 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4613 - accuracy: 0.8594\n",
      "Epoch 00054: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7787 - val_loss: 0.6593 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6562 - accuracy: 0.7344\n",
      "Epoch 00055: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.7762 - val_loss: 0.6692 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5358 - accuracy: 0.8047\n",
      "Epoch 00056: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5577 - accuracy: 0.7746 - val_loss: 0.6635 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5981 - accuracy: 0.7734\n",
      "Epoch 00057: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7770 - val_loss: 0.6688 - val_accuracy: 0.7342 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5657 - accuracy: 0.7734\n",
      "Epoch 00058: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7811 - val_loss: 0.6758 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5641 - accuracy: 0.7656\n",
      "Epoch 00059: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7910 - val_loss: 0.6872 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5883 - accuracy: 0.7656\n",
      "Epoch 00060: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7910 - val_loss: 0.6815 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5398 - accuracy: 0.8203\n",
      "Epoch 00061: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.8041 - val_loss: 0.6888 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5142 - accuracy: 0.8047\n",
      "Epoch 00062: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7943 - val_loss: 0.6862 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3854 - accuracy: 0.8750\n",
      "Epoch 00063: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7984 - val_loss: 0.7096 - val_accuracy: 0.7228 - lr: 0.0010\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5374 - accuracy: 0.7578\n",
      "Epoch 00064: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.8041 - val_loss: 0.6981 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4084 - accuracy: 0.8359\n",
      "Epoch 00065: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.8016 - val_loss: 0.7258 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5022 - accuracy: 0.8047\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.8000 - val_loss: 0.7115 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4657 - accuracy: 0.8047\n",
      "Epoch 00067: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.8057 - val_loss: 0.7197 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3769 - accuracy: 0.8906\n",
      "Epoch 00068: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.8016 - val_loss: 0.7162 - val_accuracy: 0.7113 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3818 - accuracy: 0.8828\n",
      "Epoch 00069: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.8238 - val_loss: 0.7207 - val_accuracy: 0.7247 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5600 - accuracy: 0.7656\n",
      "Epoch 00070: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.8189 - val_loss: 0.7369 - val_accuracy: 0.7247 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3687 - accuracy: 0.8516\n",
      "Epoch 00071: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8262 - val_loss: 0.7381 - val_accuracy: 0.7266 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4669 - accuracy: 0.7656\n",
      "Epoch 00072: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8205 - val_loss: 0.7463 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5091 - accuracy: 0.8047\n",
      "Epoch 00073: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.8254 - val_loss: 0.7482 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4006 - accuracy: 0.8047\n",
      "Epoch 00074: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8197 - val_loss: 0.7533 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4953 - accuracy: 0.7891\n",
      "Epoch 00075: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8410 - val_loss: 0.7619 - val_accuracy: 0.7266 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8750\n",
      "Epoch 00076: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.8279 - val_loss: 0.7753 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5138 - accuracy: 0.7734\n",
      "Epoch 00077: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.8221 - val_loss: 0.7767 - val_accuracy: 0.7113 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4240 - accuracy: 0.8203\n",
      "Epoch 00078: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8303 - val_loss: 0.7773 - val_accuracy: 0.7151 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4881 - accuracy: 0.8203\n",
      "Epoch 00079: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8508 - val_loss: 0.7750 - val_accuracy: 0.7361 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3491 - accuracy: 0.8672\n",
      "Epoch 00080: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8451 - val_loss: 0.7851 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3860 - accuracy: 0.8594\n",
      "Epoch 00081: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8451 - val_loss: 0.7925 - val_accuracy: 0.7189 - lr: 5.0000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3516 - accuracy: 0.8750\n",
      "Epoch 00082: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8525 - val_loss: 0.8047 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3855 - accuracy: 0.8516\n",
      "Epoch 00083: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8467 - val_loss: 0.8071 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3793 - accuracy: 0.8594\n",
      "Epoch 00084: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8426 - val_loss: 0.8179 - val_accuracy: 0.7228 - lr: 5.0000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4752 - accuracy: 0.8125\n",
      "Epoch 00085: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8443 - val_loss: 0.8119 - val_accuracy: 0.7285 - lr: 5.0000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4524 - accuracy: 0.8359\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8557 - val_loss: 0.8090 - val_accuracy: 0.7228 - lr: 5.0000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4567 - accuracy: 0.8516\n",
      "Epoch 00087: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8582 - val_loss: 0.8286 - val_accuracy: 0.7189 - lr: 2.5000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4093 - accuracy: 0.8359\n",
      "Epoch 00088: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8566 - val_loss: 0.8272 - val_accuracy: 0.7247 - lr: 2.5000e-04\n",
      "Epoch 89/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8672\n",
      "Epoch 00089: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8574 - val_loss: 0.8442 - val_accuracy: 0.7189 - lr: 2.5000e-04\n",
      "Epoch 90/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2857 - accuracy: 0.8672\n",
      "Epoch 00090: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8525 - val_loss: 0.8464 - val_accuracy: 0.7323 - lr: 2.5000e-04\n",
      "Epoch 91/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3452 - accuracy: 0.8359\n",
      "Epoch 00091: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8475 - val_loss: 0.8572 - val_accuracy: 0.7285 - lr: 2.5000e-04\n",
      "Epoch 92/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3790 - accuracy: 0.8516\n",
      "Epoch 00092: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8557 - val_loss: 0.8584 - val_accuracy: 0.7304 - lr: 2.5000e-04\n",
      "Epoch 93/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3721 - accuracy: 0.8594\n",
      "Epoch 00093: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8590 - val_loss: 0.8532 - val_accuracy: 0.7304 - lr: 2.5000e-04\n",
      "Epoch 94/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3280 - accuracy: 0.8828\n",
      "Epoch 00094: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8639 - val_loss: 0.8555 - val_accuracy: 0.7323 - lr: 2.5000e-04\n",
      "Epoch 95/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3767 - accuracy: 0.8516\n",
      "Epoch 00095: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8623 - val_loss: 0.8696 - val_accuracy: 0.7285 - lr: 2.5000e-04\n",
      "Epoch 96/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3944 - accuracy: 0.8359\n",
      "Epoch 00096: val_loss did not improve from 0.64825\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8615 - val_loss: 0.8730 - val_accuracy: 0.7285 - lr: 2.5000e-04\n",
      "Epoch 00096: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.0000 - accuracy: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 1.59238, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7571 - accuracy: 0.0049 - val_loss: 1.5924 - val_accuracy: 0.0784 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6363 - accuracy: 0.0156\n",
      "Epoch 00002: val_loss improved from 1.59238 to 1.56440, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6013 - accuracy: 0.0926 - val_loss: 1.5644 - val_accuracy: 0.5163 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5826 - accuracy: 0.2656\n",
      "Epoch 00003: val_loss improved from 1.56440 to 1.53329, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.5628 - accuracy: 0.3377 - val_loss: 1.5333 - val_accuracy: 0.6482 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4945 - accuracy: 0.5391\n",
      "Epoch 00004: val_loss improved from 1.53329 to 1.48861, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.5143 - accuracy: 0.5156 - val_loss: 1.4886 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4657 - accuracy: 0.5703\n",
      "Epoch 00005: val_loss improved from 1.48861 to 1.40868, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4613 - accuracy: 0.5951 - val_loss: 1.4087 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3928 - accuracy: 0.6719\n",
      "Epoch 00006: val_loss improved from 1.40868 to 1.30257, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3812 - accuracy: 0.6295 - val_loss: 1.3026 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3577 - accuracy: 0.6016\n",
      "Epoch 00007: val_loss improved from 1.30257 to 1.17499, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2831 - accuracy: 0.6410 - val_loss: 1.1750 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3316 - accuracy: 0.5391\n",
      "Epoch 00008: val_loss improved from 1.17499 to 1.06212, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1997 - accuracy: 0.6393 - val_loss: 1.0621 - val_accuracy: 0.6539 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1843 - accuracy: 0.6562\n",
      "Epoch 00009: val_loss improved from 1.06212 to 0.98267, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0897 - accuracy: 0.6434 - val_loss: 0.9827 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0767 - accuracy: 0.6328\n",
      "Epoch 00010: val_loss improved from 0.98267 to 0.92106, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0382 - accuracy: 0.6361 - val_loss: 0.9211 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9319 - accuracy: 0.6875\n",
      "Epoch 00011: val_loss improved from 0.92106 to 0.88926, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9646 - accuracy: 0.6377 - val_loss: 0.8893 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0432 - accuracy: 0.6250\n",
      "Epoch 00012: val_loss improved from 0.88926 to 0.85846, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9527 - accuracy: 0.6393 - val_loss: 0.8585 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8280 - accuracy: 0.6484\n",
      "Epoch 00013: val_loss improved from 0.85846 to 0.82556, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9168 - accuracy: 0.6393 - val_loss: 0.8256 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8607 - accuracy: 0.7031\n",
      "Epoch 00014: val_loss improved from 0.82556 to 0.81252, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8882 - accuracy: 0.6467 - val_loss: 0.8125 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8349 - accuracy: 0.6562\n",
      "Epoch 00015: val_loss improved from 0.81252 to 0.79760, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8740 - accuracy: 0.6459 - val_loss: 0.7976 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9341 - accuracy: 0.6484\n",
      "Epoch 00016: val_loss improved from 0.79760 to 0.77160, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8556 - accuracy: 0.6443 - val_loss: 0.7716 - val_accuracy: 0.6807 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8858 - accuracy: 0.6016\n",
      "Epoch 00017: val_loss improved from 0.77160 to 0.75623, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8277 - accuracy: 0.6434 - val_loss: 0.7562 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7819 - accuracy: 0.6797\n",
      "Epoch 00018: val_loss improved from 0.75623 to 0.74473, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8066 - accuracy: 0.6582 - val_loss: 0.7447 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8179 - accuracy: 0.6406\n",
      "Epoch 00019: val_loss improved from 0.74473 to 0.72000, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8191 - accuracy: 0.6623 - val_loss: 0.7200 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8239 - accuracy: 0.6953\n",
      "Epoch 00020: val_loss improved from 0.72000 to 0.71944, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8151 - accuracy: 0.6623 - val_loss: 0.7194 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7495 - accuracy: 0.6953\n",
      "Epoch 00021: val_loss improved from 0.71944 to 0.71088, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7638 - accuracy: 0.6664 - val_loss: 0.7109 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7433 - accuracy: 0.7109\n",
      "Epoch 00022: val_loss improved from 0.71088 to 0.69929, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7612 - accuracy: 0.6738 - val_loss: 0.6993 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8315 - accuracy: 0.6562\n",
      "Epoch 00023: val_loss improved from 0.69929 to 0.69512, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7795 - accuracy: 0.6738 - val_loss: 0.6951 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7868 - accuracy: 0.6328\n",
      "Epoch 00024: val_loss improved from 0.69512 to 0.68738, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7588 - accuracy: 0.6852 - val_loss: 0.6874 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7895 - accuracy: 0.7109\n",
      "Epoch 00025: val_loss did not improve from 0.68738\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7540 - accuracy: 0.6926 - val_loss: 0.6891 - val_accuracy: 0.7342 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7174 - accuracy: 0.6797\n",
      "Epoch 00026: val_loss improved from 0.68738 to 0.68131, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7403 - accuracy: 0.6877 - val_loss: 0.6813 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7892 - accuracy: 0.6250\n",
      "Epoch 00027: val_loss did not improve from 0.68131\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7341 - accuracy: 0.6967 - val_loss: 0.6915 - val_accuracy: 0.7228 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8036 - accuracy: 0.6562\n",
      "Epoch 00028: val_loss improved from 0.68131 to 0.67606, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7140 - accuracy: 0.7123 - val_loss: 0.6761 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6619 - accuracy: 0.7344\n",
      "Epoch 00029: val_loss did not improve from 0.67606\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7093 - accuracy: 0.6975 - val_loss: 0.6781 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6109 - accuracy: 0.7656\n",
      "Epoch 00030: val_loss improved from 0.67606 to 0.67423, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7061 - accuracy: 0.7057 - val_loss: 0.6742 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6493 - accuracy: 0.7344\n",
      "Epoch 00031: val_loss improved from 0.67423 to 0.66956, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6844 - accuracy: 0.7205 - val_loss: 0.6696 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6246 - accuracy: 0.7734\n",
      "Epoch 00032: val_loss improved from 0.66956 to 0.66946, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6869 - accuracy: 0.7025 - val_loss: 0.6695 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7139 - accuracy: 0.7109\n",
      "Epoch 00033: val_loss improved from 0.66946 to 0.66159, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6631 - accuracy: 0.7115 - val_loss: 0.6616 - val_accuracy: 0.7342 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5628 - accuracy: 0.7578\n",
      "Epoch 00034: val_loss did not improve from 0.66159\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.7189 - val_loss: 0.6757 - val_accuracy: 0.7266 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6027 - accuracy: 0.7344\n",
      "Epoch 00035: val_loss improved from 0.66159 to 0.65994, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6641 - accuracy: 0.7180 - val_loss: 0.6599 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7753 - accuracy: 0.6953\n",
      "Epoch 00036: val_loss improved from 0.65994 to 0.65605, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6439 - accuracy: 0.7434 - val_loss: 0.6560 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5769 - accuracy: 0.7734\n",
      "Epoch 00037: val_loss did not improve from 0.65605\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.7426 - val_loss: 0.6581 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5804 - accuracy: 0.7266\n",
      "Epoch 00038: val_loss did not improve from 0.65605\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6282 - accuracy: 0.7500 - val_loss: 0.6697 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6055 - accuracy: 0.7500\n",
      "Epoch 00039: val_loss improved from 0.65605 to 0.65100, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6180 - accuracy: 0.7541 - val_loss: 0.6510 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5634 - accuracy: 0.8125\n",
      "Epoch 00040: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7648 - val_loss: 0.6725 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5911 - accuracy: 0.7812\n",
      "Epoch 00041: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7434 - val_loss: 0.6857 - val_accuracy: 0.7304 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6384 - accuracy: 0.7031\n",
      "Epoch 00042: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6111 - accuracy: 0.7475 - val_loss: 0.6602 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6521 - accuracy: 0.7734\n",
      "Epoch 00043: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.7615 - val_loss: 0.6608 - val_accuracy: 0.7572 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6753 - accuracy: 0.7188\n",
      "Epoch 00044: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5970 - accuracy: 0.7615 - val_loss: 0.6690 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5522 - accuracy: 0.7656\n",
      "Epoch 00045: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5712 - accuracy: 0.7713 - val_loss: 0.6546 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6093 - accuracy: 0.7578\n",
      "Epoch 00046: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.7631 - val_loss: 0.6651 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5752 - accuracy: 0.7969\n",
      "Epoch 00047: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7721 - val_loss: 0.6792 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5390 - accuracy: 0.7812\n",
      "Epoch 00048: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.7738 - val_loss: 0.6616 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5163 - accuracy: 0.8047\n",
      "Epoch 00049: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5508 - accuracy: 0.7770 - val_loss: 0.6828 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5417 - accuracy: 0.8047\n",
      "Epoch 00050: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7877 - val_loss: 0.6808 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5249 - accuracy: 0.7656\n",
      "Epoch 00051: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.7730 - val_loss: 0.6679 - val_accuracy: 0.7572 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5047 - accuracy: 0.7656\n",
      "Epoch 00052: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7746 - val_loss: 0.6690 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5536 - accuracy: 0.7969\n",
      "Epoch 00053: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7787 - val_loss: 0.6774 - val_accuracy: 0.7648 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5214 - accuracy: 0.7812\n",
      "Epoch 00054: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7910 - val_loss: 0.7161 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5498 - accuracy: 0.7500\n",
      "Epoch 00055: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.7811 - val_loss: 0.7126 - val_accuracy: 0.7495 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4346 - accuracy: 0.8125\n",
      "Epoch 00056: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7967 - val_loss: 0.7104 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4938 - accuracy: 0.7891\n",
      "Epoch 00057: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4965 - accuracy: 0.7992 - val_loss: 0.7089 - val_accuracy: 0.7553 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5383 - accuracy: 0.7500\n",
      "Epoch 00058: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7992 - val_loss: 0.7190 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5167 - accuracy: 0.7812\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.8098 - val_loss: 0.7368 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4062 - accuracy: 0.8125\n",
      "Epoch 00060: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.8016 - val_loss: 0.7604 - val_accuracy: 0.7457 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3932 - accuracy: 0.8516\n",
      "Epoch 00061: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.8098 - val_loss: 0.7503 - val_accuracy: 0.7438 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4372 - accuracy: 0.8359\n",
      "Epoch 00062: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.8008 - val_loss: 0.7432 - val_accuracy: 0.7419 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3643 - accuracy: 0.8516\n",
      "Epoch 00063: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.8139 - val_loss: 0.7489 - val_accuracy: 0.7514 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8750\n",
      "Epoch 00064: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8189 - val_loss: 0.7519 - val_accuracy: 0.7553 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4358 - accuracy: 0.8281\n",
      "Epoch 00065: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8180 - val_loss: 0.7763 - val_accuracy: 0.7342 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4387 - accuracy: 0.8359\n",
      "Epoch 00066: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.8221 - val_loss: 0.7622 - val_accuracy: 0.7419 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4782 - accuracy: 0.7969\n",
      "Epoch 00067: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8221 - val_loss: 0.7840 - val_accuracy: 0.7247 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4162 - accuracy: 0.7969\n",
      "Epoch 00068: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8238 - val_loss: 0.7762 - val_accuracy: 0.7342 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4085 - accuracy: 0.8281\n",
      "Epoch 00069: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8230 - val_loss: 0.7747 - val_accuracy: 0.7380 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3838 - accuracy: 0.8750\n",
      "Epoch 00070: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8344 - val_loss: 0.7945 - val_accuracy: 0.7380 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3670 - accuracy: 0.8281\n",
      "Epoch 00071: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8254 - val_loss: 0.8091 - val_accuracy: 0.7380 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3132 - accuracy: 0.8672\n",
      "Epoch 00072: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8287 - val_loss: 0.8231 - val_accuracy: 0.7266 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3694 - accuracy: 0.8438\n",
      "Epoch 00073: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8221 - val_loss: 0.8365 - val_accuracy: 0.7495 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3980 - accuracy: 0.8125\n",
      "Epoch 00074: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8320 - val_loss: 0.8459 - val_accuracy: 0.7514 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8594\n",
      "Epoch 00075: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8352 - val_loss: 0.8333 - val_accuracy: 0.7419 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8828\n",
      "Epoch 00076: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8287 - val_loss: 0.8461 - val_accuracy: 0.7438 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3953 - accuracy: 0.8281\n",
      "Epoch 00077: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8287 - val_loss: 0.8461 - val_accuracy: 0.7438 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3333 - accuracy: 0.8516\n",
      "Epoch 00078: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8344 - val_loss: 0.8400 - val_accuracy: 0.7400 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3313 - accuracy: 0.8203\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8377 - val_loss: 0.8858 - val_accuracy: 0.7380 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3600 - accuracy: 0.8594\n",
      "Epoch 00080: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8385 - val_loss: 0.8679 - val_accuracy: 0.7304 - lr: 2.5000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3273 - accuracy: 0.8594\n",
      "Epoch 00081: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8443 - val_loss: 0.8519 - val_accuracy: 0.7342 - lr: 2.5000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3280 - accuracy: 0.8438\n",
      "Epoch 00082: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8434 - val_loss: 0.8719 - val_accuracy: 0.7361 - lr: 2.5000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3946 - accuracy: 0.8281\n",
      "Epoch 00083: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8484 - val_loss: 0.8730 - val_accuracy: 0.7400 - lr: 2.5000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3726 - accuracy: 0.8359\n",
      "Epoch 00084: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3539 - accuracy: 0.8459 - val_loss: 0.8726 - val_accuracy: 0.7400 - lr: 2.5000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4357 - accuracy: 0.7891\n",
      "Epoch 00085: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3451 - accuracy: 0.8508 - val_loss: 0.8701 - val_accuracy: 0.7419 - lr: 2.5000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3070 - accuracy: 0.8750\n",
      "Epoch 00086: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8393 - val_loss: 0.8805 - val_accuracy: 0.7476 - lr: 2.5000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8359\n",
      "Epoch 00087: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8566 - val_loss: 0.9007 - val_accuracy: 0.7476 - lr: 2.5000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3523 - accuracy: 0.8438\n",
      "Epoch 00088: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8443 - val_loss: 0.9080 - val_accuracy: 0.7438 - lr: 2.5000e-04\n",
      "Epoch 89/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3774 - accuracy: 0.8047\n",
      "Epoch 00089: val_loss did not improve from 0.65100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8484 - val_loss: 0.9051 - val_accuracy: 0.7400 - lr: 2.5000e-04\n",
      "Epoch 00089: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7261 - accuracy: 0.1484\n",
      "Epoch 00001: val_loss improved from inf to 1.56457, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.6312 - accuracy: 0.2303 - val_loss: 1.5646 - val_accuracy: 0.3767 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5571 - accuracy: 0.2812\n",
      "Epoch 00002: val_loss improved from 1.56457 to 1.49753, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.5474 - accuracy: 0.3254 - val_loss: 1.4975 - val_accuracy: 0.3709 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.5075 - accuracy: 0.3672\n",
      "Epoch 00003: val_loss improved from 1.49753 to 1.41989, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4891 - accuracy: 0.3623 - val_loss: 1.4199 - val_accuracy: 0.3748 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3939 - accuracy: 0.4297\n",
      "Epoch 00004: val_loss improved from 1.41989 to 1.37770, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4404 - accuracy: 0.3910 - val_loss: 1.3777 - val_accuracy: 0.4570 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4093 - accuracy: 0.4219\n",
      "Epoch 00005: val_loss improved from 1.37770 to 1.34330, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3960 - accuracy: 0.4303 - val_loss: 1.3433 - val_accuracy: 0.5201 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3778 - accuracy: 0.4609\n",
      "Epoch 00006: val_loss improved from 1.34330 to 1.30438, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3520 - accuracy: 0.4533 - val_loss: 1.3044 - val_accuracy: 0.5564 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2883 - accuracy: 0.4922\n",
      "Epoch 00007: val_loss improved from 1.30438 to 1.25783, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3353 - accuracy: 0.4713 - val_loss: 1.2578 - val_accuracy: 0.5717 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2697 - accuracy: 0.4844\n",
      "Epoch 00008: val_loss improved from 1.25783 to 1.18911, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2897 - accuracy: 0.5139 - val_loss: 1.1891 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3056 - accuracy: 0.4922\n",
      "Epoch 00009: val_loss improved from 1.18911 to 1.12739, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2355 - accuracy: 0.5459 - val_loss: 1.1274 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1509 - accuracy: 0.5703\n",
      "Epoch 00010: val_loss improved from 1.12739 to 1.07784, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1942 - accuracy: 0.5426 - val_loss: 1.0778 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1531 - accuracy: 0.5234\n",
      "Epoch 00011: val_loss improved from 1.07784 to 1.05414, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1534 - accuracy: 0.5590 - val_loss: 1.0541 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1111 - accuracy: 0.5703\n",
      "Epoch 00012: val_loss did not improve from 1.05414\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1031 - accuracy: 0.5779 - val_loss: 1.0580 - val_accuracy: 0.5698 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2292 - accuracy: 0.5547\n",
      "Epoch 00013: val_loss improved from 1.05414 to 1.02572, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0743 - accuracy: 0.5926 - val_loss: 1.0257 - val_accuracy: 0.6004 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0671 - accuracy: 0.5938\n",
      "Epoch 00014: val_loss improved from 1.02572 to 1.02237, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0386 - accuracy: 0.6123 - val_loss: 1.0224 - val_accuracy: 0.5851 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0076 - accuracy: 0.6406\n",
      "Epoch 00015: val_loss improved from 1.02237 to 1.00680, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.0383 - accuracy: 0.6041 - val_loss: 1.0068 - val_accuracy: 0.6099 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9388 - accuracy: 0.6797\n",
      "Epoch 00016: val_loss improved from 1.00680 to 1.00087, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0164 - accuracy: 0.6139 - val_loss: 1.0009 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0382 - accuracy: 0.6406\n",
      "Epoch 00017: val_loss did not improve from 1.00087\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0076 - accuracy: 0.6221 - val_loss: 1.0043 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9090 - accuracy: 0.6406\n",
      "Epoch 00018: val_loss improved from 1.00087 to 0.99525, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9899 - accuracy: 0.6139 - val_loss: 0.9952 - val_accuracy: 0.6214 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9119 - accuracy: 0.6484\n",
      "Epoch 00019: val_loss improved from 0.99525 to 0.99194, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9723 - accuracy: 0.6361 - val_loss: 0.9919 - val_accuracy: 0.6080 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8855 - accuracy: 0.6406\n",
      "Epoch 00020: val_loss improved from 0.99194 to 0.98611, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9512 - accuracy: 0.6426 - val_loss: 0.9861 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8826 - accuracy: 0.6953\n",
      "Epoch 00021: val_loss improved from 0.98611 to 0.97712, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9749 - accuracy: 0.6402 - val_loss: 0.9771 - val_accuracy: 0.6252 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9373 - accuracy: 0.6172\n",
      "Epoch 00022: val_loss improved from 0.97712 to 0.97610, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9290 - accuracy: 0.6344 - val_loss: 0.9761 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8981 - accuracy: 0.6641\n",
      "Epoch 00023: val_loss improved from 0.97610 to 0.96906, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9187 - accuracy: 0.6492 - val_loss: 0.9691 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9004 - accuracy: 0.6484\n",
      "Epoch 00024: val_loss improved from 0.96906 to 0.96129, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8981 - accuracy: 0.6557 - val_loss: 0.9613 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8327 - accuracy: 0.7031\n",
      "Epoch 00025: val_loss improved from 0.96129 to 0.95291, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8955 - accuracy: 0.6639 - val_loss: 0.9529 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8652 - accuracy: 0.6641\n",
      "Epoch 00026: val_loss improved from 0.95291 to 0.94652, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9015 - accuracy: 0.6475 - val_loss: 0.9465 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8916 - accuracy: 0.6250\n",
      "Epoch 00027: val_loss did not improve from 0.94652\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8833 - accuracy: 0.6582 - val_loss: 0.9698 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8441 - accuracy: 0.6484\n",
      "Epoch 00028: val_loss did not improve from 0.94652\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8616 - accuracy: 0.6566 - val_loss: 0.9629 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9627 - accuracy: 0.6172\n",
      "Epoch 00029: val_loss did not improve from 0.94652\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8800 - accuracy: 0.6549 - val_loss: 0.9628 - val_accuracy: 0.6214 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8933 - accuracy: 0.6016\n",
      "Epoch 00030: val_loss improved from 0.94652 to 0.94615, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8517 - accuracy: 0.6598 - val_loss: 0.9461 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8104 - accuracy: 0.7188\n",
      "Epoch 00031: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8393 - accuracy: 0.6721 - val_loss: 0.9560 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6348 - accuracy: 0.7266\n",
      "Epoch 00032: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8495 - accuracy: 0.6664 - val_loss: 0.9680 - val_accuracy: 0.6329 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8983 - accuracy: 0.6094\n",
      "Epoch 00033: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8287 - accuracy: 0.6672 - val_loss: 0.9485 - val_accuracy: 0.6329 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8792 - accuracy: 0.6250\n",
      "Epoch 00034: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8382 - accuracy: 0.6680 - val_loss: 0.9615 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8001 - accuracy: 0.6719\n",
      "Epoch 00035: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8253 - accuracy: 0.6721 - val_loss: 0.9689 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7177 - accuracy: 0.7266\n",
      "Epoch 00036: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8046 - accuracy: 0.6738 - val_loss: 0.9741 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8429 - accuracy: 0.6641\n",
      "Epoch 00037: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8170 - accuracy: 0.6738 - val_loss: 0.9523 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7720 - accuracy: 0.6797\n",
      "Epoch 00038: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7884 - accuracy: 0.6754 - val_loss: 0.9521 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6823 - accuracy: 0.7344\n",
      "Epoch 00039: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7894 - accuracy: 0.6770 - val_loss: 0.9592 - val_accuracy: 0.6386 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7759 - accuracy: 0.6719\n",
      "Epoch 00040: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7868 - accuracy: 0.6836 - val_loss: 0.9721 - val_accuracy: 0.6386 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7098 - accuracy: 0.7188\n",
      "Epoch 00041: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7884 - accuracy: 0.6787 - val_loss: 0.9807 - val_accuracy: 0.6272 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8105 - accuracy: 0.6641\n",
      "Epoch 00042: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7728 - accuracy: 0.6836 - val_loss: 0.9871 - val_accuracy: 0.6329 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6391 - accuracy: 0.7500\n",
      "Epoch 00043: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7678 - accuracy: 0.6787 - val_loss: 0.9941 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7609 - accuracy: 0.6797\n",
      "Epoch 00044: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7772 - accuracy: 0.6770 - val_loss: 0.9877 - val_accuracy: 0.6386 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8377 - accuracy: 0.6875\n",
      "Epoch 00045: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7594 - accuracy: 0.6869 - val_loss: 1.0234 - val_accuracy: 0.6310 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7901 - accuracy: 0.6797\n",
      "Epoch 00046: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7881 - accuracy: 0.6762 - val_loss: 0.9755 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7621 - accuracy: 0.6797\n",
      "Epoch 00047: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7667 - accuracy: 0.6844 - val_loss: 0.9792 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7810 - accuracy: 0.6484\n",
      "Epoch 00048: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7390 - accuracy: 0.6934 - val_loss: 1.0096 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6984 - accuracy: 0.7422\n",
      "Epoch 00049: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7536 - accuracy: 0.6877 - val_loss: 1.0127 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7638 - accuracy: 0.6953\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7556 - accuracy: 0.6918 - val_loss: 1.0325 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6975 - accuracy: 0.7188\n",
      "Epoch 00051: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7406 - accuracy: 0.6877 - val_loss: 1.0171 - val_accuracy: 0.6386 - lr: 5.0000e-04\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7979 - accuracy: 0.6875\n",
      "Epoch 00052: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7401 - accuracy: 0.6877 - val_loss: 1.0046 - val_accuracy: 0.6386 - lr: 5.0000e-04\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8650 - accuracy: 0.6016\n",
      "Epoch 00053: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7288 - accuracy: 0.6943 - val_loss: 1.0142 - val_accuracy: 0.6367 - lr: 5.0000e-04\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7293 - accuracy: 0.7109\n",
      "Epoch 00054: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7281 - accuracy: 0.6959 - val_loss: 1.0129 - val_accuracy: 0.6386 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7824 - accuracy: 0.6250\n",
      "Epoch 00055: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7205 - accuracy: 0.6984 - val_loss: 1.0213 - val_accuracy: 0.6405 - lr: 5.0000e-04\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7303 - accuracy: 0.6953\n",
      "Epoch 00056: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7171 - accuracy: 0.6943 - val_loss: 1.0322 - val_accuracy: 0.6405 - lr: 5.0000e-04\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6976 - accuracy: 0.7109\n",
      "Epoch 00057: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7150 - accuracy: 0.6992 - val_loss: 1.0499 - val_accuracy: 0.6386 - lr: 5.0000e-04\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7937 - accuracy: 0.6484\n",
      "Epoch 00058: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.6975 - val_loss: 1.0433 - val_accuracy: 0.6405 - lr: 5.0000e-04\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6702 - accuracy: 0.7422\n",
      "Epoch 00059: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7330 - accuracy: 0.6926 - val_loss: 1.0389 - val_accuracy: 0.6424 - lr: 5.0000e-04\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8087 - accuracy: 0.6016\n",
      "Epoch 00060: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7080 - accuracy: 0.6967 - val_loss: 1.0332 - val_accuracy: 0.6444 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6515 - accuracy: 0.7344\n",
      "Epoch 00061: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7082 - accuracy: 0.6984 - val_loss: 1.0338 - val_accuracy: 0.6482 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8038 - accuracy: 0.6562\n",
      "Epoch 00062: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7264 - accuracy: 0.6934 - val_loss: 1.0393 - val_accuracy: 0.6424 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7743 - accuracy: 0.6875\n",
      "Epoch 00063: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7175 - accuracy: 0.6967 - val_loss: 1.0471 - val_accuracy: 0.6444 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7956 - accuracy: 0.6484\n",
      "Epoch 00064: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7222 - accuracy: 0.6926 - val_loss: 1.0357 - val_accuracy: 0.6424 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6347 - accuracy: 0.7656\n",
      "Epoch 00065: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.7016 - val_loss: 1.0181 - val_accuracy: 0.6463 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7588 - accuracy: 0.6562\n",
      "Epoch 00066: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.7008 - val_loss: 1.0559 - val_accuracy: 0.6424 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6886 - accuracy: 0.7031\n",
      "Epoch 00067: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6996 - accuracy: 0.7033 - val_loss: 1.0413 - val_accuracy: 0.6424 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8265 - accuracy: 0.6562\n",
      "Epoch 00068: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.6975 - val_loss: 1.0419 - val_accuracy: 0.6424 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6915 - accuracy: 0.6953\n",
      "Epoch 00069: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7113 - accuracy: 0.6975 - val_loss: 1.0476 - val_accuracy: 0.6405 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7195 - accuracy: 0.6797\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.6992 - val_loss: 1.0488 - val_accuracy: 0.6444 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7809 - accuracy: 0.6641\n",
      "Epoch 00071: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.7033 - val_loss: 1.0457 - val_accuracy: 0.6444 - lr: 2.5000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6471 - accuracy: 0.7031\n",
      "Epoch 00072: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6968 - accuracy: 0.6926 - val_loss: 1.0555 - val_accuracy: 0.6367 - lr: 2.5000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7797 - accuracy: 0.6484\n",
      "Epoch 00073: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.6984 - val_loss: 1.0582 - val_accuracy: 0.6405 - lr: 2.5000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7133 - accuracy: 0.6484\n",
      "Epoch 00074: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.7033 - val_loss: 1.0608 - val_accuracy: 0.6405 - lr: 2.5000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6869 - accuracy: 0.7031\n",
      "Epoch 00075: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.7025 - val_loss: 1.0718 - val_accuracy: 0.6386 - lr: 2.5000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7413 - accuracy: 0.6641\n",
      "Epoch 00076: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6800 - accuracy: 0.7041 - val_loss: 1.0771 - val_accuracy: 0.6386 - lr: 2.5000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5722 - accuracy: 0.7500\n",
      "Epoch 00077: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.7025 - val_loss: 1.0790 - val_accuracy: 0.6405 - lr: 2.5000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7302 - accuracy: 0.6797\n",
      "Epoch 00078: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6785 - accuracy: 0.7025 - val_loss: 1.0830 - val_accuracy: 0.6386 - lr: 2.5000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6707 - accuracy: 0.6875\n",
      "Epoch 00079: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.6943 - val_loss: 1.0868 - val_accuracy: 0.6348 - lr: 2.5000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6911 - accuracy: 0.6641\n",
      "Epoch 00080: val_loss did not improve from 0.94615\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.6992 - val_loss: 1.0929 - val_accuracy: 0.6386 - lr: 2.5000e-04\n",
      "Epoch 00080: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9110 - accuracy: 0.0859\n",
      "Epoch 00001: val_loss improved from inf to 1.75332, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.8046 - accuracy: 0.1770 - val_loss: 1.7533 - val_accuracy: 0.3155 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7382 - accuracy: 0.3125\n",
      "Epoch 00002: val_loss improved from 1.75332 to 1.68819, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.7096 - accuracy: 0.3221 - val_loss: 1.6882 - val_accuracy: 0.3671 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6818 - accuracy: 0.3516\n",
      "Epoch 00003: val_loss improved from 1.68819 to 1.58079, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6397 - accuracy: 0.3680 - val_loss: 1.5808 - val_accuracy: 0.4340 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6006 - accuracy: 0.4062\n",
      "Epoch 00004: val_loss improved from 1.58079 to 1.46153, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.5388 - accuracy: 0.3992 - val_loss: 1.4615 - val_accuracy: 0.4685 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4457 - accuracy: 0.4219\n",
      "Epoch 00005: val_loss improved from 1.46153 to 1.39549, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4798 - accuracy: 0.4041 - val_loss: 1.3955 - val_accuracy: 0.4914 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3007 - accuracy: 0.4531\n",
      "Epoch 00006: val_loss improved from 1.39549 to 1.36081, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4185 - accuracy: 0.4418 - val_loss: 1.3608 - val_accuracy: 0.4895 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4143 - accuracy: 0.3672\n",
      "Epoch 00007: val_loss improved from 1.36081 to 1.32322, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3757 - accuracy: 0.4361 - val_loss: 1.3232 - val_accuracy: 0.5010 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4670 - accuracy: 0.4375\n",
      "Epoch 00008: val_loss improved from 1.32322 to 1.29824, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3686 - accuracy: 0.4303 - val_loss: 1.2982 - val_accuracy: 0.5220 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2334 - accuracy: 0.5234\n",
      "Epoch 00009: val_loss improved from 1.29824 to 1.27640, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.3309 - accuracy: 0.4697 - val_loss: 1.2764 - val_accuracy: 0.5430 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2695 - accuracy: 0.5234\n",
      "Epoch 00010: val_loss improved from 1.27640 to 1.23997, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2924 - accuracy: 0.4992 - val_loss: 1.2400 - val_accuracy: 0.5526 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3213 - accuracy: 0.5000\n",
      "Epoch 00011: val_loss improved from 1.23997 to 1.21253, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2901 - accuracy: 0.4885 - val_loss: 1.2125 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0540 - accuracy: 0.5547\n",
      "Epoch 00012: val_loss improved from 1.21253 to 1.19886, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2604 - accuracy: 0.4934 - val_loss: 1.1989 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1967 - accuracy: 0.5234\n",
      "Epoch 00013: val_loss improved from 1.19886 to 1.18463, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2478 - accuracy: 0.5164 - val_loss: 1.1846 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3233 - accuracy: 0.4453\n",
      "Epoch 00014: val_loss improved from 1.18463 to 1.17640, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2149 - accuracy: 0.5320 - val_loss: 1.1764 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1461 - accuracy: 0.5234\n",
      "Epoch 00015: val_loss improved from 1.17640 to 1.16597, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2179 - accuracy: 0.5205 - val_loss: 1.1660 - val_accuracy: 0.5870 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2725 - accuracy: 0.5078\n",
      "Epoch 00016: val_loss improved from 1.16597 to 1.14993, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1975 - accuracy: 0.5295 - val_loss: 1.1499 - val_accuracy: 0.5966 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3446 - accuracy: 0.5078\n",
      "Epoch 00017: val_loss improved from 1.14993 to 1.14360, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1824 - accuracy: 0.5508 - val_loss: 1.1436 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1617 - accuracy: 0.5625\n",
      "Epoch 00018: val_loss improved from 1.14360 to 1.13922, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1663 - accuracy: 0.5598 - val_loss: 1.1392 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2602 - accuracy: 0.5469\n",
      "Epoch 00019: val_loss did not improve from 1.13922\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1544 - accuracy: 0.5582 - val_loss: 1.1404 - val_accuracy: 0.6004 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2412 - accuracy: 0.5938\n",
      "Epoch 00020: val_loss improved from 1.13922 to 1.11667, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1396 - accuracy: 0.5787 - val_loss: 1.1167 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1939 - accuracy: 0.5469\n",
      "Epoch 00021: val_loss improved from 1.11667 to 1.10870, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1286 - accuracy: 0.5738 - val_loss: 1.1087 - val_accuracy: 0.5889 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0254 - accuracy: 0.6328\n",
      "Epoch 00022: val_loss improved from 1.10870 to 1.10395, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1242 - accuracy: 0.5795 - val_loss: 1.1039 - val_accuracy: 0.6099 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1340 - accuracy: 0.5781\n",
      "Epoch 00023: val_loss did not improve from 1.10395\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1136 - accuracy: 0.5836 - val_loss: 1.1055 - val_accuracy: 0.5927 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9861 - accuracy: 0.6094\n",
      "Epoch 00024: val_loss improved from 1.10395 to 1.08946, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0994 - accuracy: 0.5861 - val_loss: 1.0895 - val_accuracy: 0.6157 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0945 - accuracy: 0.5859\n",
      "Epoch 00025: val_loss did not improve from 1.08946\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0899 - accuracy: 0.5918 - val_loss: 1.0962 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0918 - accuracy: 0.5469\n",
      "Epoch 00026: val_loss improved from 1.08946 to 1.07453, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0716 - accuracy: 0.5926 - val_loss: 1.0745 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1081 - accuracy: 0.6094\n",
      "Epoch 00027: val_loss did not improve from 1.07453\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1012 - accuracy: 0.5926 - val_loss: 1.0761 - val_accuracy: 0.6195 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0805 - accuracy: 0.5859\n",
      "Epoch 00028: val_loss improved from 1.07453 to 1.07364, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0607 - accuracy: 0.5934 - val_loss: 1.0736 - val_accuracy: 0.6176 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1030 - accuracy: 0.5781\n",
      "Epoch 00029: val_loss did not improve from 1.07364\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0646 - accuracy: 0.6082 - val_loss: 1.0787 - val_accuracy: 0.6214 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0019 - accuracy: 0.6328\n",
      "Epoch 00030: val_loss improved from 1.07364 to 1.06961, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0316 - accuracy: 0.6131 - val_loss: 1.0696 - val_accuracy: 0.6252 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9485 - accuracy: 0.6641\n",
      "Epoch 00031: val_loss improved from 1.06961 to 1.05925, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0369 - accuracy: 0.6189 - val_loss: 1.0592 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1382 - accuracy: 0.5625\n",
      "Epoch 00032: val_loss improved from 1.05925 to 1.05377, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0205 - accuracy: 0.6295 - val_loss: 1.0538 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9790 - accuracy: 0.6484\n",
      "Epoch 00033: val_loss improved from 1.05377 to 1.04835, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9981 - accuracy: 0.6287 - val_loss: 1.0483 - val_accuracy: 0.6252 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0520 - accuracy: 0.6016\n",
      "Epoch 00034: val_loss did not improve from 1.04835\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0112 - accuracy: 0.6287 - val_loss: 1.0609 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9621 - accuracy: 0.6562\n",
      "Epoch 00035: val_loss did not improve from 1.04835\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9754 - accuracy: 0.6418 - val_loss: 1.0577 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9875 - accuracy: 0.6562\n",
      "Epoch 00036: val_loss did not improve from 1.04835\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9931 - accuracy: 0.6369 - val_loss: 1.0555 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9880 - accuracy: 0.6172\n",
      "Epoch 00037: val_loss did not improve from 1.04835\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9777 - accuracy: 0.6352 - val_loss: 1.0506 - val_accuracy: 0.6463 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9826 - accuracy: 0.6641\n",
      "Epoch 00038: val_loss did not improve from 1.04835\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9663 - accuracy: 0.6459 - val_loss: 1.0495 - val_accuracy: 0.6482 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9941 - accuracy: 0.6250\n",
      "Epoch 00039: val_loss improved from 1.04835 to 1.03336, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9290 - accuracy: 0.6533 - val_loss: 1.0334 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0931 - accuracy: 0.5312\n",
      "Epoch 00040: val_loss improved from 1.03336 to 1.03068, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9592 - accuracy: 0.6311 - val_loss: 1.0307 - val_accuracy: 0.6520 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7981 - accuracy: 0.7109\n",
      "Epoch 00041: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9385 - accuracy: 0.6475 - val_loss: 1.0445 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8534 - accuracy: 0.6953\n",
      "Epoch 00042: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9214 - accuracy: 0.6500 - val_loss: 1.0547 - val_accuracy: 0.6329 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0434 - accuracy: 0.5547\n",
      "Epoch 00043: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9314 - accuracy: 0.6434 - val_loss: 1.0510 - val_accuracy: 0.6463 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8838 - accuracy: 0.6406\n",
      "Epoch 00044: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9075 - accuracy: 0.6484 - val_loss: 1.0914 - val_accuracy: 0.6272 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8658 - accuracy: 0.6406\n",
      "Epoch 00045: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9134 - accuracy: 0.6508 - val_loss: 1.0595 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9024 - accuracy: 0.6953\n",
      "Epoch 00046: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8972 - accuracy: 0.6557 - val_loss: 1.0345 - val_accuracy: 0.6405 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9546 - accuracy: 0.6484\n",
      "Epoch 00047: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8651 - accuracy: 0.6664 - val_loss: 1.0490 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7397 - accuracy: 0.6797\n",
      "Epoch 00048: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8589 - accuracy: 0.6639 - val_loss: 1.0467 - val_accuracy: 0.6386 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9005 - accuracy: 0.6562\n",
      "Epoch 00049: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8945 - accuracy: 0.6615 - val_loss: 1.0550 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7437 - accuracy: 0.6797\n",
      "Epoch 00050: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8661 - accuracy: 0.6689 - val_loss: 1.0455 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9096 - accuracy: 0.6484\n",
      "Epoch 00051: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8460 - accuracy: 0.6721 - val_loss: 1.0470 - val_accuracy: 0.6424 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8565 - accuracy: 0.6641\n",
      "Epoch 00052: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8361 - accuracy: 0.6795 - val_loss: 1.0599 - val_accuracy: 0.6329 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8386 - accuracy: 0.6797\n",
      "Epoch 00053: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8296 - accuracy: 0.6746 - val_loss: 1.0737 - val_accuracy: 0.6367 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9692 - accuracy: 0.6484\n",
      "Epoch 00054: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8272 - accuracy: 0.6861 - val_loss: 1.0590 - val_accuracy: 0.6501 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8416 - accuracy: 0.6953\n",
      "Epoch 00055: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8123 - accuracy: 0.6852 - val_loss: 1.1295 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7937 - accuracy: 0.7031\n",
      "Epoch 00056: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7964 - accuracy: 0.7041 - val_loss: 1.0388 - val_accuracy: 0.6750 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7968 - accuracy: 0.7188\n",
      "Epoch 00057: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8263 - accuracy: 0.6869 - val_loss: 1.1114 - val_accuracy: 0.6501 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9364 - accuracy: 0.6562\n",
      "Epoch 00058: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8465 - accuracy: 0.6787 - val_loss: 1.0556 - val_accuracy: 0.6673 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9240 - accuracy: 0.6328\n",
      "Epoch 00059: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7973 - accuracy: 0.7107 - val_loss: 1.0781 - val_accuracy: 0.6730 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7469 - accuracy: 0.7578\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7827 - accuracy: 0.7156 - val_loss: 1.0625 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7565 - accuracy: 0.7734\n",
      "Epoch 00061: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7796 - accuracy: 0.7221 - val_loss: 1.0484 - val_accuracy: 0.6845 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7615 - accuracy: 0.6875\n",
      "Epoch 00062: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7393 - accuracy: 0.7221 - val_loss: 1.0785 - val_accuracy: 0.6845 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7069 - accuracy: 0.7422\n",
      "Epoch 00063: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7398 - accuracy: 0.7279 - val_loss: 1.0555 - val_accuracy: 0.6883 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7546 - accuracy: 0.6875\n",
      "Epoch 00064: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7270 - accuracy: 0.7377 - val_loss: 1.0990 - val_accuracy: 0.6826 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6606 - accuracy: 0.7344\n",
      "Epoch 00065: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7384 - accuracy: 0.7311 - val_loss: 1.0842 - val_accuracy: 0.6807 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7555 - accuracy: 0.7266\n",
      "Epoch 00066: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7323 - accuracy: 0.7410 - val_loss: 1.1004 - val_accuracy: 0.6769 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8081 - accuracy: 0.6797\n",
      "Epoch 00067: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7181 - accuracy: 0.7410 - val_loss: 1.0655 - val_accuracy: 0.6807 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7959 - accuracy: 0.6797\n",
      "Epoch 00068: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7120 - accuracy: 0.7443 - val_loss: 1.0676 - val_accuracy: 0.6883 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7238 - accuracy: 0.7500\n",
      "Epoch 00069: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6952 - accuracy: 0.7549 - val_loss: 1.0725 - val_accuracy: 0.6922 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8217 - accuracy: 0.7031\n",
      "Epoch 00070: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7100 - accuracy: 0.7443 - val_loss: 1.0773 - val_accuracy: 0.6788 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6802 - accuracy: 0.7500\n",
      "Epoch 00071: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7202 - accuracy: 0.7361 - val_loss: 1.0996 - val_accuracy: 0.6902 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7338 - accuracy: 0.7031\n",
      "Epoch 00072: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6829 - accuracy: 0.7516 - val_loss: 1.0796 - val_accuracy: 0.6807 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7008 - accuracy: 0.7031\n",
      "Epoch 00073: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.7549 - val_loss: 1.0938 - val_accuracy: 0.6826 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5974 - accuracy: 0.7969\n",
      "Epoch 00074: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.7689 - val_loss: 1.1108 - val_accuracy: 0.6826 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7542 - accuracy: 0.7344\n",
      "Epoch 00075: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.7615 - val_loss: 1.0854 - val_accuracy: 0.6788 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5922 - accuracy: 0.8203\n",
      "Epoch 00076: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6750 - accuracy: 0.7582 - val_loss: 1.0999 - val_accuracy: 0.6730 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5687 - accuracy: 0.8125\n",
      "Epoch 00077: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6714 - accuracy: 0.7525 - val_loss: 1.0906 - val_accuracy: 0.6807 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7728 - accuracy: 0.7188\n",
      "Epoch 00078: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.7639 - val_loss: 1.1061 - val_accuracy: 0.6941 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6765 - accuracy: 0.7578\n",
      "Epoch 00079: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6734 - accuracy: 0.7566 - val_loss: 1.0770 - val_accuracy: 0.6883 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6355 - accuracy: 0.7891\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.7549 - val_loss: 1.0904 - val_accuracy: 0.6845 - lr: 5.0000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7238 - accuracy: 0.7266\n",
      "Epoch 00081: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.7738 - val_loss: 1.0921 - val_accuracy: 0.6864 - lr: 2.5000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7138 - accuracy: 0.7500\n",
      "Epoch 00082: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6548 - accuracy: 0.7770 - val_loss: 1.0837 - val_accuracy: 0.6902 - lr: 2.5000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7698 - accuracy: 0.7344\n",
      "Epoch 00083: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.7672 - val_loss: 1.0861 - val_accuracy: 0.6864 - lr: 2.5000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5345 - accuracy: 0.8359\n",
      "Epoch 00084: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.7680 - val_loss: 1.0951 - val_accuracy: 0.6826 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7385 - accuracy: 0.7891\n",
      "Epoch 00085: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6349 - accuracy: 0.7680 - val_loss: 1.1217 - val_accuracy: 0.6845 - lr: 2.5000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5880 - accuracy: 0.8125\n",
      "Epoch 00086: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.7852 - val_loss: 1.1238 - val_accuracy: 0.6902 - lr: 2.5000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7220 - accuracy: 0.7344\n",
      "Epoch 00087: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6366 - accuracy: 0.7713 - val_loss: 1.1294 - val_accuracy: 0.6864 - lr: 2.5000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6595 - accuracy: 0.7500\n",
      "Epoch 00088: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.7787 - val_loss: 1.1166 - val_accuracy: 0.6807 - lr: 2.5000e-04\n",
      "Epoch 89/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6564 - accuracy: 0.7734\n",
      "Epoch 00089: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.7738 - val_loss: 1.1124 - val_accuracy: 0.6864 - lr: 2.5000e-04\n",
      "Epoch 90/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6010 - accuracy: 0.7891\n",
      "Epoch 00090: val_loss did not improve from 1.03068\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.7795 - val_loss: 1.1567 - val_accuracy: 0.6807 - lr: 2.5000e-04\n",
      "Epoch 00090: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.3479 - accuracy: 0.3594\n",
      "Epoch 00001: val_loss improved from inf to 1.16663, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.2453 - accuracy: 0.4967 - val_loss: 1.1666 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0824 - accuracy: 0.6172\n",
      "Epoch 00002: val_loss improved from 1.16663 to 0.86494, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0033 - accuracy: 0.5910 - val_loss: 0.8649 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9584 - accuracy: 0.5547\n",
      "Epoch 00003: val_loss improved from 0.86494 to 0.73938, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8728 - accuracy: 0.5869 - val_loss: 0.7394 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7568 - accuracy: 0.5703\n",
      "Epoch 00004: val_loss improved from 0.73938 to 0.67964, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8120 - accuracy: 0.5918 - val_loss: 0.6796 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7437 - accuracy: 0.5469\n",
      "Epoch 00005: val_loss improved from 0.67964 to 0.67255, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7466 - accuracy: 0.5803 - val_loss: 0.6726 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7920 - accuracy: 0.6797\n",
      "Epoch 00006: val_loss improved from 0.67255 to 0.63270, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7227 - accuracy: 0.5984 - val_loss: 0.6327 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7452 - accuracy: 0.6016\n",
      "Epoch 00007: val_loss improved from 0.63270 to 0.62137, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7082 - accuracy: 0.6279 - val_loss: 0.6214 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7279 - accuracy: 0.6562\n",
      "Epoch 00008: val_loss improved from 0.62137 to 0.60333, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6871 - accuracy: 0.6352 - val_loss: 0.6033 - val_accuracy: 0.7438 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6340 - accuracy: 0.6797\n",
      "Epoch 00009: val_loss improved from 0.60333 to 0.59537, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6774 - accuracy: 0.6320 - val_loss: 0.5954 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6476 - accuracy: 0.6484\n",
      "Epoch 00010: val_loss improved from 0.59537 to 0.57479, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6462 - accuracy: 0.6443 - val_loss: 0.5748 - val_accuracy: 0.7495 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5869 - accuracy: 0.7109\n",
      "Epoch 00011: val_loss improved from 0.57479 to 0.56877, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6326 - accuracy: 0.6549 - val_loss: 0.5688 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6590 - accuracy: 0.6406\n",
      "Epoch 00012: val_loss improved from 0.56877 to 0.55653, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6222 - accuracy: 0.6820 - val_loss: 0.5565 - val_accuracy: 0.7572 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7578 - accuracy: 0.5625\n",
      "Epoch 00013: val_loss improved from 0.55653 to 0.54420, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5931 - accuracy: 0.6992 - val_loss: 0.5442 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5965 - accuracy: 0.6953\n",
      "Epoch 00014: val_loss improved from 0.54420 to 0.52698, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5891 - accuracy: 0.6951 - val_loss: 0.5270 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4711 - accuracy: 0.8047\n",
      "Epoch 00015: val_loss improved from 0.52698 to 0.51831, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5643 - accuracy: 0.7467 - val_loss: 0.5183 - val_accuracy: 0.7533 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5620 - accuracy: 0.7578\n",
      "Epoch 00016: val_loss improved from 0.51831 to 0.51174, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5607 - accuracy: 0.7508 - val_loss: 0.5117 - val_accuracy: 0.7610 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4191 - accuracy: 0.8047\n",
      "Epoch 00017: val_loss improved from 0.51174 to 0.50717, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.7598 - val_loss: 0.5072 - val_accuracy: 0.7744 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5381 - accuracy: 0.7969\n",
      "Epoch 00018: val_loss improved from 0.50717 to 0.49569, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5244 - accuracy: 0.7623 - val_loss: 0.4957 - val_accuracy: 0.7763 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6930 - accuracy: 0.7344\n",
      "Epoch 00019: val_loss improved from 0.49569 to 0.48251, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5390 - accuracy: 0.7639 - val_loss: 0.4825 - val_accuracy: 0.7916 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5199 - accuracy: 0.7969\n",
      "Epoch 00020: val_loss improved from 0.48251 to 0.47749, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5093 - accuracy: 0.7918 - val_loss: 0.4775 - val_accuracy: 0.7801 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4989 - accuracy: 0.8125\n",
      "Epoch 00021: val_loss improved from 0.47749 to 0.45873, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5061 - accuracy: 0.7934 - val_loss: 0.4587 - val_accuracy: 0.7954 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4315 - accuracy: 0.8672\n",
      "Epoch 00022: val_loss improved from 0.45873 to 0.44911, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4825 - accuracy: 0.8016 - val_loss: 0.4491 - val_accuracy: 0.8069 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4717 - accuracy: 0.8125\n",
      "Epoch 00023: val_loss improved from 0.44911 to 0.44035, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4674 - accuracy: 0.8189 - val_loss: 0.4404 - val_accuracy: 0.8107 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3751 - accuracy: 0.8594\n",
      "Epoch 00024: val_loss did not improve from 0.44035\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.8164 - val_loss: 0.4439 - val_accuracy: 0.7973 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5498 - accuracy: 0.8125\n",
      "Epoch 00025: val_loss improved from 0.44035 to 0.44018, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4439 - accuracy: 0.8221 - val_loss: 0.4402 - val_accuracy: 0.8164 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4568 - accuracy: 0.8203\n",
      "Epoch 00026: val_loss improved from 0.44018 to 0.42357, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8287 - val_loss: 0.4236 - val_accuracy: 0.8164 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4361 - accuracy: 0.8281\n",
      "Epoch 00027: val_loss did not improve from 0.42357\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8311 - val_loss: 0.4280 - val_accuracy: 0.8184 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4359 - accuracy: 0.8047\n",
      "Epoch 00028: val_loss improved from 0.42357 to 0.41766, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8467 - val_loss: 0.4177 - val_accuracy: 0.8164 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4190 - accuracy: 0.8359\n",
      "Epoch 00029: val_loss improved from 0.41766 to 0.41079, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3929 - accuracy: 0.8361 - val_loss: 0.4108 - val_accuracy: 0.8260 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3601 - accuracy: 0.8359\n",
      "Epoch 00030: val_loss improved from 0.41079 to 0.39746, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8566 - val_loss: 0.3975 - val_accuracy: 0.8298 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4607 - accuracy: 0.7812\n",
      "Epoch 00031: val_loss did not improve from 0.39746\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8459 - val_loss: 0.4126 - val_accuracy: 0.8203 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5358 - accuracy: 0.8047\n",
      "Epoch 00032: val_loss did not improve from 0.39746\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8582 - val_loss: 0.4013 - val_accuracy: 0.8356 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2980 - accuracy: 0.9062\n",
      "Epoch 00033: val_loss improved from 0.39746 to 0.39709, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3662 - accuracy: 0.8721 - val_loss: 0.3971 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4053 - accuracy: 0.8516\n",
      "Epoch 00034: val_loss did not improve from 0.39709\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3462 - accuracy: 0.8713 - val_loss: 0.4016 - val_accuracy: 0.8375 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2558 - accuracy: 0.9141\n",
      "Epoch 00035: val_loss improved from 0.39709 to 0.39429, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3483 - accuracy: 0.8820 - val_loss: 0.3943 - val_accuracy: 0.8585 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3541 - accuracy: 0.8984\n",
      "Epoch 00036: val_loss improved from 0.39429 to 0.38390, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3300 - accuracy: 0.8811 - val_loss: 0.3839 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2281 - accuracy: 0.9453\n",
      "Epoch 00037: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8852 - val_loss: 0.4069 - val_accuracy: 0.8317 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2211 - accuracy: 0.9219\n",
      "Epoch 00038: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8893 - val_loss: 0.3953 - val_accuracy: 0.8394 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2401 - accuracy: 0.9531\n",
      "Epoch 00039: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8869 - val_loss: 0.4185 - val_accuracy: 0.8375 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2512 - accuracy: 0.9062\n",
      "Epoch 00040: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8926 - val_loss: 0.3935 - val_accuracy: 0.8489 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4350 - accuracy: 0.8594\n",
      "Epoch 00041: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2980 - accuracy: 0.8885 - val_loss: 0.3981 - val_accuracy: 0.8604 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2966 - accuracy: 0.8828\n",
      "Epoch 00042: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.8893 - val_loss: 0.4145 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2302 - accuracy: 0.8984\n",
      "Epoch 00043: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2680 - accuracy: 0.8951 - val_loss: 0.4159 - val_accuracy: 0.8432 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1699 - accuracy: 0.9531\n",
      "Epoch 00044: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2623 - accuracy: 0.9066 - val_loss: 0.3931 - val_accuracy: 0.8470 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1766 - accuracy: 0.9453\n",
      "Epoch 00045: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2558 - accuracy: 0.9123 - val_loss: 0.4271 - val_accuracy: 0.8642 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1940 - accuracy: 0.9141\n",
      "Epoch 00046: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2468 - accuracy: 0.9123 - val_loss: 0.3988 - val_accuracy: 0.8585 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2509 - accuracy: 0.9141\n",
      "Epoch 00047: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2502 - accuracy: 0.9123 - val_loss: 0.4058 - val_accuracy: 0.8585 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1946 - accuracy: 0.9453\n",
      "Epoch 00048: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2604 - accuracy: 0.9107 - val_loss: 0.4114 - val_accuracy: 0.8547 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2629 - accuracy: 0.9297\n",
      "Epoch 00049: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2539 - accuracy: 0.9049 - val_loss: 0.4263 - val_accuracy: 0.8585 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1978 - accuracy: 0.9141\n",
      "Epoch 00050: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2374 - accuracy: 0.9115 - val_loss: 0.4265 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2461 - accuracy: 0.9219\n",
      "Epoch 00051: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2520 - accuracy: 0.9164 - val_loss: 0.4347 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1569 - accuracy: 0.9453\n",
      "Epoch 00052: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2519 - accuracy: 0.9172 - val_loss: 0.4297 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1915 - accuracy: 0.9219\n",
      "Epoch 00053: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2229 - accuracy: 0.9221 - val_loss: 0.4295 - val_accuracy: 0.8470 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1861 - accuracy: 0.9297\n",
      "Epoch 00054: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2297 - accuracy: 0.9238 - val_loss: 0.4545 - val_accuracy: 0.8623 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2174 - accuracy: 0.9062\n",
      "Epoch 00055: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2217 - accuracy: 0.9139 - val_loss: 0.4637 - val_accuracy: 0.8623 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1976 - accuracy: 0.9375\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2128 - accuracy: 0.9262 - val_loss: 0.4942 - val_accuracy: 0.8547 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2462 - accuracy: 0.9141\n",
      "Epoch 00057: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2173 - accuracy: 0.9254 - val_loss: 0.4521 - val_accuracy: 0.8642 - lr: 5.0000e-04\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1556 - accuracy: 0.9375\n",
      "Epoch 00058: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.9311 - val_loss: 0.4789 - val_accuracy: 0.8566 - lr: 5.0000e-04\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1920 - accuracy: 0.9297\n",
      "Epoch 00059: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1828 - accuracy: 0.9393 - val_loss: 0.4469 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2777 - accuracy: 0.9141\n",
      "Epoch 00060: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9369 - val_loss: 0.4563 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1473 - accuracy: 0.9688\n",
      "Epoch 00061: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9500 - val_loss: 0.4630 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1731 - accuracy: 0.9297\n",
      "Epoch 00062: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9426 - val_loss: 0.4543 - val_accuracy: 0.8681 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1732 - accuracy: 0.9297\n",
      "Epoch 00063: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9484 - val_loss: 0.4825 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1592 - accuracy: 0.9375\n",
      "Epoch 00064: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1425 - accuracy: 0.9533 - val_loss: 0.4815 - val_accuracy: 0.8662 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1997 - accuracy: 0.9375\n",
      "Epoch 00065: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.9516 - val_loss: 0.5155 - val_accuracy: 0.8566 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1540 - accuracy: 0.9531\n",
      "Epoch 00066: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1426 - accuracy: 0.9516 - val_loss: 0.5268 - val_accuracy: 0.8642 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1793 - accuracy: 0.9375\n",
      "Epoch 00067: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1567 - accuracy: 0.9467 - val_loss: 0.5438 - val_accuracy: 0.8585 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1798 - accuracy: 0.9531\n",
      "Epoch 00068: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9492 - val_loss: 0.5352 - val_accuracy: 0.8604 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1186 - accuracy: 0.9531\n",
      "Epoch 00069: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.9525 - val_loss: 0.5425 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2033 - accuracy: 0.9531\n",
      "Epoch 00070: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1453 - accuracy: 0.9549 - val_loss: 0.5161 - val_accuracy: 0.8528 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0788 - accuracy: 0.9766\n",
      "Epoch 00071: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1388 - accuracy: 0.9590 - val_loss: 0.5583 - val_accuracy: 0.8604 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1363 - accuracy: 0.9609\n",
      "Epoch 00072: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1557 - accuracy: 0.9459 - val_loss: 0.5336 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0962 - accuracy: 0.9766\n",
      "Epoch 00073: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 0.9566 - val_loss: 0.5446 - val_accuracy: 0.8566 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1550 - accuracy: 0.9219\n",
      "Epoch 00074: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9484 - val_loss: 0.5451 - val_accuracy: 0.8604 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1818 - accuracy: 0.9219\n",
      "Epoch 00075: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1234 - accuracy: 0.9549 - val_loss: 0.5551 - val_accuracy: 0.8566 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0934 - accuracy: 0.9609\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1300 - accuracy: 0.9549 - val_loss: 0.5873 - val_accuracy: 0.8642 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0946 - accuracy: 0.9609\n",
      "Epoch 00077: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1321 - accuracy: 0.9615 - val_loss: 0.5848 - val_accuracy: 0.8604 - lr: 2.5000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1407 - accuracy: 0.9531\n",
      "Epoch 00078: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.9689 - val_loss: 0.5813 - val_accuracy: 0.8604 - lr: 2.5000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1228 - accuracy: 0.9688\n",
      "Epoch 00079: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 0.9598 - val_loss: 0.5834 - val_accuracy: 0.8623 - lr: 2.5000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1278 - accuracy: 0.9531\n",
      "Epoch 00080: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9582 - val_loss: 0.5911 - val_accuracy: 0.8662 - lr: 2.5000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2020 - accuracy: 0.9688\n",
      "Epoch 00081: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9623 - val_loss: 0.5903 - val_accuracy: 0.8681 - lr: 2.5000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0789 - accuracy: 0.9688\n",
      "Epoch 00082: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9672 - val_loss: 0.5889 - val_accuracy: 0.8623 - lr: 2.5000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1398 - accuracy: 0.9453\n",
      "Epoch 00083: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1139 - accuracy: 0.9639 - val_loss: 0.6086 - val_accuracy: 0.8623 - lr: 2.5000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0556 - accuracy: 0.9844\n",
      "Epoch 00084: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1011 - accuracy: 0.9697 - val_loss: 0.6139 - val_accuracy: 0.8623 - lr: 2.5000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1550 - accuracy: 0.9688\n",
      "Epoch 00085: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9656 - val_loss: 0.5967 - val_accuracy: 0.8604 - lr: 2.5000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1358 - accuracy: 0.9531\n",
      "Epoch 00086: val_loss did not improve from 0.38390\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9664 - val_loss: 0.6169 - val_accuracy: 0.8604 - lr: 2.5000e-04\n",
      "Epoch 00086: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 2.0142 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from inf to 1.73241, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.8329 - accuracy: 0.1090 - val_loss: 1.7324 - val_accuracy: 0.4971 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7430 - accuracy: 0.2422\n",
      "Epoch 00002: val_loss improved from 1.73241 to 1.62504, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6885 - accuracy: 0.3779 - val_loss: 1.6250 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6087 - accuracy: 0.5078\n",
      "Epoch 00003: val_loss improved from 1.62504 to 1.38405, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.5239 - accuracy: 0.5631 - val_loss: 1.3840 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4163 - accuracy: 0.5391\n",
      "Epoch 00004: val_loss improved from 1.38405 to 1.14839, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3150 - accuracy: 0.6033 - val_loss: 1.1484 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2115 - accuracy: 0.6406\n",
      "Epoch 00005: val_loss improved from 1.14839 to 1.11057, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2283 - accuracy: 0.6082 - val_loss: 1.1106 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0447 - accuracy: 0.6719\n",
      "Epoch 00006: val_loss improved from 1.11057 to 1.10381, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1593 - accuracy: 0.6148 - val_loss: 1.1038 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0930 - accuracy: 0.6016\n",
      "Epoch 00007: val_loss improved from 1.10381 to 1.08005, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1123 - accuracy: 0.6098 - val_loss: 1.0800 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0815 - accuracy: 0.6250\n",
      "Epoch 00008: val_loss improved from 1.08005 to 1.06919, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0971 - accuracy: 0.6123 - val_loss: 1.0692 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1057 - accuracy: 0.6172\n",
      "Epoch 00009: val_loss improved from 1.06919 to 1.04685, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0794 - accuracy: 0.6139 - val_loss: 1.0469 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0930 - accuracy: 0.5859\n",
      "Epoch 00010: val_loss improved from 1.04685 to 1.02501, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0527 - accuracy: 0.6139 - val_loss: 1.0250 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0095 - accuracy: 0.5859\n",
      "Epoch 00011: val_loss improved from 1.02501 to 1.00926, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0356 - accuracy: 0.6139 - val_loss: 1.0093 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9981 - accuracy: 0.6250\n",
      "Epoch 00012: val_loss improved from 1.00926 to 0.98718, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0163 - accuracy: 0.6172 - val_loss: 0.9872 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8779 - accuracy: 0.6641\n",
      "Epoch 00013: val_loss improved from 0.98718 to 0.98016, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9979 - accuracy: 0.6189 - val_loss: 0.9802 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9258 - accuracy: 0.6641\n",
      "Epoch 00014: val_loss did not improve from 0.98016\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9776 - accuracy: 0.6197 - val_loss: 0.9829 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0547 - accuracy: 0.5781\n",
      "Epoch 00015: val_loss improved from 0.98016 to 0.97156, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.9826 - accuracy: 0.6180 - val_loss: 0.9716 - val_accuracy: 0.6176 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0452 - accuracy: 0.6094\n",
      "Epoch 00016: val_loss improved from 0.97156 to 0.95418, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9604 - accuracy: 0.6254 - val_loss: 0.9542 - val_accuracy: 0.6176 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8529 - accuracy: 0.7031\n",
      "Epoch 00017: val_loss improved from 0.95418 to 0.94896, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9449 - accuracy: 0.6262 - val_loss: 0.9490 - val_accuracy: 0.6291 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8113 - accuracy: 0.6953\n",
      "Epoch 00018: val_loss did not improve from 0.94896\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9389 - accuracy: 0.6434 - val_loss: 0.9490 - val_accuracy: 0.6597 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9187 - accuracy: 0.6719\n",
      "Epoch 00019: val_loss improved from 0.94896 to 0.93565, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9446 - accuracy: 0.6361 - val_loss: 0.9356 - val_accuracy: 0.6558 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0209 - accuracy: 0.6328\n",
      "Epoch 00020: val_loss improved from 0.93565 to 0.93496, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9486 - accuracy: 0.6230 - val_loss: 0.9350 - val_accuracy: 0.6597 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8364 - accuracy: 0.6797\n",
      "Epoch 00021: val_loss improved from 0.93496 to 0.93188, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9181 - accuracy: 0.6385 - val_loss: 0.9319 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8961 - accuracy: 0.6797\n",
      "Epoch 00022: val_loss improved from 0.93188 to 0.91297, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9033 - accuracy: 0.6549 - val_loss: 0.9130 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9030 - accuracy: 0.6406\n",
      "Epoch 00023: val_loss improved from 0.91297 to 0.89946, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8943 - accuracy: 0.6459 - val_loss: 0.8995 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8641 - accuracy: 0.6094\n",
      "Epoch 00024: val_loss improved from 0.89946 to 0.89129, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9051 - accuracy: 0.6426 - val_loss: 0.8913 - val_accuracy: 0.6979 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7569 - accuracy: 0.7109\n",
      "Epoch 00025: val_loss improved from 0.89129 to 0.88216, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8769 - accuracy: 0.6648 - val_loss: 0.8822 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9437 - accuracy: 0.6562\n",
      "Epoch 00026: val_loss improved from 0.88216 to 0.87214, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8663 - accuracy: 0.6656 - val_loss: 0.8721 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7817 - accuracy: 0.6719\n",
      "Epoch 00027: val_loss improved from 0.87214 to 0.86217, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8613 - accuracy: 0.6730 - val_loss: 0.8622 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8445 - accuracy: 0.6875\n",
      "Epoch 00028: val_loss improved from 0.86217 to 0.85488, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8578 - accuracy: 0.6811 - val_loss: 0.8549 - val_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8497 - accuracy: 0.6797\n",
      "Epoch 00029: val_loss improved from 0.85488 to 0.85324, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8435 - accuracy: 0.6820 - val_loss: 0.8532 - val_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8876 - accuracy: 0.6641\n",
      "Epoch 00030: val_loss did not improve from 0.85324\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8158 - accuracy: 0.7033 - val_loss: 0.8564 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9090 - accuracy: 0.6953\n",
      "Epoch 00031: val_loss improved from 0.85324 to 0.85096, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8348 - accuracy: 0.6803 - val_loss: 0.8510 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8144 - accuracy: 0.6953\n",
      "Epoch 00032: val_loss improved from 0.85096 to 0.84335, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7995 - accuracy: 0.6975 - val_loss: 0.8434 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7244 - accuracy: 0.7656\n",
      "Epoch 00033: val_loss improved from 0.84335 to 0.83778, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7857 - accuracy: 0.7131 - val_loss: 0.8378 - val_accuracy: 0.7094 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8158 - accuracy: 0.7031\n",
      "Epoch 00034: val_loss did not improve from 0.83778\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7931 - accuracy: 0.6926 - val_loss: 0.8384 - val_accuracy: 0.7170 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7534 - accuracy: 0.6641\n",
      "Epoch 00035: val_loss improved from 0.83778 to 0.83506, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7871 - accuracy: 0.7041 - val_loss: 0.8351 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7111 - accuracy: 0.7578\n",
      "Epoch 00036: val_loss did not improve from 0.83506\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7819 - accuracy: 0.7057 - val_loss: 0.8375 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6741 - accuracy: 0.7422\n",
      "Epoch 00037: val_loss improved from 0.83506 to 0.82714, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7719 - accuracy: 0.7082 - val_loss: 0.8271 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7411 - accuracy: 0.7188\n",
      "Epoch 00038: val_loss did not improve from 0.82714\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7568 - accuracy: 0.7213 - val_loss: 0.8308 - val_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7933 - accuracy: 0.7109\n",
      "Epoch 00039: val_loss did not improve from 0.82714\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7508 - accuracy: 0.7172 - val_loss: 0.8412 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6939 - accuracy: 0.7344\n",
      "Epoch 00040: val_loss did not improve from 0.82714\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7679 - accuracy: 0.7074 - val_loss: 0.8294 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8094 - accuracy: 0.7188\n",
      "Epoch 00041: val_loss did not improve from 0.82714\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7378 - accuracy: 0.7230 - val_loss: 0.8354 - val_accuracy: 0.7151 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7731 - accuracy: 0.7422\n",
      "Epoch 00042: val_loss improved from 0.82714 to 0.82578, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7310 - accuracy: 0.7295 - val_loss: 0.8258 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6434 - accuracy: 0.7344\n",
      "Epoch 00043: val_loss did not improve from 0.82578\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7107 - accuracy: 0.7303 - val_loss: 0.8413 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6722 - accuracy: 0.7578\n",
      "Epoch 00044: val_loss did not improve from 0.82578\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6983 - accuracy: 0.7287 - val_loss: 0.8278 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6531 - accuracy: 0.7500\n",
      "Epoch 00045: val_loss did not improve from 0.82578\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7200 - accuracy: 0.7221 - val_loss: 0.8408 - val_accuracy: 0.7189 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7731 - accuracy: 0.6875\n",
      "Epoch 00046: val_loss did not improve from 0.82578\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7125 - accuracy: 0.7402 - val_loss: 0.8311 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5984 - accuracy: 0.8125\n",
      "Epoch 00047: val_loss did not improve from 0.82578\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.7385 - val_loss: 0.8275 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6803 - accuracy: 0.7266\n",
      "Epoch 00048: val_loss improved from 0.82578 to 0.81750, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6988 - accuracy: 0.7385 - val_loss: 0.8175 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6921 - accuracy: 0.7578\n",
      "Epoch 00049: val_loss did not improve from 0.81750\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.7541 - val_loss: 0.8263 - val_accuracy: 0.7036 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6184 - accuracy: 0.7812\n",
      "Epoch 00050: val_loss improved from 0.81750 to 0.81673, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7056 - accuracy: 0.7393 - val_loss: 0.8167 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6101 - accuracy: 0.7891\n",
      "Epoch 00051: val_loss improved from 0.81673 to 0.81608, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6607 - accuracy: 0.7598 - val_loss: 0.8161 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6341 - accuracy: 0.8047\n",
      "Epoch 00052: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6202 - accuracy: 0.7664 - val_loss: 0.8332 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6328 - accuracy: 0.7578\n",
      "Epoch 00053: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.7549 - val_loss: 0.8236 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5744 - accuracy: 0.7812\n",
      "Epoch 00054: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7746 - val_loss: 0.8298 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5862 - accuracy: 0.7812\n",
      "Epoch 00055: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6185 - accuracy: 0.7697 - val_loss: 0.8270 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6920 - accuracy: 0.7266\n",
      "Epoch 00056: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.7705 - val_loss: 0.8249 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6337 - accuracy: 0.7656\n",
      "Epoch 00057: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.7697 - val_loss: 0.8552 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6331 - accuracy: 0.7656\n",
      "Epoch 00058: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6030 - accuracy: 0.7779 - val_loss: 0.8227 - val_accuracy: 0.7342 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5083 - accuracy: 0.8125\n",
      "Epoch 00059: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6015 - accuracy: 0.7820 - val_loss: 0.8172 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5509 - accuracy: 0.8125\n",
      "Epoch 00060: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7910 - val_loss: 0.8237 - val_accuracy: 0.7113 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6534 - accuracy: 0.7188\n",
      "Epoch 00061: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5971 - accuracy: 0.7730 - val_loss: 0.8584 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6291 - accuracy: 0.7812\n",
      "Epoch 00062: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.7852 - val_loss: 0.8525 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6193 - accuracy: 0.7891\n",
      "Epoch 00063: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7984 - val_loss: 0.8587 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5017 - accuracy: 0.7656\n",
      "Epoch 00064: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.7877 - val_loss: 0.9132 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5745 - accuracy: 0.8281\n",
      "Epoch 00065: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7844 - val_loss: 0.8846 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6308 - accuracy: 0.7656\n",
      "Epoch 00066: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7918 - val_loss: 0.8581 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6068 - accuracy: 0.7734\n",
      "Epoch 00067: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.8107 - val_loss: 0.8713 - val_accuracy: 0.7055 - lr: 0.0010\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3363 - accuracy: 0.8750\n",
      "Epoch 00068: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7975 - val_loss: 0.8638 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5045 - accuracy: 0.8203\n",
      "Epoch 00069: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5561 - accuracy: 0.8041 - val_loss: 0.8620 - val_accuracy: 0.7247 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4433 - accuracy: 0.8359\n",
      "Epoch 00070: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.8049 - val_loss: 0.9171 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4950 - accuracy: 0.8359\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7893 - val_loss: 0.8811 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3882 - accuracy: 0.8594\n",
      "Epoch 00072: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.8066 - val_loss: 0.8872 - val_accuracy: 0.7189 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5492 - accuracy: 0.7969\n",
      "Epoch 00073: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.8279 - val_loss: 0.9095 - val_accuracy: 0.7075 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5532 - accuracy: 0.7891\n",
      "Epoch 00074: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.8336 - val_loss: 0.9175 - val_accuracy: 0.7189 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4891 - accuracy: 0.8438\n",
      "Epoch 00075: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.8107 - val_loss: 0.9315 - val_accuracy: 0.7151 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4404 - accuracy: 0.8438\n",
      "Epoch 00076: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.8385 - val_loss: 0.9129 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5378 - accuracy: 0.7812\n",
      "Epoch 00077: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5046 - accuracy: 0.8148 - val_loss: 0.9472 - val_accuracy: 0.7228 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5171 - accuracy: 0.8359\n",
      "Epoch 00078: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8393 - val_loss: 0.9276 - val_accuracy: 0.7208 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4622 - accuracy: 0.8281\n",
      "Epoch 00079: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.8320 - val_loss: 0.9418 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4549 - accuracy: 0.8125\n",
      "Epoch 00080: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.8361 - val_loss: 0.9581 - val_accuracy: 0.7075 - lr: 5.0000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5106 - accuracy: 0.8047\n",
      "Epoch 00081: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.8377 - val_loss: 0.9594 - val_accuracy: 0.6998 - lr: 5.0000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4146 - accuracy: 0.8594\n",
      "Epoch 00082: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8451 - val_loss: 0.9666 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4435 - accuracy: 0.8438\n",
      "Epoch 00083: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8484 - val_loss: 0.9634 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3570 - accuracy: 0.8672\n",
      "Epoch 00084: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.8377 - val_loss: 0.9727 - val_accuracy: 0.7170 - lr: 5.0000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4514 - accuracy: 0.8281\n",
      "Epoch 00085: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8426 - val_loss: 0.9724 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4471 - accuracy: 0.8828\n",
      "Epoch 00086: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8533 - val_loss: 0.9542 - val_accuracy: 0.7266 - lr: 5.0000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3901 - accuracy: 0.8672\n",
      "Epoch 00087: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8443 - val_loss: 0.9680 - val_accuracy: 0.7285 - lr: 5.0000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4790 - accuracy: 0.8594\n",
      "Epoch 00088: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.8467 - val_loss: 0.9963 - val_accuracy: 0.7132 - lr: 5.0000e-04\n",
      "Epoch 89/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4596 - accuracy: 0.8047\n",
      "Epoch 00089: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8369 - val_loss: 0.9918 - val_accuracy: 0.6979 - lr: 5.0000e-04\n",
      "Epoch 90/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5052 - accuracy: 0.7891\n",
      "Epoch 00090: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.8254 - val_loss: 0.9936 - val_accuracy: 0.7036 - lr: 5.0000e-04\n",
      "Epoch 91/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3835 - accuracy: 0.8594\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.8393 - val_loss: 0.9881 - val_accuracy: 0.7055 - lr: 5.0000e-04\n",
      "Epoch 92/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3935 - accuracy: 0.8828\n",
      "Epoch 00092: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8566 - val_loss: 0.9942 - val_accuracy: 0.7094 - lr: 2.5000e-04\n",
      "Epoch 93/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5423 - accuracy: 0.8359\n",
      "Epoch 00093: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8574 - val_loss: 1.0102 - val_accuracy: 0.7113 - lr: 2.5000e-04\n",
      "Epoch 94/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4202 - accuracy: 0.8750\n",
      "Epoch 00094: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8484 - val_loss: 0.9989 - val_accuracy: 0.7113 - lr: 2.5000e-04\n",
      "Epoch 95/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4413 - accuracy: 0.8203\n",
      "Epoch 00095: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8475 - val_loss: 1.0166 - val_accuracy: 0.7094 - lr: 2.5000e-04\n",
      "Epoch 96/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8672\n",
      "Epoch 00096: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8533 - val_loss: 1.0323 - val_accuracy: 0.7228 - lr: 2.5000e-04\n",
      "Epoch 97/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4186 - accuracy: 0.8594\n",
      "Epoch 00097: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8582 - val_loss: 1.0278 - val_accuracy: 0.7151 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5106 - accuracy: 0.8359\n",
      "Epoch 00098: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8607 - val_loss: 1.0346 - val_accuracy: 0.7075 - lr: 2.5000e-04\n",
      "Epoch 99/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3524 - accuracy: 0.8828\n",
      "Epoch 00099: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8500 - val_loss: 1.0467 - val_accuracy: 0.7170 - lr: 2.5000e-04\n",
      "Epoch 100/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3021 - accuracy: 0.8984\n",
      "Epoch 00100: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8557 - val_loss: 1.0383 - val_accuracy: 0.7075 - lr: 2.5000e-04\n",
      "Epoch 101/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2939 - accuracy: 0.8828\n",
      "Epoch 00101: val_loss did not improve from 0.81608\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8664 - val_loss: 1.0419 - val_accuracy: 0.7189 - lr: 2.5000e-04\n",
      "Epoch 00101: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.8416 - accuracy: 0.1172\n",
      "Epoch 00001: val_loss improved from inf to 1.66438, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.7533 - accuracy: 0.2205 - val_loss: 1.6644 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.6489 - accuracy: 0.4375\n",
      "Epoch 00002: val_loss improved from 1.66438 to 1.39862, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.5712 - accuracy: 0.5197 - val_loss: 1.3986 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4156 - accuracy: 0.6484\n",
      "Epoch 00003: val_loss improved from 1.39862 to 1.09180, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3311 - accuracy: 0.6705 - val_loss: 1.0918 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4472 - accuracy: 0.6719\n",
      "Epoch 00004: val_loss improved from 1.09180 to 1.01014, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2741 - accuracy: 0.6967 - val_loss: 1.0101 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0529 - accuracy: 0.7188\n",
      "Epoch 00005: val_loss improved from 1.01014 to 0.98564, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1364 - accuracy: 0.6959 - val_loss: 0.9856 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9796 - accuracy: 0.7578\n",
      "Epoch 00006: val_loss improved from 0.98564 to 0.95158, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1126 - accuracy: 0.6959 - val_loss: 0.9516 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1796 - accuracy: 0.6484\n",
      "Epoch 00007: val_loss improved from 0.95158 to 0.94113, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0616 - accuracy: 0.6959 - val_loss: 0.9411 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0901 - accuracy: 0.7109\n",
      "Epoch 00008: val_loss improved from 0.94113 to 0.93545, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0639 - accuracy: 0.6967 - val_loss: 0.9355 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0438 - accuracy: 0.6953\n",
      "Epoch 00009: val_loss improved from 0.93545 to 0.93189, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0233 - accuracy: 0.6967 - val_loss: 0.9319 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9677 - accuracy: 0.7344\n",
      "Epoch 00010: val_loss improved from 0.93189 to 0.91465, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0109 - accuracy: 0.6967 - val_loss: 0.9146 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9903 - accuracy: 0.6953\n",
      "Epoch 00011: val_loss improved from 0.91465 to 0.91075, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0271 - accuracy: 0.6967 - val_loss: 0.9108 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9374 - accuracy: 0.6875\n",
      "Epoch 00012: val_loss improved from 0.91075 to 0.90574, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.0032 - accuracy: 0.6967 - val_loss: 0.9057 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9053 - accuracy: 0.7109\n",
      "Epoch 00013: val_loss did not improve from 0.90574\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9836 - accuracy: 0.6967 - val_loss: 0.9149 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1724 - accuracy: 0.6406\n",
      "Epoch 00014: val_loss did not improve from 0.90574\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9808 - accuracy: 0.6967 - val_loss: 0.9081 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0180 - accuracy: 0.6562\n",
      "Epoch 00015: val_loss improved from 0.90574 to 0.88548, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9759 - accuracy: 0.6967 - val_loss: 0.8855 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9421 - accuracy: 0.7188\n",
      "Epoch 00016: val_loss did not improve from 0.88548\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9720 - accuracy: 0.6967 - val_loss: 0.8876 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9138 - accuracy: 0.6953\n",
      "Epoch 00017: val_loss improved from 0.88548 to 0.87469, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9456 - accuracy: 0.6967 - val_loss: 0.8747 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8576 - accuracy: 0.7188\n",
      "Epoch 00018: val_loss did not improve from 0.87469\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9448 - accuracy: 0.6967 - val_loss: 0.8766 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7276 - accuracy: 0.7578\n",
      "Epoch 00019: val_loss improved from 0.87469 to 0.86132, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9385 - accuracy: 0.6967 - val_loss: 0.8613 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8645 - accuracy: 0.6719\n",
      "Epoch 00020: val_loss improved from 0.86132 to 0.85206, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9359 - accuracy: 0.6967 - val_loss: 0.8521 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0885 - accuracy: 0.6562\n",
      "Epoch 00021: val_loss improved from 0.85206 to 0.84546, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9313 - accuracy: 0.6967 - val_loss: 0.8455 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8617 - accuracy: 0.7500\n",
      "Epoch 00022: val_loss improved from 0.84546 to 0.83201, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9201 - accuracy: 0.6967 - val_loss: 0.8320 - val_accuracy: 0.7075 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9580 - accuracy: 0.6875\n",
      "Epoch 00023: val_loss improved from 0.83201 to 0.82098, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8877 - accuracy: 0.6959 - val_loss: 0.8210 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7598 - accuracy: 0.7109\n",
      "Epoch 00024: val_loss improved from 0.82098 to 0.80625, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8868 - accuracy: 0.6967 - val_loss: 0.8063 - val_accuracy: 0.7075 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9782 - accuracy: 0.6719\n",
      "Epoch 00025: val_loss did not improve from 0.80625\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8973 - accuracy: 0.6943 - val_loss: 0.8189 - val_accuracy: 0.7304 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8815 - accuracy: 0.7188\n",
      "Epoch 00026: val_loss improved from 0.80625 to 0.79261, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8693 - accuracy: 0.6992 - val_loss: 0.7926 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9335 - accuracy: 0.6953\n",
      "Epoch 00027: val_loss did not improve from 0.79261\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8734 - accuracy: 0.6951 - val_loss: 0.8130 - val_accuracy: 0.7266 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8305 - accuracy: 0.7188\n",
      "Epoch 00028: val_loss did not improve from 0.79261\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8840 - accuracy: 0.6984 - val_loss: 0.8221 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8256 - accuracy: 0.6953\n",
      "Epoch 00029: val_loss did not improve from 0.79261\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8508 - accuracy: 0.6984 - val_loss: 0.7980 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8950 - accuracy: 0.6797\n",
      "Epoch 00030: val_loss did not improve from 0.79261\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8297 - accuracy: 0.7000 - val_loss: 0.7940 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8526 - accuracy: 0.7188\n",
      "Epoch 00031: val_loss did not improve from 0.79261\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8266 - accuracy: 0.7090 - val_loss: 0.7977 - val_accuracy: 0.7285 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7142 - accuracy: 0.7500\n",
      "Epoch 00032: val_loss improved from 0.79261 to 0.78777, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8203 - accuracy: 0.7025 - val_loss: 0.7878 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7995 - accuracy: 0.6797\n",
      "Epoch 00033: val_loss did not improve from 0.78777\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8030 - accuracy: 0.7049 - val_loss: 0.7954 - val_accuracy: 0.7323 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9658 - accuracy: 0.6562\n",
      "Epoch 00034: val_loss improved from 0.78777 to 0.78694, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8316 - accuracy: 0.6984 - val_loss: 0.7869 - val_accuracy: 0.7304 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8624 - accuracy: 0.6719\n",
      "Epoch 00035: val_loss did not improve from 0.78694\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7919 - accuracy: 0.7057 - val_loss: 0.7879 - val_accuracy: 0.7361 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9103 - accuracy: 0.6641\n",
      "Epoch 00036: val_loss improved from 0.78694 to 0.77960, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7900 - accuracy: 0.7000 - val_loss: 0.7796 - val_accuracy: 0.7247 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7399 - accuracy: 0.7188\n",
      "Epoch 00037: val_loss improved from 0.77960 to 0.76499, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7715 - accuracy: 0.7000 - val_loss: 0.7650 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7582 - accuracy: 0.6953\n",
      "Epoch 00038: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7774 - accuracy: 0.6992 - val_loss: 0.7729 - val_accuracy: 0.7304 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7637 - accuracy: 0.6719\n",
      "Epoch 00039: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7752 - accuracy: 0.6902 - val_loss: 0.7859 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8202 - accuracy: 0.6328\n",
      "Epoch 00040: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7679 - accuracy: 0.7025 - val_loss: 0.7835 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7957 - accuracy: 0.6875\n",
      "Epoch 00041: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7483 - accuracy: 0.7123 - val_loss: 0.7760 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7584 - accuracy: 0.6875\n",
      "Epoch 00042: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7471 - accuracy: 0.7074 - val_loss: 0.7866 - val_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7084 - accuracy: 0.7734\n",
      "Epoch 00043: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7479 - accuracy: 0.7139 - val_loss: 0.8115 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7518 - accuracy: 0.7344\n",
      "Epoch 00044: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7465 - accuracy: 0.7066 - val_loss: 0.7754 - val_accuracy: 0.7533 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7371 - accuracy: 0.7188\n",
      "Epoch 00045: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7443 - accuracy: 0.7205 - val_loss: 0.7861 - val_accuracy: 0.7533 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7277 - accuracy: 0.6953\n",
      "Epoch 00046: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7182 - accuracy: 0.7361 - val_loss: 0.7894 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5962 - accuracy: 0.8047\n",
      "Epoch 00047: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7153 - accuracy: 0.7221 - val_loss: 0.7763 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7071 - accuracy: 0.7031\n",
      "Epoch 00048: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6779 - accuracy: 0.7393 - val_loss: 0.7832 - val_accuracy: 0.7591 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6176 - accuracy: 0.7734\n",
      "Epoch 00049: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.7402 - val_loss: 0.7838 - val_accuracy: 0.7610 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5756 - accuracy: 0.8203\n",
      "Epoch 00050: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6987 - accuracy: 0.7402 - val_loss: 0.7796 - val_accuracy: 0.7495 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6207 - accuracy: 0.7500\n",
      "Epoch 00051: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.7426 - val_loss: 0.7870 - val_accuracy: 0.7457 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6808 - accuracy: 0.7031\n",
      "Epoch 00052: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.7525 - val_loss: 0.7994 - val_accuracy: 0.7706 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7305 - accuracy: 0.6953\n",
      "Epoch 00053: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.7525 - val_loss: 0.7899 - val_accuracy: 0.7553 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8081 - accuracy: 0.6953\n",
      "Epoch 00054: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.7475 - val_loss: 0.7874 - val_accuracy: 0.7610 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5413 - accuracy: 0.7812\n",
      "Epoch 00055: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.7566 - val_loss: 0.7790 - val_accuracy: 0.7553 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6182 - accuracy: 0.7422\n",
      "Epoch 00056: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.7557 - val_loss: 0.8039 - val_accuracy: 0.7572 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5633 - accuracy: 0.8359\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.7648 - val_loss: 0.7831 - val_accuracy: 0.7648 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6765 - accuracy: 0.7891\n",
      "Epoch 00058: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7762 - val_loss: 0.7892 - val_accuracy: 0.7725 - lr: 5.0000e-04\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6665 - accuracy: 0.7344\n",
      "Epoch 00059: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7795 - val_loss: 0.8006 - val_accuracy: 0.7686 - lr: 5.0000e-04\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6662 - accuracy: 0.7734\n",
      "Epoch 00060: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6016 - accuracy: 0.7770 - val_loss: 0.8115 - val_accuracy: 0.7782 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6147 - accuracy: 0.7188\n",
      "Epoch 00061: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.7746 - val_loss: 0.8038 - val_accuracy: 0.7706 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4824 - accuracy: 0.8594\n",
      "Epoch 00062: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6067 - accuracy: 0.7836 - val_loss: 0.8087 - val_accuracy: 0.7725 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7907 - accuracy: 0.7344\n",
      "Epoch 00063: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5959 - accuracy: 0.7869 - val_loss: 0.8012 - val_accuracy: 0.7706 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5735 - accuracy: 0.8281\n",
      "Epoch 00064: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5930 - accuracy: 0.8000 - val_loss: 0.8112 - val_accuracy: 0.7629 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6687 - accuracy: 0.7734\n",
      "Epoch 00065: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5982 - accuracy: 0.8008 - val_loss: 0.8326 - val_accuracy: 0.7744 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5681 - accuracy: 0.7891\n",
      "Epoch 00066: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5745 - accuracy: 0.7918 - val_loss: 0.8328 - val_accuracy: 0.7706 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6110 - accuracy: 0.8203\n",
      "Epoch 00067: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5943 - accuracy: 0.7951 - val_loss: 0.8564 - val_accuracy: 0.7725 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5428 - accuracy: 0.8281\n",
      "Epoch 00068: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5803 - accuracy: 0.7910 - val_loss: 0.8390 - val_accuracy: 0.7782 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5148 - accuracy: 0.8203\n",
      "Epoch 00069: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5641 - accuracy: 0.8066 - val_loss: 0.8461 - val_accuracy: 0.7820 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6171 - accuracy: 0.8125\n",
      "Epoch 00070: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5623 - accuracy: 0.8082 - val_loss: 0.8190 - val_accuracy: 0.7706 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8104 - accuracy: 0.7266\n",
      "Epoch 00071: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5742 - accuracy: 0.7943 - val_loss: 0.8349 - val_accuracy: 0.7801 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5755 - accuracy: 0.7891\n",
      "Epoch 00072: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5537 - accuracy: 0.7975 - val_loss: 0.8313 - val_accuracy: 0.7782 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5575 - accuracy: 0.8203\n",
      "Epoch 00073: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.8131 - val_loss: 0.8441 - val_accuracy: 0.7820 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7174 - accuracy: 0.7500\n",
      "Epoch 00074: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.8090 - val_loss: 0.8464 - val_accuracy: 0.7878 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4621 - accuracy: 0.8203\n",
      "Epoch 00075: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.8098 - val_loss: 0.8538 - val_accuracy: 0.7839 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3937 - accuracy: 0.8359\n",
      "Epoch 00076: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.8008 - val_loss: 0.8750 - val_accuracy: 0.7839 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5391 - accuracy: 0.8047\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.8131 - val_loss: 0.8682 - val_accuracy: 0.7839 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4688 - accuracy: 0.8359\n",
      "Epoch 00078: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.8123 - val_loss: 0.8480 - val_accuracy: 0.7820 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6552 - accuracy: 0.7891\n",
      "Epoch 00079: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.8148 - val_loss: 0.8596 - val_accuracy: 0.7744 - lr: 2.5000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4583 - accuracy: 0.8516\n",
      "Epoch 00080: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.8148 - val_loss: 0.8717 - val_accuracy: 0.7820 - lr: 2.5000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4345 - accuracy: 0.8672\n",
      "Epoch 00081: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.8164 - val_loss: 0.8661 - val_accuracy: 0.7897 - lr: 2.5000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5097 - accuracy: 0.8281\n",
      "Epoch 00082: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.8189 - val_loss: 0.8745 - val_accuracy: 0.7859 - lr: 2.5000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5421 - accuracy: 0.8359\n",
      "Epoch 00083: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.8205 - val_loss: 0.8624 - val_accuracy: 0.7839 - lr: 2.5000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4864 - accuracy: 0.8203\n",
      "Epoch 00084: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.8270 - val_loss: 0.8774 - val_accuracy: 0.7820 - lr: 2.5000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5234 - accuracy: 0.8203\n",
      "Epoch 00085: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.8180 - val_loss: 0.8814 - val_accuracy: 0.7801 - lr: 2.5000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5009 - accuracy: 0.8125\n",
      "Epoch 00086: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.8082 - val_loss: 0.8791 - val_accuracy: 0.7859 - lr: 2.5000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4060 - accuracy: 0.8672\n",
      "Epoch 00087: val_loss did not improve from 0.76499\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.8172 - val_loss: 0.8794 - val_accuracy: 0.7859 - lr: 2.5000e-04\n",
      "Epoch 00087: early stopping\n",
      "Epoch 1/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.9022 - accuracy: 0.0547\n",
      "Epoch 00001: val_loss improved from inf to 1.73729, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.8189 - accuracy: 0.1000 - val_loss: 1.7373 - val_accuracy: 0.3909 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.7548 - accuracy: 0.1875\n",
      "Epoch 00002: val_loss improved from 1.73729 to 1.68073, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.7286 - accuracy: 0.2443 - val_loss: 1.6807 - val_accuracy: 0.4412 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.6945 - accuracy: 0.3203\n",
      "Epoch 00003: val_loss improved from 1.68073 to 1.61749, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6830 - accuracy: 0.3608 - val_loss: 1.6175 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.6801 - accuracy: 0.4219\n",
      "Epoch 00004: val_loss improved from 1.61749 to 1.55253, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.6070 - accuracy: 0.4237 - val_loss: 1.5525 - val_accuracy: 0.4341 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.4338 - accuracy: 0.4844\n",
      "Epoch 00005: val_loss improved from 1.55253 to 1.51046, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.5331 - accuracy: 0.4392 - val_loss: 1.5105 - val_accuracy: 0.4341 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.5066 - accuracy: 0.4609\n",
      "Epoch 00006: val_loss improved from 1.51046 to 1.47404, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4761 - accuracy: 0.4412 - val_loss: 1.4740 - val_accuracy: 0.4341 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.3661 - accuracy: 0.4297\n",
      "Epoch 00007: val_loss improved from 1.47404 to 1.44065, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.4347 - accuracy: 0.4340 - val_loss: 1.4407 - val_accuracy: 0.4341 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.5386 - accuracy: 0.4453\n",
      "Epoch 00008: val_loss improved from 1.44065 to 1.41785, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.4141 - accuracy: 0.4526 - val_loss: 1.4178 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.3775 - accuracy: 0.4453\n",
      "Epoch 00009: val_loss improved from 1.41785 to 1.40139, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3966 - accuracy: 0.4536 - val_loss: 1.4014 - val_accuracy: 0.4365 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.4080 - accuracy: 0.4531\n",
      "Epoch 00010: val_loss improved from 1.40139 to 1.38913, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3468 - accuracy: 0.4546 - val_loss: 1.3891 - val_accuracy: 0.4341 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.3914 - accuracy: 0.4531\n",
      "Epoch 00011: val_loss improved from 1.38913 to 1.37382, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3392 - accuracy: 0.4577 - val_loss: 1.3738 - val_accuracy: 0.4388 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2357 - accuracy: 0.4375\n",
      "Epoch 00012: val_loss improved from 1.37382 to 1.36430, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3262 - accuracy: 0.4526 - val_loss: 1.3643 - val_accuracy: 0.4532 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.3417 - accuracy: 0.4375\n",
      "Epoch 00013: val_loss did not improve from 1.36430\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3076 - accuracy: 0.4557 - val_loss: 1.3668 - val_accuracy: 0.4604 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2661 - accuracy: 0.4688\n",
      "Epoch 00014: val_loss improved from 1.36430 to 1.35703, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.2993 - accuracy: 0.4722 - val_loss: 1.3570 - val_accuracy: 0.4724 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2519 - accuracy: 0.4922\n",
      "Epoch 00015: val_loss improved from 1.35703 to 1.34401, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2789 - accuracy: 0.4742 - val_loss: 1.3440 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2706 - accuracy: 0.5078\n",
      "Epoch 00016: val_loss improved from 1.34401 to 1.33829, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2628 - accuracy: 0.4856 - val_loss: 1.3383 - val_accuracy: 0.4892 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2888 - accuracy: 0.4609\n",
      "Epoch 00017: val_loss improved from 1.33829 to 1.32325, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2763 - accuracy: 0.4938 - val_loss: 1.3233 - val_accuracy: 0.5012 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1811 - accuracy: 0.5469\n",
      "Epoch 00018: val_loss improved from 1.32325 to 1.32268, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2564 - accuracy: 0.4979 - val_loss: 1.3227 - val_accuracy: 0.4988 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2488 - accuracy: 0.3906\n",
      "Epoch 00019: val_loss improved from 1.32268 to 1.31025, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2374 - accuracy: 0.5010 - val_loss: 1.3102 - val_accuracy: 0.5372 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2257 - accuracy: 0.4922\n",
      "Epoch 00020: val_loss improved from 1.31025 to 1.30119, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.2265 - accuracy: 0.5206 - val_loss: 1.3012 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2326 - accuracy: 0.5938\n",
      "Epoch 00021: val_loss improved from 1.30119 to 1.28987, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.2191 - accuracy: 0.5320 - val_loss: 1.2899 - val_accuracy: 0.5444 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1732 - accuracy: 0.5469\n",
      "Epoch 00022: val_loss improved from 1.28987 to 1.27719, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.2087 - accuracy: 0.5278 - val_loss: 1.2772 - val_accuracy: 0.5516 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2350 - accuracy: 0.5469\n",
      "Epoch 00023: val_loss improved from 1.27719 to 1.27338, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1836 - accuracy: 0.5732 - val_loss: 1.2734 - val_accuracy: 0.5683 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1538 - accuracy: 0.5781\n",
      "Epoch 00024: val_loss did not improve from 1.27338\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1832 - accuracy: 0.5588 - val_loss: 1.2830 - val_accuracy: 0.5659 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.2661 - accuracy: 0.5156\n",
      "Epoch 00025: val_loss improved from 1.27338 to 1.26649, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1542 - accuracy: 0.5680 - val_loss: 1.2665 - val_accuracy: 0.5755 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1473 - accuracy: 0.5703\n",
      "Epoch 00026: val_loss improved from 1.26649 to 1.24642, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1510 - accuracy: 0.5680 - val_loss: 1.2464 - val_accuracy: 0.5659 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1250 - accuracy: 0.5547\n",
      "Epoch 00027: val_loss improved from 1.24642 to 1.24397, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1362 - accuracy: 0.5804 - val_loss: 1.2440 - val_accuracy: 0.5827 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0844 - accuracy: 0.6250\n",
      "Epoch 00028: val_loss improved from 1.24397 to 1.24254, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1080 - accuracy: 0.5897 - val_loss: 1.2425 - val_accuracy: 0.5923 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1962 - accuracy: 0.5859\n",
      "Epoch 00029: val_loss improved from 1.24254 to 1.22568, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.1132 - accuracy: 0.5887 - val_loss: 1.2257 - val_accuracy: 0.5875 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0602 - accuracy: 0.6094\n",
      "Epoch 00030: val_loss improved from 1.22568 to 1.22083, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0993 - accuracy: 0.6062 - val_loss: 1.2208 - val_accuracy: 0.6019 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0692 - accuracy: 0.6484\n",
      "Epoch 00031: val_loss improved from 1.22083 to 1.20169, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0731 - accuracy: 0.6227 - val_loss: 1.2017 - val_accuracy: 0.6091 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0645 - accuracy: 0.5938\n",
      "Epoch 00032: val_loss improved from 1.20169 to 1.19734, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0593 - accuracy: 0.6196 - val_loss: 1.1973 - val_accuracy: 0.5995 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0881 - accuracy: 0.6250\n",
      "Epoch 00033: val_loss improved from 1.19734 to 1.18317, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0625 - accuracy: 0.6041 - val_loss: 1.1832 - val_accuracy: 0.6163 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.9184 - accuracy: 0.6953\n",
      "Epoch 00034: val_loss did not improve from 1.18317\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0273 - accuracy: 0.6227 - val_loss: 1.1990 - val_accuracy: 0.6163 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8648 - accuracy: 0.6875\n",
      "Epoch 00035: val_loss did not improve from 1.18317\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0237 - accuracy: 0.6412 - val_loss: 1.1910 - val_accuracy: 0.6067 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.9053 - accuracy: 0.7266\n",
      "Epoch 00036: val_loss improved from 1.18317 to 1.17289, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0237 - accuracy: 0.6381 - val_loss: 1.1729 - val_accuracy: 0.6187 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0809 - accuracy: 0.6250\n",
      "Epoch 00037: val_loss improved from 1.17289 to 1.15078, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0047 - accuracy: 0.6515 - val_loss: 1.1508 - val_accuracy: 0.6019 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.1009 - accuracy: 0.5469\n",
      "Epoch 00038: val_loss did not improve from 1.15078\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9873 - accuracy: 0.6392 - val_loss: 1.2016 - val_accuracy: 0.6067 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0295 - accuracy: 0.6094\n",
      "Epoch 00039: val_loss improved from 1.15078 to 1.14775, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9853 - accuracy: 0.6495 - val_loss: 1.1477 - val_accuracy: 0.6235 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.9737 - accuracy: 0.6406\n",
      "Epoch 00040: val_loss did not improve from 1.14775\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.9706 - accuracy: 0.6567 - val_loss: 1.1636 - val_accuracy: 0.6115 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 1.0128 - accuracy: 0.6328\n",
      "Epoch 00041: val_loss did not improve from 1.14775\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.9374 - accuracy: 0.6660 - val_loss: 1.1576 - val_accuracy: 0.6115 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.9796 - accuracy: 0.6484\n",
      "Epoch 00042: val_loss did not improve from 1.14775\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9441 - accuracy: 0.6526 - val_loss: 1.1669 - val_accuracy: 0.6187 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8557 - accuracy: 0.6484\n",
      "Epoch 00043: val_loss improved from 1.14775 to 1.12437, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9105 - accuracy: 0.6639 - val_loss: 1.1244 - val_accuracy: 0.6139 - lr: 0.0010\n",
      "Epoch 44/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 0.9986 - accuracy: 0.6250\n",
      "Epoch 00044: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9209 - accuracy: 0.6629 - val_loss: 1.1340 - val_accuracy: 0.6235 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8153 - accuracy: 0.7031\n",
      "Epoch 00045: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8660 - accuracy: 0.6742 - val_loss: 1.1678 - val_accuracy: 0.6211 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7856 - accuracy: 0.7031\n",
      "Epoch 00046: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8937 - accuracy: 0.6649 - val_loss: 1.1678 - val_accuracy: 0.6163 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7895 - accuracy: 0.6953\n",
      "Epoch 00047: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8704 - accuracy: 0.6814 - val_loss: 1.1488 - val_accuracy: 0.6187 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8188 - accuracy: 0.6875\n",
      "Epoch 00048: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8715 - accuracy: 0.6773 - val_loss: 1.1621 - val_accuracy: 0.6235 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8145 - accuracy: 0.6797\n",
      "Epoch 00049: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8633 - accuracy: 0.6784 - val_loss: 1.1609 - val_accuracy: 0.6355 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7992 - accuracy: 0.7188\n",
      "Epoch 00050: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8466 - accuracy: 0.6938 - val_loss: 1.1438 - val_accuracy: 0.6187 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8319 - accuracy: 0.6641\n",
      "Epoch 00051: val_loss did not improve from 1.12437\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8829 - accuracy: 0.6856 - val_loss: 1.1511 - val_accuracy: 0.6355 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.9185 - accuracy: 0.6250\n",
      "Epoch 00052: val_loss improved from 1.12437 to 1.12251, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8393 - accuracy: 0.6866 - val_loss: 1.1225 - val_accuracy: 0.6451 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7974 - accuracy: 0.7109\n",
      "Epoch 00053: val_loss improved from 1.12251 to 1.09754, saving model to cnn_class_mic.h5\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8315 - accuracy: 0.7062 - val_loss: 1.0975 - val_accuracy: 0.6427 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7495 - accuracy: 0.7266\n",
      "Epoch 00054: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8114 - accuracy: 0.7093 - val_loss: 1.1383 - val_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7656 - accuracy: 0.7266\n",
      "Epoch 00055: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7983 - accuracy: 0.7082 - val_loss: 1.1502 - val_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7313 - accuracy: 0.7266\n",
      "Epoch 00056: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8025 - accuracy: 0.7062 - val_loss: 1.1249 - val_accuracy: 0.6499 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7251 - accuracy: 0.7422\n",
      "Epoch 00057: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8084 - accuracy: 0.7062 - val_loss: 1.1208 - val_accuracy: 0.6451 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7134 - accuracy: 0.7266\n",
      "Epoch 00058: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7819 - accuracy: 0.7144 - val_loss: 1.1234 - val_accuracy: 0.6379 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7824 - accuracy: 0.6875\n",
      "Epoch 00059: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7585 - accuracy: 0.7206 - val_loss: 1.1478 - val_accuracy: 0.6379 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7947 - accuracy: 0.7188\n",
      "Epoch 00060: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7837 - accuracy: 0.7155 - val_loss: 1.1662 - val_accuracy: 0.6355 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7383 - accuracy: 0.7031\n",
      "Epoch 00061: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7668 - accuracy: 0.7247 - val_loss: 1.1023 - val_accuracy: 0.6451 - lr: 0.0010\n",
      "Epoch 62/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7002 - accuracy: 0.7188\n",
      "Epoch 00062: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7237 - accuracy: 0.7351 - val_loss: 1.1281 - val_accuracy: 0.6547 - lr: 0.0010\n",
      "Epoch 63/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8838 - accuracy: 0.6797\n",
      "Epoch 00063: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7450 - accuracy: 0.7340 - val_loss: 1.1919 - val_accuracy: 0.6355 - lr: 0.0010\n",
      "Epoch 64/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8144 - accuracy: 0.6875\n",
      "Epoch 00064: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7344 - accuracy: 0.7268 - val_loss: 1.1709 - val_accuracy: 0.6403 - lr: 0.0010\n",
      "Epoch 65/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8427 - accuracy: 0.6797\n",
      "Epoch 00065: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7283 - accuracy: 0.7351 - val_loss: 1.1918 - val_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 66/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7173 - accuracy: 0.7188\n",
      "Epoch 00066: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7054 - accuracy: 0.7433 - val_loss: 1.1897 - val_accuracy: 0.6451 - lr: 0.0010\n",
      "Epoch 67/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6485 - accuracy: 0.7578\n",
      "Epoch 00067: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7012 - accuracy: 0.7423 - val_loss: 1.2080 - val_accuracy: 0.6427 - lr: 0.0010\n",
      "Epoch 68/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7040 - accuracy: 0.7188\n",
      "Epoch 00068: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7029 - accuracy: 0.7423 - val_loss: 1.1957 - val_accuracy: 0.6379 - lr: 0.0010\n",
      "Epoch 69/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6816 - accuracy: 0.7344\n",
      "Epoch 00069: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7158 - accuracy: 0.7351 - val_loss: 1.2142 - val_accuracy: 0.6427 - lr: 0.0010\n",
      "Epoch 70/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6735 - accuracy: 0.7422\n",
      "Epoch 00070: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.7443 - val_loss: 1.2154 - val_accuracy: 0.6331 - lr: 0.0010\n",
      "Epoch 71/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6302 - accuracy: 0.7969\n",
      "Epoch 00071: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.7381 - val_loss: 1.2349 - val_accuracy: 0.6403 - lr: 0.0010\n",
      "Epoch 72/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6919 - accuracy: 0.7266\n",
      "Epoch 00072: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.7371 - val_loss: 1.1835 - val_accuracy: 0.6307 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5898 - accuracy: 0.7891\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6814 - accuracy: 0.7495 - val_loss: 1.2202 - val_accuracy: 0.6187 - lr: 0.0010\n",
      "Epoch 74/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6463 - accuracy: 0.7266\n",
      "Epoch 00074: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7055 - accuracy: 0.7361 - val_loss: 1.2113 - val_accuracy: 0.6475 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6908 - accuracy: 0.7422\n",
      "Epoch 00075: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.7464 - val_loss: 1.2528 - val_accuracy: 0.6451 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.8006 - accuracy: 0.6641\n",
      "Epoch 00076: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6371 - accuracy: 0.7567 - val_loss: 1.2428 - val_accuracy: 0.6427 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6878 - accuracy: 0.7266\n",
      "Epoch 00077: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6275 - accuracy: 0.7670 - val_loss: 1.2228 - val_accuracy: 0.6547 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6723 - accuracy: 0.7344\n",
      "Epoch 00078: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.7536 - val_loss: 1.2431 - val_accuracy: 0.6523 - lr: 5.0000e-04\n",
      "Epoch 79/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6154 - accuracy: 0.7812\n",
      "Epoch 00079: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6597 - accuracy: 0.7536 - val_loss: 1.2660 - val_accuracy: 0.6475 - lr: 5.0000e-04\n",
      "Epoch 80/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6809 - accuracy: 0.7344\n",
      "Epoch 00080: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6232 - accuracy: 0.7660 - val_loss: 1.2531 - val_accuracy: 0.6403 - lr: 5.0000e-04\n",
      "Epoch 81/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5572 - accuracy: 0.8203\n",
      "Epoch 00081: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.7763 - val_loss: 1.2672 - val_accuracy: 0.6451 - lr: 5.0000e-04\n",
      "Epoch 82/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5510 - accuracy: 0.8359\n",
      "Epoch 00082: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6299 - accuracy: 0.7691 - val_loss: 1.2798 - val_accuracy: 0.6523 - lr: 5.0000e-04\n",
      "Epoch 83/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6596 - accuracy: 0.7188\n",
      "Epoch 00083: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6233 - accuracy: 0.7680 - val_loss: 1.2353 - val_accuracy: 0.6547 - lr: 5.0000e-04\n",
      "Epoch 84/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5546 - accuracy: 0.8047\n",
      "Epoch 00084: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.7691 - val_loss: 1.2477 - val_accuracy: 0.6499 - lr: 5.0000e-04\n",
      "Epoch 85/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5421 - accuracy: 0.8203\n",
      "Epoch 00085: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.7691 - val_loss: 1.2970 - val_accuracy: 0.6499 - lr: 5.0000e-04\n",
      "Epoch 86/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5962 - accuracy: 0.7734\n",
      "Epoch 00086: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6211 - accuracy: 0.7557 - val_loss: 1.3041 - val_accuracy: 0.6547 - lr: 5.0000e-04\n",
      "Epoch 87/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6952 - accuracy: 0.7188\n",
      "Epoch 00087: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5953 - accuracy: 0.7814 - val_loss: 1.2838 - val_accuracy: 0.6523 - lr: 5.0000e-04\n",
      "Epoch 88/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6790 - accuracy: 0.7344\n",
      "Epoch 00088: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6031 - accuracy: 0.7680 - val_loss: 1.2889 - val_accuracy: 0.6499 - lr: 5.0000e-04\n",
      "Epoch 89/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5015 - accuracy: 0.8203\n",
      "Epoch 00089: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5998 - accuracy: 0.7742 - val_loss: 1.2878 - val_accuracy: 0.6379 - lr: 5.0000e-04\n",
      "Epoch 90/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6021 - accuracy: 0.7812\n",
      "Epoch 00090: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5866 - accuracy: 0.7773 - val_loss: 1.3442 - val_accuracy: 0.6331 - lr: 5.0000e-04\n",
      "Epoch 91/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6079 - accuracy: 0.7500\n",
      "Epoch 00091: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5953 - accuracy: 0.7680 - val_loss: 1.3793 - val_accuracy: 0.6427 - lr: 5.0000e-04\n",
      "Epoch 92/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6954 - accuracy: 0.7422\n",
      "Epoch 00092: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.7856 - val_loss: 1.3220 - val_accuracy: 0.6619 - lr: 5.0000e-04\n",
      "Epoch 93/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6130 - accuracy: 0.7734\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5934 - accuracy: 0.7711 - val_loss: 1.3287 - val_accuracy: 0.6475 - lr: 5.0000e-04\n",
      "Epoch 94/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5846 - accuracy: 0.7578\n",
      "Epoch 00094: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.7619 - val_loss: 1.3472 - val_accuracy: 0.6547 - lr: 2.5000e-04\n",
      "Epoch 95/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5293 - accuracy: 0.8047\n",
      "Epoch 00095: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5927 - accuracy: 0.7722 - val_loss: 1.3456 - val_accuracy: 0.6499 - lr: 2.5000e-04\n",
      "Epoch 96/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6384 - accuracy: 0.7578\n",
      "Epoch 00096: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5654 - accuracy: 0.7773 - val_loss: 1.3397 - val_accuracy: 0.6523 - lr: 2.5000e-04\n",
      "Epoch 97/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.7216 - accuracy: 0.7422\n",
      "Epoch 00097: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6003 - accuracy: 0.7722 - val_loss: 1.3259 - val_accuracy: 0.6547 - lr: 2.5000e-04\n",
      "Epoch 98/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4949 - accuracy: 0.8047\n",
      "Epoch 00098: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5826 - accuracy: 0.7732 - val_loss: 1.3242 - val_accuracy: 0.6475 - lr: 2.5000e-04\n",
      "Epoch 99/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5892 - accuracy: 0.7734\n",
      "Epoch 00099: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.7814 - val_loss: 1.3154 - val_accuracy: 0.6595 - lr: 2.5000e-04\n",
      "Epoch 100/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5323 - accuracy: 0.8125\n",
      "Epoch 00100: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.7887 - val_loss: 1.3313 - val_accuracy: 0.6595 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4956 - accuracy: 0.8438\n",
      "Epoch 00101: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.7722 - val_loss: 1.3675 - val_accuracy: 0.6547 - lr: 2.5000e-04\n",
      "Epoch 102/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5767 - accuracy: 0.7812\n",
      "Epoch 00102: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5843 - accuracy: 0.7825 - val_loss: 1.3727 - val_accuracy: 0.6547 - lr: 2.5000e-04\n",
      "Epoch 103/4000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5618 - accuracy: 0.7812\n",
      "Epoch 00103: val_loss did not improve from 1.09754\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5624 - accuracy: 0.7794 - val_loss: 1.3400 - val_accuracy: 0.6547 - lr: 2.5000e-04\n",
      "Epoch 00103: early stopping\n",
      "Epoch 1/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.9216 - accuracy: 0.2891\n",
      "Epoch 00001: val_loss improved from inf to 1.66450, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.8244 - accuracy: 0.2426 - val_loss: 1.6645 - val_accuracy: 0.2409 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.7087 - accuracy: 0.2109\n",
      "Epoch 00002: val_loss improved from 1.66450 to 1.48025, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.6041 - accuracy: 0.2533 - val_loss: 1.4802 - val_accuracy: 0.2505 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.4504 - accuracy: 0.3828\n",
      "Epoch 00003: val_loss improved from 1.48025 to 1.22738, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4134 - accuracy: 0.3303 - val_loss: 1.2274 - val_accuracy: 0.4876 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2517 - accuracy: 0.4375\n",
      "Epoch 00004: val_loss improved from 1.22738 to 1.00950, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2083 - accuracy: 0.5500 - val_loss: 1.0095 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.2526 - accuracy: 0.6094\n",
      "Epoch 00005: val_loss improved from 1.00950 to 0.96224, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1106 - accuracy: 0.6484 - val_loss: 0.9622 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.1208 - accuracy: 0.6250\n",
      "Epoch 00006: val_loss improved from 0.96224 to 0.94599, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0954 - accuracy: 0.6492 - val_loss: 0.9460 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9417 - accuracy: 0.6719\n",
      "Epoch 00007: val_loss improved from 0.94599 to 0.91681, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.0170 - accuracy: 0.6484 - val_loss: 0.9168 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9896 - accuracy: 0.6641\n",
      "Epoch 00008: val_loss improved from 0.91681 to 0.88834, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9985 - accuracy: 0.6475 - val_loss: 0.8883 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9966 - accuracy: 0.6328\n",
      "Epoch 00009: val_loss improved from 0.88834 to 0.87643, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9764 - accuracy: 0.6467 - val_loss: 0.8764 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9301 - accuracy: 0.7266\n",
      "Epoch 00010: val_loss improved from 0.87643 to 0.86519, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9813 - accuracy: 0.6451 - val_loss: 0.8652 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8661 - accuracy: 0.6562\n",
      "Epoch 00011: val_loss improved from 0.86519 to 0.86428, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9582 - accuracy: 0.6467 - val_loss: 0.8643 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0200 - accuracy: 0.6172\n",
      "Epoch 00012: val_loss did not improve from 0.86428\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9635 - accuracy: 0.6484 - val_loss: 0.8679 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0770 - accuracy: 0.6094\n",
      "Epoch 00013: val_loss improved from 0.86428 to 0.85933, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9358 - accuracy: 0.6467 - val_loss: 0.8593 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9189 - accuracy: 0.6406\n",
      "Epoch 00014: val_loss improved from 0.85933 to 0.84946, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9416 - accuracy: 0.6492 - val_loss: 0.8495 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8559 - accuracy: 0.6953\n",
      "Epoch 00015: val_loss did not improve from 0.84946\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9247 - accuracy: 0.6475 - val_loss: 0.8543 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8931 - accuracy: 0.6641\n",
      "Epoch 00016: val_loss did not improve from 0.84946\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9143 - accuracy: 0.6475 - val_loss: 0.8544 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9055 - accuracy: 0.6797\n",
      "Epoch 00017: val_loss improved from 0.84946 to 0.84501, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9081 - accuracy: 0.6484 - val_loss: 0.8450 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9157 - accuracy: 0.6484\n",
      "Epoch 00018: val_loss improved from 0.84501 to 0.84372, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9160 - accuracy: 0.6492 - val_loss: 0.8437 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9714 - accuracy: 0.6250\n",
      "Epoch 00019: val_loss did not improve from 0.84372\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8906 - accuracy: 0.6475 - val_loss: 0.8458 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8544 - accuracy: 0.6406\n",
      "Epoch 00020: val_loss improved from 0.84372 to 0.84083, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8868 - accuracy: 0.6500 - val_loss: 0.8408 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.9171 - accuracy: 0.6250\n",
      "Epoch 00021: val_loss improved from 0.84083 to 0.83307, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8838 - accuracy: 0.6500 - val_loss: 0.8331 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8255 - accuracy: 0.6953\n",
      "Epoch 00022: val_loss did not improve from 0.83307\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8695 - accuracy: 0.6516 - val_loss: 0.8347 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8229 - accuracy: 0.6562\n",
      "Epoch 00023: val_loss did not improve from 0.83307\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8709 - accuracy: 0.6525 - val_loss: 0.8397 - val_accuracy: 0.6711 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7667 - accuracy: 0.6562\n",
      "Epoch 00024: val_loss improved from 0.83307 to 0.82800, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8572 - accuracy: 0.6533 - val_loss: 0.8280 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7637 - accuracy: 0.7188\n",
      "Epoch 00025: val_loss did not improve from 0.82800\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8539 - accuracy: 0.6525 - val_loss: 0.8306 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8250 - accuracy: 0.6797\n",
      "Epoch 00026: val_loss improved from 0.82800 to 0.82276, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8336 - accuracy: 0.6566 - val_loss: 0.8228 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8526 - accuracy: 0.6797\n",
      "Epoch 00027: val_loss did not improve from 0.82276\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8312 - accuracy: 0.6582 - val_loss: 0.8325 - val_accuracy: 0.6769 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7248 - accuracy: 0.7500\n",
      "Epoch 00028: val_loss improved from 0.82276 to 0.82082, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8127 - accuracy: 0.6598 - val_loss: 0.8208 - val_accuracy: 0.6807 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8569 - accuracy: 0.6562\n",
      "Epoch 00029: val_loss improved from 0.82082 to 0.81921, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8155 - accuracy: 0.6615 - val_loss: 0.8192 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7058 - accuracy: 0.7578\n",
      "Epoch 00030: val_loss improved from 0.81921 to 0.81691, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8124 - accuracy: 0.6639 - val_loss: 0.8169 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8092 - accuracy: 0.6641\n",
      "Epoch 00031: val_loss did not improve from 0.81691\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8059 - accuracy: 0.6656 - val_loss: 0.8240 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8466 - accuracy: 0.6328\n",
      "Epoch 00032: val_loss did not improve from 0.81691\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8010 - accuracy: 0.6639 - val_loss: 0.8181 - val_accuracy: 0.6826 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7748 - accuracy: 0.7031\n",
      "Epoch 00033: val_loss did not improve from 0.81691\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7822 - accuracy: 0.6705 - val_loss: 0.8196 - val_accuracy: 0.6807 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7640 - accuracy: 0.6484\n",
      "Epoch 00034: val_loss improved from 0.81691 to 0.81307, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7854 - accuracy: 0.6697 - val_loss: 0.8131 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7044 - accuracy: 0.7109\n",
      "Epoch 00035: val_loss did not improve from 0.81307\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7804 - accuracy: 0.6779 - val_loss: 0.8238 - val_accuracy: 0.6673 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7789 - accuracy: 0.6641\n",
      "Epoch 00036: val_loss improved from 0.81307 to 0.80840, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7511 - accuracy: 0.6746 - val_loss: 0.8084 - val_accuracy: 0.6902 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6663 - accuracy: 0.7344\n",
      "Epoch 00037: val_loss did not improve from 0.80840\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7561 - accuracy: 0.6787 - val_loss: 0.8287 - val_accuracy: 0.6807 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7463 - accuracy: 0.7031\n",
      "Epoch 00038: val_loss improved from 0.80840 to 0.80361, saving model to cnn_class_mic.h5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.7583 - accuracy: 0.6836 - val_loss: 0.8036 - val_accuracy: 0.6941 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8061 - accuracy: 0.6641\n",
      "Epoch 00039: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7426 - accuracy: 0.7066 - val_loss: 0.8063 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6942 - accuracy: 0.7422\n",
      "Epoch 00040: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7426 - accuracy: 0.6959 - val_loss: 0.8209 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7589 - accuracy: 0.7109\n",
      "Epoch 00041: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7446 - accuracy: 0.6918 - val_loss: 0.8134 - val_accuracy: 0.6807 - lr: 0.0010\n",
      "Epoch 42/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.8497 - accuracy: 0.5859\n",
      "Epoch 00042: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7225 - accuracy: 0.7107 - val_loss: 0.8131 - val_accuracy: 0.6960 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7202 - accuracy: 0.7031\n",
      "Epoch 00043: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7262 - accuracy: 0.6984 - val_loss: 0.8109 - val_accuracy: 0.6922 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7089 - accuracy: 0.6484\n",
      "Epoch 00044: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7293 - accuracy: 0.6984 - val_loss: 0.8340 - val_accuracy: 0.6807 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7406 - accuracy: 0.6641\n",
      "Epoch 00045: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.7057 - val_loss: 0.8102 - val_accuracy: 0.6941 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7467 - accuracy: 0.6953\n",
      "Epoch 00046: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6803 - accuracy: 0.7205 - val_loss: 0.8485 - val_accuracy: 0.6769 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7168 - accuracy: 0.7109\n",
      "Epoch 00047: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.7205 - val_loss: 0.8152 - val_accuracy: 0.6922 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6724 - accuracy: 0.7188\n",
      "Epoch 00048: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6708 - accuracy: 0.7238 - val_loss: 0.8657 - val_accuracy: 0.6692 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6096 - accuracy: 0.7734\n",
      "Epoch 00049: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.7254 - val_loss: 0.8363 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6320 - accuracy: 0.7188\n",
      "Epoch 00050: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6717 - accuracy: 0.7246 - val_loss: 0.8396 - val_accuracy: 0.6826 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6310 - accuracy: 0.7266\n",
      "Epoch 00051: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6761 - accuracy: 0.7270 - val_loss: 0.8418 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6320 - accuracy: 0.7109\n",
      "Epoch 00052: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6508 - accuracy: 0.7295 - val_loss: 0.8368 - val_accuracy: 0.6826 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5467 - accuracy: 0.7812\n",
      "Epoch 00053: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.7352 - val_loss: 0.8510 - val_accuracy: 0.6711 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6152 - accuracy: 0.7656\n",
      "Epoch 00054: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.7369 - val_loss: 0.8458 - val_accuracy: 0.6845 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6831 - accuracy: 0.6797\n",
      "Epoch 00055: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.7295 - val_loss: 0.8788 - val_accuracy: 0.6673 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5164 - accuracy: 0.7891\n",
      "Epoch 00056: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.7385 - val_loss: 0.8476 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6826 - accuracy: 0.7344\n",
      "Epoch 00057: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.7262 - val_loss: 0.8561 - val_accuracy: 0.6788 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5672 - accuracy: 0.7578\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.7500 - val_loss: 0.8875 - val_accuracy: 0.6883 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.7648 - accuracy: 0.6797\n",
      "Epoch 00059: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7631 - val_loss: 0.8993 - val_accuracy: 0.6692 - lr: 5.0000e-04\n",
      "Epoch 60/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5164 - accuracy: 0.7969\n",
      "Epoch 00060: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7557 - val_loss: 0.9257 - val_accuracy: 0.6692 - lr: 5.0000e-04\n",
      "Epoch 61/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5322 - accuracy: 0.7578\n",
      "Epoch 00061: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7525 - val_loss: 0.9003 - val_accuracy: 0.6845 - lr: 5.0000e-04\n",
      "Epoch 62/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.6213 - accuracy: 0.7812\n",
      "Epoch 00062: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.7541 - val_loss: 0.9027 - val_accuracy: 0.6864 - lr: 5.0000e-04\n",
      "Epoch 63/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4839 - accuracy: 0.7656\n",
      "Epoch 00063: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5624 - accuracy: 0.7582 - val_loss: 0.9085 - val_accuracy: 0.6769 - lr: 5.0000e-04\n",
      "Epoch 64/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5611 - accuracy: 0.7344\n",
      "Epoch 00064: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7574 - val_loss: 0.9035 - val_accuracy: 0.6845 - lr: 5.0000e-04\n",
      "Epoch 65/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4898 - accuracy: 0.7891\n",
      "Epoch 00065: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.7582 - val_loss: 0.9314 - val_accuracy: 0.6750 - lr: 5.0000e-04\n",
      "Epoch 66/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5622 - accuracy: 0.7500\n",
      "Epoch 00066: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5396 - accuracy: 0.7680 - val_loss: 0.9204 - val_accuracy: 0.6883 - lr: 5.0000e-04\n",
      "Epoch 67/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5456 - accuracy: 0.7500\n",
      "Epoch 00067: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7762 - val_loss: 0.9493 - val_accuracy: 0.6864 - lr: 5.0000e-04\n",
      "Epoch 68/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4843 - accuracy: 0.7891\n",
      "Epoch 00068: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5613 - accuracy: 0.7689 - val_loss: 0.9259 - val_accuracy: 0.6922 - lr: 5.0000e-04\n",
      "Epoch 69/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5246 - accuracy: 0.7422\n",
      "Epoch 00069: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7664 - val_loss: 0.9172 - val_accuracy: 0.6922 - lr: 5.0000e-04\n",
      "Epoch 70/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4753 - accuracy: 0.8203\n",
      "Epoch 00070: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7746 - val_loss: 0.9425 - val_accuracy: 0.6864 - lr: 5.0000e-04\n",
      "Epoch 71/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4825 - accuracy: 0.7812\n",
      "Epoch 00071: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7811 - val_loss: 0.9674 - val_accuracy: 0.6826 - lr: 5.0000e-04\n",
      "Epoch 72/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5444 - accuracy: 0.7812\n",
      "Epoch 00072: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7844 - val_loss: 0.9577 - val_accuracy: 0.6807 - lr: 5.0000e-04\n",
      "Epoch 73/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4868 - accuracy: 0.7656\n",
      "Epoch 00073: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7820 - val_loss: 0.9797 - val_accuracy: 0.6769 - lr: 5.0000e-04\n",
      "Epoch 74/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4299 - accuracy: 0.8281\n",
      "Epoch 00074: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.7869 - val_loss: 0.9702 - val_accuracy: 0.6807 - lr: 5.0000e-04\n",
      "Epoch 75/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5433 - accuracy: 0.7344\n",
      "Epoch 00075: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7787 - val_loss: 1.0012 - val_accuracy: 0.6711 - lr: 5.0000e-04\n",
      "Epoch 76/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4916 - accuracy: 0.7656\n",
      "Epoch 00076: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7738 - val_loss: 1.0154 - val_accuracy: 0.6730 - lr: 5.0000e-04\n",
      "Epoch 77/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4400 - accuracy: 0.8125\n",
      "Epoch 00077: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7943 - val_loss: 1.0334 - val_accuracy: 0.6750 - lr: 5.0000e-04\n",
      "Epoch 78/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5801 - accuracy: 0.7344\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7754 - val_loss: 0.9842 - val_accuracy: 0.6826 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5203 - accuracy: 0.7891\n",
      "Epoch 00079: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5018 - accuracy: 0.7811 - val_loss: 1.0211 - val_accuracy: 0.6807 - lr: 2.5000e-04\n",
      "Epoch 80/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4504 - accuracy: 0.8047\n",
      "Epoch 00080: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7836 - val_loss: 0.9993 - val_accuracy: 0.6807 - lr: 2.5000e-04\n",
      "Epoch 81/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4616 - accuracy: 0.8281\n",
      "Epoch 00081: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7984 - val_loss: 1.0181 - val_accuracy: 0.6750 - lr: 2.5000e-04\n",
      "Epoch 82/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.5042 - accuracy: 0.7969\n",
      "Epoch 00082: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7861 - val_loss: 1.0221 - val_accuracy: 0.6807 - lr: 2.5000e-04\n",
      "Epoch 83/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4406 - accuracy: 0.8281\n",
      "Epoch 00083: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.8066 - val_loss: 1.0400 - val_accuracy: 0.6922 - lr: 2.5000e-04\n",
      "Epoch 84/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4367 - accuracy: 0.7734\n",
      "Epoch 00084: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7975 - val_loss: 1.0238 - val_accuracy: 0.6788 - lr: 2.5000e-04\n",
      "Epoch 85/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4177 - accuracy: 0.8359\n",
      "Epoch 00085: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.8008 - val_loss: 1.0104 - val_accuracy: 0.6730 - lr: 2.5000e-04\n",
      "Epoch 86/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4573 - accuracy: 0.7812\n",
      "Epoch 00086: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.8000 - val_loss: 1.0190 - val_accuracy: 0.6769 - lr: 2.5000e-04\n",
      "Epoch 87/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4643 - accuracy: 0.8203\n",
      "Epoch 00087: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.8057 - val_loss: 1.0417 - val_accuracy: 0.6711 - lr: 2.5000e-04\n",
      "Epoch 88/4000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4743 - accuracy: 0.7578\n",
      "Epoch 00088: val_loss did not improve from 0.80361\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8074 - val_loss: 1.0281 - val_accuracy: 0.6769 - lr: 2.5000e-04\n",
      "Epoch 00088: early stopping\n",
      "Epoch 1/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 2.0759 - accuracy: 0.0703\n",
      "Epoch 00001: val_loss improved from inf to 1.50452, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.9475 - accuracy: 0.0771 - val_loss: 1.5045 - val_accuracy: 0.0231 - lr: 0.0010\n",
      "Epoch 2/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.7596 - accuracy: 0.0703\n",
      "Epoch 00002: val_loss improved from 1.50452 to 1.42940, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.6864 - accuracy: 0.0697 - val_loss: 1.4294 - val_accuracy: 0.0694 - lr: 0.0010\n",
      "Epoch 3/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.5680 - accuracy: 0.0859\n",
      "Epoch 00003: val_loss improved from 1.42940 to 1.38686, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5379 - accuracy: 0.0647 - val_loss: 1.3869 - val_accuracy: 0.2832 - lr: 0.0010\n",
      "Epoch 4/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4957 - accuracy: 0.0625\n",
      "Epoch 00004: val_loss improved from 1.38686 to 1.35775, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4631 - accuracy: 0.0995 - val_loss: 1.3577 - val_accuracy: 0.6474 - lr: 0.0010\n",
      "Epoch 5/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4061 - accuracy: 0.2031\n",
      "Epoch 00005: val_loss improved from 1.35775 to 1.33577, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4017 - accuracy: 0.2463 - val_loss: 1.3358 - val_accuracy: 0.8266 - lr: 0.0010\n",
      "Epoch 6/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.3780 - accuracy: 0.3203\n",
      "Epoch 00006: val_loss improved from 1.33577 to 1.31649, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3706 - accuracy: 0.3632 - val_loss: 1.3165 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 7/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.3355 - accuracy: 0.5469\n",
      "Epoch 00007: val_loss improved from 1.31649 to 1.29686, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3347 - accuracy: 0.5547 - val_loss: 1.2969 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 8/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.3073 - accuracy: 0.6719\n",
      "Epoch 00008: val_loss improved from 1.29686 to 1.27470, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3083 - accuracy: 0.6443 - val_loss: 1.2747 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 9/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.2907 - accuracy: 0.7422\n",
      "Epoch 00009: val_loss improved from 1.27470 to 1.24708, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2846 - accuracy: 0.7488 - val_loss: 1.2471 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 10/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.2699 - accuracy: 0.7422\n",
      "Epoch 00010: val_loss improved from 1.24708 to 1.21263, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2517 - accuracy: 0.8159 - val_loss: 1.2126 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 11/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.2304 - accuracy: 0.8125\n",
      "Epoch 00011: val_loss improved from 1.21263 to 1.16966, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2186 - accuracy: 0.8408 - val_loss: 1.1697 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 12/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1723 - accuracy: 0.8828\n",
      "Epoch 00012: val_loss improved from 1.16966 to 1.11195, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1729 - accuracy: 0.8507 - val_loss: 1.1119 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 13/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.1307 - accuracy: 0.8516\n",
      "Epoch 00013: val_loss improved from 1.11195 to 1.03652, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1144 - accuracy: 0.8632 - val_loss: 1.0365 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 14/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0460 - accuracy: 0.8594\n",
      "Epoch 00014: val_loss improved from 1.03652 to 0.94592, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0397 - accuracy: 0.8657 - val_loss: 0.9459 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 15/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.9876 - accuracy: 0.9062\n",
      "Epoch 00015: val_loss improved from 0.94592 to 0.82905, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9578 - accuracy: 0.8731 - val_loss: 0.8290 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 16/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.9157 - accuracy: 0.8828\n",
      "Epoch 00016: val_loss improved from 0.82905 to 0.70209, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8646 - accuracy: 0.8731 - val_loss: 0.7021 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 17/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.7808 - accuracy: 0.8750\n",
      "Epoch 00017: val_loss improved from 0.70209 to 0.59244, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7632 - accuracy: 0.8731 - val_loss: 0.5924 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 18/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.7501 - accuracy: 0.8438\n",
      "Epoch 00018: val_loss improved from 0.59244 to 0.51670, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6448 - accuracy: 0.8731 - val_loss: 0.5167 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 19/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6301 - accuracy: 0.8516\n",
      "Epoch 00019: val_loss improved from 0.51670 to 0.47426, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6493 - accuracy: 0.8731 - val_loss: 0.4743 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 20/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6560 - accuracy: 0.8359\n",
      "Epoch 00020: val_loss improved from 0.47426 to 0.44402, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5815 - accuracy: 0.8706 - val_loss: 0.4440 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 21/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5131 - accuracy: 0.8672\n",
      "Epoch 00021: val_loss improved from 0.44402 to 0.41948, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5664 - accuracy: 0.8731 - val_loss: 0.4195 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 22/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.7089 - accuracy: 0.8359\n",
      "Epoch 00022: val_loss improved from 0.41948 to 0.40193, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5577 - accuracy: 0.8731 - val_loss: 0.4019 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 23/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5901 - accuracy: 0.8438\n",
      "Epoch 00023: val_loss improved from 0.40193 to 0.38565, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5489 - accuracy: 0.8731 - val_loss: 0.3856 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 24/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4320 - accuracy: 0.9062\n",
      "Epoch 00024: val_loss improved from 0.38565 to 0.36961, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5159 - accuracy: 0.8731 - val_loss: 0.3696 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 25/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5541 - accuracy: 0.8672\n",
      "Epoch 00025: val_loss improved from 0.36961 to 0.35710, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5166 - accuracy: 0.8731 - val_loss: 0.3571 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 26/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4093 - accuracy: 0.8750\n",
      "Epoch 00026: val_loss improved from 0.35710 to 0.34700, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4748 - accuracy: 0.8731 - val_loss: 0.3470 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 27/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5748 - accuracy: 0.8438\n",
      "Epoch 00027: val_loss improved from 0.34700 to 0.33731, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4739 - accuracy: 0.8731 - val_loss: 0.3373 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 28/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5253 - accuracy: 0.8438\n",
      "Epoch 00028: val_loss improved from 0.33731 to 0.32475, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4591 - accuracy: 0.8706 - val_loss: 0.3247 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 29/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.5294 - accuracy: 0.8516\n",
      "Epoch 00029: val_loss improved from 0.32475 to 0.31136, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4529 - accuracy: 0.8731 - val_loss: 0.3114 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 30/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4631 - accuracy: 0.8438\n",
      "Epoch 00030: val_loss improved from 0.31136 to 0.30276, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4375 - accuracy: 0.8731 - val_loss: 0.3028 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 31/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3590 - accuracy: 0.8984\n",
      "Epoch 00031: val_loss improved from 0.30276 to 0.29753, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4187 - accuracy: 0.8731 - val_loss: 0.2975 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 32/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3215 - accuracy: 0.9141\n",
      "Epoch 00032: val_loss improved from 0.29753 to 0.29363, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4318 - accuracy: 0.8706 - val_loss: 0.2936 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 33/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.6495 - accuracy: 0.8359\n",
      "Epoch 00033: val_loss improved from 0.29363 to 0.29255, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4229 - accuracy: 0.8731 - val_loss: 0.2926 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 34/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3786 - accuracy: 0.8828\n",
      "Epoch 00034: val_loss improved from 0.29255 to 0.28808, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3902 - accuracy: 0.8731 - val_loss: 0.2881 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 35/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8984\n",
      "Epoch 00035: val_loss improved from 0.28808 to 0.28216, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3927 - accuracy: 0.8731 - val_loss: 0.2822 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 36/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4040 - accuracy: 0.8750\n",
      "Epoch 00036: val_loss improved from 0.28216 to 0.27631, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3840 - accuracy: 0.8731 - val_loss: 0.2763 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 37/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4292 - accuracy: 0.8281\n",
      "Epoch 00037: val_loss improved from 0.27631 to 0.27067, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3828 - accuracy: 0.8731 - val_loss: 0.2707 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 38/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3721 - accuracy: 0.8672\n",
      "Epoch 00038: val_loss improved from 0.27067 to 0.26736, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3692 - accuracy: 0.8731 - val_loss: 0.2674 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 39/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3568 - accuracy: 0.8750\n",
      "Epoch 00039: val_loss improved from 0.26736 to 0.26685, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3820 - accuracy: 0.8706 - val_loss: 0.2668 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 40/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3807 - accuracy: 0.8750\n",
      "Epoch 00040: val_loss improved from 0.26685 to 0.26585, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3719 - accuracy: 0.8731 - val_loss: 0.2658 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 41/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3398 - accuracy: 0.8750\n",
      "Epoch 00041: val_loss improved from 0.26585 to 0.26459, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3637 - accuracy: 0.8731 - val_loss: 0.2646 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 42/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4348 - accuracy: 0.8438\n",
      "Epoch 00042: val_loss did not improve from 0.26459\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3579 - accuracy: 0.8731 - val_loss: 0.2647 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 43/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4345 - accuracy: 0.8359\n",
      "Epoch 00043: val_loss did not improve from 0.26459\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3570 - accuracy: 0.8731 - val_loss: 0.2657 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 44/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3168 - accuracy: 0.8750\n",
      "Epoch 00044: val_loss improved from 0.26459 to 0.26342, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3345 - accuracy: 0.8731 - val_loss: 0.2634 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 45/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2931 - accuracy: 0.8672\n",
      "Epoch 00045: val_loss improved from 0.26342 to 0.25997, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3262 - accuracy: 0.8731 - val_loss: 0.2600 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 46/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2984 - accuracy: 0.8984\n",
      "Epoch 00046: val_loss improved from 0.25997 to 0.25613, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3225 - accuracy: 0.8731 - val_loss: 0.2561 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 47/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3550 - accuracy: 0.8438\n",
      "Epoch 00047: val_loss improved from 0.25613 to 0.25421, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3214 - accuracy: 0.8731 - val_loss: 0.2542 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 48/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3803 - accuracy: 0.8438\n",
      "Epoch 00048: val_loss did not improve from 0.25421\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3179 - accuracy: 0.8731 - val_loss: 0.2543 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 49/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.4147 - accuracy: 0.8125\n",
      "Epoch 00049: val_loss did not improve from 0.25421\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3288 - accuracy: 0.8731 - val_loss: 0.2555 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 50/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2157 - accuracy: 0.9141\n",
      "Epoch 00050: val_loss did not improve from 0.25421\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.8731 - val_loss: 0.2563 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 51/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2736 - accuracy: 0.8828\n",
      "Epoch 00051: val_loss did not improve from 0.25421\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3102 - accuracy: 0.8731 - val_loss: 0.2569 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 52/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2913 - accuracy: 0.9141\n",
      "Epoch 00052: val_loss did not improve from 0.25421\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3142 - accuracy: 0.8731 - val_loss: 0.2544 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 53/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3680 - accuracy: 0.8281\n",
      "Epoch 00053: val_loss improved from 0.25421 to 0.25129, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3117 - accuracy: 0.8731 - val_loss: 0.2513 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 54/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3978 - accuracy: 0.8047\n",
      "Epoch 00054: val_loss improved from 0.25129 to 0.24907, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3147 - accuracy: 0.8731 - val_loss: 0.2491 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 55/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3301 - accuracy: 0.8516\n",
      "Epoch 00055: val_loss improved from 0.24907 to 0.24701, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3232 - accuracy: 0.8731 - val_loss: 0.2470 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 56/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3432 - accuracy: 0.8359\n",
      "Epoch 00056: val_loss improved from 0.24701 to 0.24520, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3026 - accuracy: 0.8731 - val_loss: 0.2452 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 57/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2685 - accuracy: 0.9062\n",
      "Epoch 00057: val_loss did not improve from 0.24520\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2935 - accuracy: 0.8731 - val_loss: 0.2454 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 58/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3054 - accuracy: 0.8516\n",
      "Epoch 00058: val_loss did not improve from 0.24520\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3093 - accuracy: 0.8731 - val_loss: 0.2453 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 59/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2569 - accuracy: 0.8906\n",
      "Epoch 00059: val_loss improved from 0.24520 to 0.24428, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2942 - accuracy: 0.8731 - val_loss: 0.2443 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 60/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3488 - accuracy: 0.8516\n",
      "Epoch 00060: val_loss improved from 0.24428 to 0.24383, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2842 - accuracy: 0.8731 - val_loss: 0.2438 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 61/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2869 - accuracy: 0.8750\n",
      "Epoch 00061: val_loss did not improve from 0.24383\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2917 - accuracy: 0.8731 - val_loss: 0.2442 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 62/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2496 - accuracy: 0.8828\n",
      "Epoch 00062: val_loss improved from 0.24383 to 0.24378, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2759 - accuracy: 0.8756 - val_loss: 0.2438 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 63/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8359\n",
      "Epoch 00063: val_loss did not improve from 0.24378\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2784 - accuracy: 0.8731 - val_loss: 0.2441 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 64/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2505 - accuracy: 0.8672\n",
      "Epoch 00064: val_loss did not improve from 0.24378\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2645 - accuracy: 0.8731 - val_loss: 0.2454 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 65/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2354 - accuracy: 0.8828\n",
      "Epoch 00065: val_loss did not improve from 0.24378\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2601 - accuracy: 0.8731 - val_loss: 0.2460 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 66/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2387 - accuracy: 0.8906\n",
      "Epoch 00066: val_loss did not improve from 0.24378\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2684 - accuracy: 0.8756 - val_loss: 0.2443 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 67/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2688 - accuracy: 0.8750\n",
      "Epoch 00067: val_loss improved from 0.24378 to 0.23974, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2628 - accuracy: 0.8731 - val_loss: 0.2397 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 68/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8594\n",
      "Epoch 00068: val_loss improved from 0.23974 to 0.23970, saving model to cnn_class_mic.h5\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2608 - accuracy: 0.8731 - val_loss: 0.2397 - val_accuracy: 0.9017 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1893 - accuracy: 0.9141\n",
      "Epoch 00069: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2494 - accuracy: 0.8781 - val_loss: 0.2406 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 70/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3082 - accuracy: 0.8516\n",
      "Epoch 00070: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2478 - accuracy: 0.8756 - val_loss: 0.2405 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 71/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2968 - accuracy: 0.8438\n",
      "Epoch 00071: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2356 - accuracy: 0.8731 - val_loss: 0.2401 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 72/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.3130 - accuracy: 0.8359\n",
      "Epoch 00072: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2515 - accuracy: 0.8706 - val_loss: 0.2403 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 73/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2479 - accuracy: 0.8750\n",
      "Epoch 00073: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2469 - accuracy: 0.8756 - val_loss: 0.2415 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 74/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2389 - accuracy: 0.8672\n",
      "Epoch 00074: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.8756 - val_loss: 0.2419 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 75/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2261 - accuracy: 0.8750\n",
      "Epoch 00075: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2294 - accuracy: 0.8756 - val_loss: 0.2429 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 76/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2099 - accuracy: 0.8984\n",
      "Epoch 00076: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2379 - accuracy: 0.8781 - val_loss: 0.2432 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 77/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2839 - accuracy: 0.8359\n",
      "Epoch 00077: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2298 - accuracy: 0.8756 - val_loss: 0.2445 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 78/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2113 - accuracy: 0.8984\n",
      "Epoch 00078: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2306 - accuracy: 0.8806 - val_loss: 0.2471 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 79/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2667 - accuracy: 0.8672\n",
      "Epoch 00079: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2215 - accuracy: 0.8806 - val_loss: 0.2479 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 80/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2378 - accuracy: 0.8750\n",
      "Epoch 00080: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2299 - accuracy: 0.8806 - val_loss: 0.2411 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 81/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2130 - accuracy: 0.8906\n",
      "Epoch 00081: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2101 - accuracy: 0.8881 - val_loss: 0.2409 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 82/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2388 - accuracy: 0.8828\n",
      "Epoch 00082: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2046 - accuracy: 0.9005 - val_loss: 0.2431 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 83/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1998 - accuracy: 0.8906\n",
      "Epoch 00083: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2104 - accuracy: 0.8930 - val_loss: 0.2498 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 84/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1912 - accuracy: 0.8750\n",
      "Epoch 00084: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2054 - accuracy: 0.8930 - val_loss: 0.2551 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 85/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1943 - accuracy: 0.8828\n",
      "Epoch 00085: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1865 - accuracy: 0.9005 - val_loss: 0.2586 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 86/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1755 - accuracy: 0.9141\n",
      "Epoch 00086: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2016 - accuracy: 0.9080 - val_loss: 0.2577 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 87/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2188 - accuracy: 0.9062\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1891 - accuracy: 0.9204 - val_loss: 0.2557 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 88/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2108 - accuracy: 0.8984\n",
      "Epoch 00088: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2022 - accuracy: 0.9104 - val_loss: 0.2566 - val_accuracy: 0.8960 - lr: 5.0000e-04\n",
      "Epoch 89/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1828 - accuracy: 0.9141\n",
      "Epoch 00089: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1692 - accuracy: 0.9229 - val_loss: 0.2587 - val_accuracy: 0.8960 - lr: 5.0000e-04\n",
      "Epoch 90/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1389 - accuracy: 0.9609\n",
      "Epoch 00090: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1876 - accuracy: 0.9179 - val_loss: 0.2648 - val_accuracy: 0.8902 - lr: 5.0000e-04\n",
      "Epoch 91/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1480 - accuracy: 0.9219\n",
      "Epoch 00091: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1745 - accuracy: 0.9104 - val_loss: 0.2720 - val_accuracy: 0.8902 - lr: 5.0000e-04\n",
      "Epoch 92/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2277 - accuracy: 0.8672\n",
      "Epoch 00092: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9030 - val_loss: 0.2737 - val_accuracy: 0.9017 - lr: 5.0000e-04\n",
      "Epoch 93/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1617 - accuracy: 0.9219\n",
      "Epoch 00093: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1806 - accuracy: 0.9080 - val_loss: 0.2744 - val_accuracy: 0.9017 - lr: 5.0000e-04\n",
      "Epoch 94/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1650 - accuracy: 0.9141\n",
      "Epoch 00094: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1606 - accuracy: 0.9229 - val_loss: 0.2723 - val_accuracy: 0.9017 - lr: 5.0000e-04\n",
      "Epoch 95/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1726 - accuracy: 0.9141\n",
      "Epoch 00095: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.9254 - val_loss: 0.2728 - val_accuracy: 0.8960 - lr: 5.0000e-04\n",
      "Epoch 96/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1204 - accuracy: 0.9453\n",
      "Epoch 00096: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1580 - accuracy: 0.9328 - val_loss: 0.2735 - val_accuracy: 0.8960 - lr: 5.0000e-04\n",
      "Epoch 97/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1313 - accuracy: 0.9375\n",
      "Epoch 00097: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1628 - accuracy: 0.9328 - val_loss: 0.2716 - val_accuracy: 0.9017 - lr: 5.0000e-04\n",
      "Epoch 98/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1924 - accuracy: 0.9219\n",
      "Epoch 00098: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1707 - accuracy: 0.9254 - val_loss: 0.2738 - val_accuracy: 0.9133 - lr: 5.0000e-04\n",
      "Epoch 99/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1580 - accuracy: 0.9062\n",
      "Epoch 00099: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1632 - accuracy: 0.9229 - val_loss: 0.2795 - val_accuracy: 0.9133 - lr: 5.0000e-04\n",
      "Epoch 100/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1242 - accuracy: 0.9375\n",
      "Epoch 00100: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1547 - accuracy: 0.9254 - val_loss: 0.2849 - val_accuracy: 0.9017 - lr: 5.0000e-04\n",
      "Epoch 101/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1861 - accuracy: 0.9062\n",
      "Epoch 00101: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1536 - accuracy: 0.9353 - val_loss: 0.2889 - val_accuracy: 0.8960 - lr: 5.0000e-04\n",
      "Epoch 102/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1505 - accuracy: 0.9297\n",
      "Epoch 00102: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1529 - accuracy: 0.9428 - val_loss: 0.2912 - val_accuracy: 0.9075 - lr: 5.0000e-04\n",
      "Epoch 103/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1233 - accuracy: 0.9375\n",
      "Epoch 00103: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1675 - accuracy: 0.9229 - val_loss: 0.2992 - val_accuracy: 0.9133 - lr: 5.0000e-04\n",
      "Epoch 104/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1182 - accuracy: 0.9609\n",
      "Epoch 00104: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1631 - accuracy: 0.9279 - val_loss: 0.2991 - val_accuracy: 0.9017 - lr: 5.0000e-04\n",
      "Epoch 105/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1630 - accuracy: 0.9219\n",
      "Epoch 00105: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1549 - accuracy: 0.9403 - val_loss: 0.2935 - val_accuracy: 0.9017 - lr: 5.0000e-04\n",
      "Epoch 106/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1053 - accuracy: 0.9766\n",
      "Epoch 00106: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1416 - accuracy: 0.9552 - val_loss: 0.2967 - val_accuracy: 0.8960 - lr: 5.0000e-04\n",
      "Epoch 107/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1210 - accuracy: 0.9375\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1539 - accuracy: 0.9378 - val_loss: 0.3022 - val_accuracy: 0.8960 - lr: 5.0000e-04\n",
      "Epoch 108/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1287 - accuracy: 0.9609\n",
      "Epoch 00108: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9527 - val_loss: 0.3034 - val_accuracy: 0.8960 - lr: 2.5000e-04\n",
      "Epoch 109/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1079 - accuracy: 0.9531\n",
      "Epoch 00109: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1496 - accuracy: 0.9552 - val_loss: 0.3032 - val_accuracy: 0.8960 - lr: 2.5000e-04\n",
      "Epoch 110/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.2069 - accuracy: 0.8984\n",
      "Epoch 00110: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1523 - accuracy: 0.9353 - val_loss: 0.3075 - val_accuracy: 0.9017 - lr: 2.5000e-04\n",
      "Epoch 111/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1236 - accuracy: 0.9531\n",
      "Epoch 00111: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1357 - accuracy: 0.9453 - val_loss: 0.3125 - val_accuracy: 0.9017 - lr: 2.5000e-04\n",
      "Epoch 112/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1491 - accuracy: 0.9531\n",
      "Epoch 00112: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1352 - accuracy: 0.9478 - val_loss: 0.3197 - val_accuracy: 0.9017 - lr: 2.5000e-04\n",
      "Epoch 113/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1825 - accuracy: 0.9219\n",
      "Epoch 00113: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1389 - accuracy: 0.9502 - val_loss: 0.3264 - val_accuracy: 0.9017 - lr: 2.5000e-04\n",
      "Epoch 114/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1498 - accuracy: 0.9531\n",
      "Epoch 00114: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1214 - accuracy: 0.9527 - val_loss: 0.3300 - val_accuracy: 0.9017 - lr: 2.5000e-04\n",
      "Epoch 115/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1237 - accuracy: 0.9688\n",
      "Epoch 00115: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1295 - accuracy: 0.9478 - val_loss: 0.3320 - val_accuracy: 0.9017 - lr: 2.5000e-04\n",
      "Epoch 116/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1576 - accuracy: 0.9453\n",
      "Epoch 00116: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1596 - accuracy: 0.9403 - val_loss: 0.3310 - val_accuracy: 0.8960 - lr: 2.5000e-04\n",
      "Epoch 117/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.1392 - accuracy: 0.9531\n",
      "Epoch 00117: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1377 - accuracy: 0.9502 - val_loss: 0.3318 - val_accuracy: 0.8960 - lr: 2.5000e-04\n",
      "Epoch 118/4000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0872 - accuracy: 0.9766\n",
      "Epoch 00118: val_loss did not improve from 0.23970\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.9577 - val_loss: 0.3341 - val_accuracy: 0.8960 - lr: 2.5000e-04\n",
      "Epoch 00118: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Avarage accuracy within +/-1 2 fold dilution step, by antibiotic\n",
    "\n",
    "# List of antibiotics\n",
    "antibiotics = matrix.columns[-15:]\n",
    "\n",
    "accuracies = []\n",
    "for antibiotic in antibiotics:\n",
    "    # list of unique mic values (leaving nan values)\n",
    "    mic_values_uniq = matrix[antibiotic].loc[matrix[antibiotic]>0].sort_values().unique()\n",
    "    # list of MIC values\n",
    "    mic_values = matrix[antibiotic].loc[matrix[antibiotic]>0].values\n",
    "    # by definition we need to reshape the list of mics\n",
    "    mic_reshape = np.reshape(mic_values,(-1,1))\n",
    "    # define encoder function\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    # transform data from numerical cat to onehot code\n",
    "    mic_onehot = encoder.fit_transform(mic_reshape)\n",
    "    # Define the features input (X) and the target output (y) variables\n",
    "    X = matrix.loc[matrix[antibiotic]>0].values[:,0:136]\n",
    "    y = mic_onehot\n",
    "    # Split into the training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)\n",
    " \n",
    "    # We standardize the input samples\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "    X_train = (X_train - mean)/std\n",
    "    X_test = (X_test - mean)/std\n",
    "    \n",
    "    # The model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(136, ), activation='relu', name='input'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(mic_onehot.shape[1], activation='softmax', name='output'))\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    filepath=\"cnn_class_mic.h5\"\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=50, verbose=1, min_delta=1e-7)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, verbose=1, patience=20, min_lr=0.000000001)\n",
    "    callbacks=[reduce_lr, checkpoint, earlystopper]\n",
    "    history = model.fit(X_train, y_train, epochs=4000, batch_size=128, validation_split=0.3, callbacks=callbacks)\n",
    "    model_from_file = load_model(filepath)\n",
    "    \n",
    "    # concat X_test and y_test\n",
    "    pd.DataFrame(X_test)\n",
    "    pd.DataFrame(y_test)\n",
    "    test_data = pd.concat([pd.DataFrame(X_test),pd.DataFrame(mic_reshape)], axis=1, join='inner')\n",
    "    test_data_enc = pd.concat([pd.DataFrame(X_test),pd.DataFrame(y_test)], axis=1, join='inner')\n",
    "    \n",
    "    accuracy = []\n",
    "    for mic in mic_values_uniq:\n",
    "        X_test_class = test_data.loc[test_data.iloc[:,136]==mic].iloc[:,0:136].to_numpy()\n",
    "        if len(X_test_class)!=0:\n",
    "            y_test_class = test_data_enc.loc[test_data.iloc[:,136]==mic].iloc[:,136:145].to_numpy()\n",
    "            scores = model_from_file.evaluate(X_test_class, y_test_class, verbose=0)\n",
    "            accuracy.append(scores[1])\n",
    "        else:\n",
    "            accuracy.append(0)\n",
    "    accuracies.append(pd.DataFrame(np.reshape(accuracy, (1,-1)), columns=mic_values_uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 33.0, 'Antibiotic MIC (micrograms per milliliter)')"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy within Â±1 2-fold dilution step of the laboratory-derived MIC\n",
    "\n",
    "# Accuracy DataFrame\n",
    "accuracies_dframe = accuracies[0].append(accuracies[1:15], sort=False, ignore_index=True)\n",
    "\n",
    "# Set the width and height of the figure\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Accuracy of the MIC Prediction Model\")\n",
    "\n",
    "# Heatmap showing the amount of genomes with the same MIC for each MIC, by antibiotic\n",
    "sns.heatmap(data=accuracies_dframe,annot=amounts_dframe,fmt='.4g',cmap=\"YlGnBu\")\n",
    "\n",
    "# Add label for horizontal axis\n",
    "plt.xlabel(\"Antibiotic MIC (micrograms per milliliter)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
